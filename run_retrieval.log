2023-10-01 08:36:23,787 INFO rerun retrieving AcademySoftwareFoundation_openexr
2023-10-01 08:36:50,635 INFO 

[Oct 01, 08:36:25] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AcademySoftwareFoundation_openexr/retrieve.py/2023-10-01_08.36.25 




[Oct 01, 08:36:27] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AcademySoftwareFoundation_openexr/retrieve.py/2023-10-01_08.36.25/logs/ 


[Oct 01, 08:36:27] {'root': 'run/retrieve_output', 'experiment': 'AcademySoftwareFoundation_openexr', 'run': '2023-10-01_08.36.25', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/AcademySoftwareFoundation_openexr.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/AcademySoftwareFoundation_openexr', 'index_name': 'AcademySoftwareFoundation_openexr', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:36:38] #> Loading model checkpoint.
[Oct 01, 08:36:38] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:36:39] #> checkpoint['epoch'] = 0
[Oct 01, 08:36:39] #> checkpoint['batch'] = 346000
[Oct 01, 08:36:39] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:36:39] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/AcademySoftwareFoundation_openexr.tsv ...
[Oct 01, 08:36:39] #> Got 7 queries. All QIDs are unique.

[Oct 01, 08:36:41] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/AcademySoftwareFoundation_openexr/AcademySoftwareFoundation_openexr/ivfpq.70.faiss ..
[Oct 01, 08:36:41] #> Building the emb2pid mapping..
[Oct 01, 08:36:42] len(self.emb2pid) = 3365456
[Oct 01, 08:36:43] tensor.size() =  torch.Size([3365968, 128])
[Oct 01, 08:36:43] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/AcademySoftwareFoundation_openexr/AcademySoftwareFoundation_openexr/0.pt ...
[Oct 01, 08:36:44] #> Using strides [332, 398]..
[Oct 01, 08:36:46] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AcademySoftwareFoundation_openexr/retrieve.py/2023-10-01_08.36.25/ranking.tsv
0 A Null Pointer Deference issue exists in Academy Software Foundation OpenEXR 2.3.0 in generatePreview in makePreview.cpp that can cause a denial of service via a crafted EXR file . 175 175 29.65019989013672 15143 989.7234439849854 ms
1 A heap-based buffer overflow vulnerability exists in Academy Software Foundation OpenEXR 2.3.0 in chunkOffsetReconstruction in ImfMultiPartInputFile.cpp that can cause a denial of service via a crafted EXR file . 126 126 31.1346435546875 15143 587.7361297607422 ms
2 A flaw was found in OpenEXR 's hufDecode functionality . This flaw allows an attacker who can pass a crafted file to be processed by OpenEXR , to trigger an undefined right shift error . The highest threat from this vulnerability is to system availability . 210 210 30.735559463500977 4327 444.3818728129069 ms
3 A flaw was found in OpenEXR 's B44Compressor . This flaw allows an attacker who can submit a crafted file to be processed by OpenEXR , to exhaust all memory accessible to the application . The highest threat from this vulnerability is to system availability . 154 154 30.78278923034668 15145 371.1540699005127 ms
4 A head-based buffer overflow exists in Academy Software Foundation OpenEXR 2.3.0 in writeTileData in ImfTiledOutputFile.cpp that can cause a denial of service via a crafted EXR file . 147 147 30.46944808959961 15147 327.1486282348633 ms
5 A flaw was found in OpenEXR 's Multipart input file functionality . A crafted multi-part input file with no actual parts can trigger a NULL pointer dereference . The highest threat from this vulnerability is to system availability . 224 224 30.024492263793945 15146 298.42738310496014 ms
6 OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1 : :LineCompositeTask : :execute ( called from IlmThread_3_1 : :NullThreadPoolProvider : :addTask and IlmThread_3_1 : :ThreadPool : :addGlobalTask ) . NOTE : db217f2 may be inapplicable . 111 111 31.22720718383789 15143 277.9123783111572 ms
[Oct 01, 08:36:48] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AcademySoftwareFoundation_openexr/retrieve.py/2023-10-01_08.36.25/ranking.tsv
#> Done.




2023-10-01 08:36:50,636 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:36:50,637 INFO rerun retrieving DanBloomberg_leptonica
2023-10-01 08:37:16,694 INFO 

[Oct 01, 08:36:52] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/DanBloomberg_leptonica/retrieve.py/2023-10-01_08.36.52 




[Oct 01, 08:36:54] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/DanBloomberg_leptonica/retrieve.py/2023-10-01_08.36.52/logs/ 


[Oct 01, 08:36:54] {'root': 'run/retrieve_output', 'experiment': 'DanBloomberg_leptonica', 'run': '2023-10-01_08.36.52', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/DanBloomberg_leptonica.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/DanBloomberg_leptonica', 'index_name': 'DanBloomberg_leptonica', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:37:05] #> Loading model checkpoint.
[Oct 01, 08:37:05] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:37:06] #> checkpoint['epoch'] = 0
[Oct 01, 08:37:06] #> checkpoint['batch'] = 346000
[Oct 01, 08:37:06] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:37:06] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/DanBloomberg_leptonica.tsv ...
[Oct 01, 08:37:06] #> Got 6 queries. All QIDs are unique.

[Oct 01, 08:37:08] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/DanBloomberg_leptonica/DanBloomberg_leptonica/ivfpq.70.faiss ..
[Oct 01, 08:37:08] #> Building the emb2pid mapping..
[Oct 01, 08:37:08] len(self.emb2pid) = 2051437
[Oct 01, 08:37:09] tensor.size() =  torch.Size([2051949, 128])
[Oct 01, 08:37:09] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/DanBloomberg_leptonica/DanBloomberg_leptonica/0.pt ...
[Oct 01, 08:37:09] #> Using strides [331, 404]..
[Oct 01, 08:37:12] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/DanBloomberg_leptonica/retrieve.py/2023-10-01_08.36.52/ranking.tsv
0 Leptonica before 1.80.0 allows a heap-based buffer over-read in rasteropGeneralLow , related to adaptmap_reg.c and adaptmap.c . 222 222 30.44910430908203 1523 1083.1327438354492 ms
1 Leptonica before 1.80.0 allows a heap-based buffer over-read in findNextBorderPixel in ccbord.c . 336 336 30.16832733154297 9141 609.4481945037842 ms
2 Leptonica before 1.75.3 does not limit the number of characters in a % s format argument to fscanf or sscanf , which allows remote attackers to cause a denial of service ( stack-based buffer overflow ) or possibly have unspecified other impact via a long string , as demonstrated by the gplotRead and ptaReadStream functions . 306 306 30.576622009277344 9139 453.2455603281657 ms
3 Leptonica before 1.80.0 allows a heap-based buffer over-read in pixFewColorsOctcubeQuantMixed in colorquant1.c . 246 246 30.118871688842773 9143 371.80793285369873 ms
4 Leptonica before 1.80.0 allows a heap-based buffer over-read in pixReadFromTiffStream , related to tiffio.c . 228 228 30.72096824645996 9142 319.9425220489502 ms
5 An issue was discovered in pixHtmlViewer in prog/htmlviewer.c in Leptonica before 1.75.3 . Unsanitized input ( rootname ) can overflow a buffer , leading potentially to arbitrary code execution or possibly unspecified other impact . 294 294 30.243999481201172 9140 285.49567858378094 ms
[Oct 01, 08:37:14] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/DanBloomberg_leptonica/retrieve.py/2023-10-01_08.36.52/ranking.tsv
#> Done.




2023-10-01 08:37:16,694 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:37:16,695 INFO rerun retrieving Ettercap_ettercap
2023-10-01 08:37:42,532 INFO 

[Oct 01, 08:37:18] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Ettercap_ettercap/retrieve.py/2023-10-01_08.37.18 




[Oct 01, 08:37:20] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Ettercap_ettercap/retrieve.py/2023-10-01_08.37.18/logs/ 


[Oct 01, 08:37:20] {'root': 'run/retrieve_output', 'experiment': 'Ettercap_ettercap', 'run': '2023-10-01_08.37.18', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/Ettercap_ettercap.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/Ettercap_ettercap', 'index_name': 'Ettercap_ettercap', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:37:31] #> Loading model checkpoint.
[Oct 01, 08:37:31] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:37:32] #> checkpoint['epoch'] = 0
[Oct 01, 08:37:32] #> checkpoint['batch'] = 346000
[Oct 01, 08:37:32] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:37:32] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/Ettercap_ettercap.tsv ...
[Oct 01, 08:37:32] #> Got 3 queries. All QIDs are unique.

[Oct 01, 08:37:34] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/Ettercap_ettercap/Ettercap_ettercap/ivfpq.70.faiss ..
[Oct 01, 08:37:34] #> Building the emb2pid mapping..
[Oct 01, 08:37:34] len(self.emb2pid) = 1942977
[Oct 01, 08:37:35] tensor.size() =  torch.Size([1943489, 128])
[Oct 01, 08:37:35] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/Ettercap_ettercap/Ettercap_ettercap/0.pt ...
[Oct 01, 08:37:35] #> Using strides [305, 464]..
[Oct 01, 08:37:38] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Ettercap_ettercap/retrieve.py/2023-10-01_08.37.18/ranking.tsv
0 An unchecked sscanf ( ) call in ettercap before 0.7.5 allows an insecure temporary settings file to overflow a static-sized buffer on the stack . 267 267 28.62824058532715 6198 1132.5929164886475 ms
1 Heap-based buffer overflow in the dissector_postgresql function in dissectors/ec_postgresql.c in Ettercap before 0.8.1 allows remote attackers to cause a denial of service or possibly execute arbitrary code via a crafted password length value that is inconsistent with the actual length of the password . 306 306 29.327476501464844 9299 627.7104616165161 ms
2 The dissector_postgresql function in dissectors/ec_postgresql.c in Ettercap before 0.8.1 allows remote attackers to cause a denial of service and possibly execute arbitrary code via a crafted password length , which triggers a 0 character to be written to an arbitrary memory location . 324 324 29.07990837097168 9299 459.73777770996094 ms
[Oct 01, 08:37:39] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Ettercap_ettercap/retrieve.py/2023-10-01_08.37.18/ranking.tsv
#> Done.




2023-10-01 08:37:42,532 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:37:42,533 INFO rerun retrieving AntonKueltz_fastecdsa
2023-10-01 08:38:07,053 INFO 

[Oct 01, 08:37:44] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AntonKueltz_fastecdsa/retrieve.py/2023-10-01_08.37.44 




[Oct 01, 08:37:46] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AntonKueltz_fastecdsa/retrieve.py/2023-10-01_08.37.44/logs/ 


[Oct 01, 08:37:46] {'root': 'run/retrieve_output', 'experiment': 'AntonKueltz_fastecdsa', 'run': '2023-10-01_08.37.44', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/AntonKueltz_fastecdsa.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/AntonKueltz_fastecdsa', 'index_name': 'AntonKueltz_fastecdsa', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:37:56] #> Loading model checkpoint.
[Oct 01, 08:37:56] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:37:57] #> checkpoint['epoch'] = 0
[Oct 01, 08:37:57] #> checkpoint['batch'] = 346000
[Oct 01, 08:37:57] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:37:57] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/AntonKueltz_fastecdsa.tsv ...
[Oct 01, 08:37:57] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:38:00] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/AntonKueltz_fastecdsa/AntonKueltz_fastecdsa/ivfpq.70.faiss ..
[Oct 01, 08:38:00] #> Building the emb2pid mapping..
[Oct 01, 08:38:00] len(self.emb2pid) = 59044
[Oct 01, 08:38:00] tensor.size() =  torch.Size([59556, 128])
[Oct 01, 08:38:00] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/AntonKueltz_fastecdsa/AntonKueltz_fastecdsa/0.pt ...
[Oct 01, 08:38:00] #> Using strides [324, 474]..
[Oct 01, 08:38:03] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AntonKueltz_fastecdsa/retrieve.py/2023-10-01_08.37.44/ranking.tsv
0 An issue was discovered in fastecdsa before 2.1.2 . When using the NIST P-256 curve in the ECDSA implementation , the point at infinity is mishandled . This means that for an extreme value in k and s^-1 , the signature verification fails even if the signature is correct . This behavior is not solely a usability problem . There are some threat models where an attacker can benefit by successfully guessing users for whom signature verification will fail . 61 61 22.87002182006836 313 997.6663589477539 ms
[Oct 01, 08:38:04] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/AntonKueltz_fastecdsa/retrieve.py/2023-10-01_08.37.44/ranking.tsv
#> Done.




2023-10-01 08:38:07,053 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:38:07,054 INFO rerun retrieving FransUrbo_zfs
2023-10-01 08:38:32,390 INFO 

[Oct 01, 08:38:09] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FransUrbo_zfs/retrieve.py/2023-10-01_08.38.08 




[Oct 01, 08:38:10] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FransUrbo_zfs/retrieve.py/2023-10-01_08.38.08/logs/ 


[Oct 01, 08:38:11] {'root': 'run/retrieve_output', 'experiment': 'FransUrbo_zfs', 'run': '2023-10-01_08.38.08', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/FransUrbo_zfs.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/FransUrbo_zfs', 'index_name': 'FransUrbo_zfs', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:38:21] #> Loading model checkpoint.
[Oct 01, 08:38:21] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:38:22] #> checkpoint['epoch'] = 0
[Oct 01, 08:38:22] #> checkpoint['batch'] = 346000
[Oct 01, 08:38:22] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:38:22] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/FransUrbo_zfs.tsv ...
[Oct 01, 08:38:22] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:38:24] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/FransUrbo_zfs/FransUrbo_zfs/ivfpq.70.faiss ..
[Oct 01, 08:38:25] #> Building the emb2pid mapping..
[Oct 01, 08:38:25] len(self.emb2pid) = 884174
[Oct 01, 08:38:25] tensor.size() =  torch.Size([884686, 128])
[Oct 01, 08:38:25] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/FransUrbo_zfs/FransUrbo_zfs/0.pt ...
[Oct 01, 08:38:26] #> Using strides [363, 467]..
[Oct 01, 08:38:28] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FransUrbo_zfs/retrieve.py/2023-10-01_08.38.08/ranking.tsv
0 sharenfs 0.6.4 , when built with commits bcdd594 and 7d08880 from the zfs repository , provides world readable access to the shared zfs file system , which might allow remote authenticated users to obtain sensitive information by reading shared files . 118 118 25.535430908203125 3157 1063.6613368988037 ms
[Oct 01, 08:38:29] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FransUrbo_zfs/retrieve.py/2023-10-01_08.38.08/ranking.tsv
#> Done.




2023-10-01 08:38:32,390 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:38:32,391 INFO rerun retrieving FreeRADIUS_freeradius-server
2023-10-01 08:39:00,356 INFO 

[Oct 01, 08:38:34] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FreeRADIUS_freeradius-server/retrieve.py/2023-10-01_08.38.34 




[Oct 01, 08:38:36] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FreeRADIUS_freeradius-server/retrieve.py/2023-10-01_08.38.34/logs/ 


[Oct 01, 08:38:36] {'root': 'run/retrieve_output', 'experiment': 'FreeRADIUS_freeradius-server', 'run': '2023-10-01_08.38.34', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/FreeRADIUS_freeradius-server.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/FreeRADIUS_freeradius-server', 'index_name': 'FreeRADIUS_freeradius-server', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:38:50] #> Loading model checkpoint.
[Oct 01, 08:38:50] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:38:50] #> checkpoint['epoch'] = 0
[Oct 01, 08:38:50] #> checkpoint['batch'] = 346000
[Oct 01, 08:38:50] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:38:50] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/FreeRADIUS_freeradius-server.tsv ...
[Oct 01, 08:38:50] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:38:53] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/FreeRADIUS_freeradius-server/FreeRADIUS_freeradius-server/ivfpq.70.faiss ..
[Oct 01, 08:38:53] #> Building the emb2pid mapping..
[Oct 01, 08:38:53] len(self.emb2pid) = 938877
[Oct 01, 08:38:53] tensor.size() =  torch.Size([939389, 128])
[Oct 01, 08:38:53] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/FreeRADIUS_freeradius-server/FreeRADIUS_freeradius-server/0.pt ...
[Oct 01, 08:38:54] #> Using strides [297, 422]..
[Oct 01, 08:38:56] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FreeRADIUS_freeradius-server/retrieve.py/2023-10-01_08.38.34/ranking.tsv
0 In FreeRADIUS 3.0 through 3.0.19 , on average 1 in every 2048 EAP-pwd handshakes fails because the password element can not be found within 10 iterations of the hunting and pecking loop . This leaks information that an attacker can use to recover the password of any user . This information leakage is similar to the `` Dragonblood '' attack and CVE-2019-9494 . 79 79 30.07427978515625 5000 1005.2187442779541 ms
[Oct 01, 08:38:57] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/FreeRADIUS_freeradius-server/retrieve.py/2023-10-01_08.38.34/ranking.tsv
#> Done.




2023-10-01 08:39:00,356 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:39:00,357 INFO rerun retrieving LibreDWG_libredwg
2023-10-01 08:39:29,350 INFO 

[Oct 01, 08:39:02] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/LibreDWG_libredwg/retrieve.py/2023-10-01_08.39.02 




[Oct 01, 08:39:04] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/LibreDWG_libredwg/retrieve.py/2023-10-01_08.39.02/logs/ 


[Oct 01, 08:39:04] {'root': 'run/retrieve_output', 'experiment': 'LibreDWG_libredwg', 'run': '2023-10-01_08.39.02', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/LibreDWG_libredwg.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/LibreDWG_libredwg', 'index_name': 'LibreDWG_libredwg', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:39:15] #> Loading model checkpoint.
[Oct 01, 08:39:15] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:39:16] #> checkpoint['epoch'] = 0
[Oct 01, 08:39:16] #> checkpoint['batch'] = 346000
[Oct 01, 08:39:16] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:39:16] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/LibreDWG_libredwg.tsv ...
[Oct 01, 08:39:16] #> Got 6 queries. All QIDs are unique.

[Oct 01, 08:39:18] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/LibreDWG_libredwg/LibreDWG_libredwg/ivfpq.70.faiss ..
[Oct 01, 08:39:18] #> Building the emb2pid mapping..
[Oct 01, 08:39:18] len(self.emb2pid) = 6845505
[Oct 01, 08:39:19] tensor.size() =  torch.Size([6846017, 128])
[Oct 01, 08:39:19] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/LibreDWG_libredwg/LibreDWG_libredwg/0.pt ...
[Oct 01, 08:39:21] #> Using strides [309, 419]..
[Oct 01, 08:39:24] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/LibreDWG_libredwg/retrieve.py/2023-10-01_08.39.02/ranking.tsv
0 An issue was discovered in GNU LibreDWG through 0.9.3 . There is a NULL pointer dereference in the function dwg_encode_LWPOLYLINE in dwg.spec . 132 132 29.975173950195312 5000 1256.1793327331543 ms
1 An issue was discovered in GNU LibreDWG through 0.9.3 . Crafted input will lead to a heap-based buffer over-read in bit_write_TF in bits.c . 126 126 30.200786590576172 5000 768.6963081359863 ms
2 An issue was discovered in GNU LibreDWG through 0.9.3 . Crafted input will lead to a stack overflow in bits.c , possibly related to bit_read_TF . 132 132 30.21286392211914 5000 604.8806508382162 ms
3 An issue was discovered in GNU LibreDWG through 0.9.3 . There is a NULL pointer dereference in the function dwg_encode_common_entity_handle_data in common_entity_handle_data.spec . 132 132 29.975173950195312 5000 529.5298099517822 ms
4 GNU LibreDWG 0.12.3.4163 through 0.12.3.4191 has a double-free in bit_chain_free ( called from dwg_encode_MTEXT and dwg_encode_add_object ) . 120 120 30.163677215576172 5000 480.2149772644043 ms
5 An issue was discovered in GNU LibreDWG through 0.9.3 . Crafted input will lead to denial of service in bit_calc_CRC in bits.c , related to a for loop . 132 132 30.017776489257812 5000 445.6140200297038 ms
[Oct 01, 08:39:26] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/LibreDWG_libredwg/retrieve.py/2023-10-01_08.39.02/ranking.tsv
#> Done.




2023-10-01 08:39:29,350 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:39:29,351 INFO rerun retrieving OSGeo_gdal
2023-10-01 08:39:56,645 INFO 

[Oct 01, 08:39:31] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OSGeo_gdal/retrieve.py/2023-10-01_08.39.30 




[Oct 01, 08:39:32] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OSGeo_gdal/retrieve.py/2023-10-01_08.39.30/logs/ 


[Oct 01, 08:39:33] {'root': 'run/retrieve_output', 'experiment': 'OSGeo_gdal', 'run': '2023-10-01_08.39.30', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/OSGeo_gdal.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/OSGeo_gdal', 'index_name': 'OSGeo_gdal', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:39:44] #> Loading model checkpoint.
[Oct 01, 08:39:44] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:39:44] #> checkpoint['epoch'] = 0
[Oct 01, 08:39:44] #> checkpoint['batch'] = 346000
[Oct 01, 08:39:44] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:39:44] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/OSGeo_gdal.tsv ...
[Oct 01, 08:39:44] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:39:47] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/OSGeo_gdal/OSGeo_gdal/ivfpq.70.faiss ..
[Oct 01, 08:39:47] #> Building the emb2pid mapping..
[Oct 01, 08:39:47] len(self.emb2pid) = 4483083
[Oct 01, 08:39:48] tensor.size() =  torch.Size([4483595, 128])
[Oct 01, 08:39:48] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/OSGeo_gdal/OSGeo_gdal/0.pt ...
[Oct 01, 08:39:49] #> Using strides [335, 414]..
[Oct 01, 08:39:52] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OSGeo_gdal/retrieve.py/2023-10-01_08.39.30/ranking.tsv
0 GDAL 3.3.0 through 3.4.0 has a heap-based buffer overflow in PCIDSK : :CPCIDSKFile : :ReadFromFile ( called from PCIDSK : :CPCIDSKSegment : :ReadFromFile and PCIDSK : :CPCIDSKBinarySegment : :CPCIDSKBinarySegment ) . 84 84 31.193988800048828 20003 1178.0328750610352 ms
1 GDAL through 3.0.1 has a poolDestroy double free in OGRExpatRealloc in ogr/ogr_expat.cpp when the 10MB threshold is exceeded . 84 84 30.445981979370117 20000 705.0453424453735 ms
2 tif_getimage.c in LibTIFF through 4.0.10 , as used in GDAL through 3.0.1 and other products , has an integer overflow that potentially causes a heap-based buffer overflow via a crafted RGBA image , related to a `` Negative-size-param '' condition . 84 84 30.967914581298828 20001 546.5848445892334 ms
3 netCDF in GDAL 2.4.2 through 3.0.4 has a stack-based buffer overflow in nc4_get_att ( called from nc4_get_att_tc and nc_get_att_text ) and in uffd_cleanup ( called from netCDFDataset : :~netCDFDataset and netCDFDataset : :~netCDFDataset ) . 84 84 31.226015090942383 20002 460.0525498390198 ms
[Oct 01, 08:39:54] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OSGeo_gdal/retrieve.py/2023-10-01_08.39.30/ranking.tsv
#> Done.




2023-10-01 08:39:56,645 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:39:56,646 INFO rerun retrieving OpenRC_openrc
2023-10-01 08:40:21,926 INFO 

[Oct 01, 08:39:58] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenRC_openrc/retrieve.py/2023-10-01_08.39.58 




[Oct 01, 08:40:00] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenRC_openrc/retrieve.py/2023-10-01_08.39.58/logs/ 


[Oct 01, 08:40:00] {'root': 'run/retrieve_output', 'experiment': 'OpenRC_openrc', 'run': '2023-10-01_08.39.58', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/OpenRC_openrc.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/OpenRC_openrc', 'index_name': 'OpenRC_openrc', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:40:11] #> Loading model checkpoint.
[Oct 01, 08:40:11] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:40:12] #> checkpoint['epoch'] = 0
[Oct 01, 08:40:12] #> checkpoint['batch'] = 346000
[Oct 01, 08:40:12] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:40:12] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/OpenRC_openrc.tsv ...
[Oct 01, 08:40:12] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:40:14] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/OpenRC_openrc/OpenRC_openrc/ivfpq.70.faiss ..
[Oct 01, 08:40:14] #> Building the emb2pid mapping..
[Oct 01, 08:40:14] len(self.emb2pid) = 586028
[Oct 01, 08:40:16] tensor.size() =  torch.Size([586540, 128])
[Oct 01, 08:40:16] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/OpenRC_openrc/OpenRC_openrc/0.pt ...
[Oct 01, 08:40:16] #> Using strides [300, 389]..
[Oct 01, 08:40:18] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenRC_openrc/retrieve.py/2023-10-01_08.39.58/ranking.tsv
0 checkpath in OpenRC before 0.44.7 uses the direct output of strlen ( ) to allocate strings , which does not account for the '\0 ' byte at the end of the string . This results in memory corruption . CVE-2021-42341 was introduced in git commit 63db2d99e730547339d1bdd28e8437999c380cae , which was introduced as part of OpenRC 0.44.0 development . 820 820 30.71072769165039 3444 966.254472732544 ms
[Oct 01, 08:40:19] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenRC_openrc/retrieve.py/2023-10-01_08.39.58/ranking.tsv
#> Done.




2023-10-01 08:40:21,926 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:40:21,927 INFO rerun retrieving OpenSC_OpenSC
2023-10-01 08:41:26,563 INFO 

[Oct 01, 08:40:24] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenSC_OpenSC/retrieve.py/2023-10-01_08.40.23 




[Oct 01, 08:40:25] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenSC_OpenSC/retrieve.py/2023-10-01_08.40.23/logs/ 


[Oct 01, 08:40:26] {'root': 'run/retrieve_output', 'experiment': 'OpenSC_OpenSC', 'run': '2023-10-01_08.40.23', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/OpenSC_OpenSC.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/OpenSC_OpenSC', 'index_name': 'OpenSC_OpenSC', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:40:37] #> Loading model checkpoint.
[Oct 01, 08:40:37] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:40:38] #> checkpoint['epoch'] = 0
[Oct 01, 08:40:38] #> checkpoint['batch'] = 346000
[Oct 01, 08:40:38] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:40:38] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/OpenSC_OpenSC.tsv ...
[Oct 01, 08:40:38] #> Got 25 queries. All QIDs are unique.

[Oct 01, 08:40:40] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/OpenSC_OpenSC/OpenSC_OpenSC/ivfpq.70.faiss ..
[Oct 01, 08:40:41] #> Building the emb2pid mapping..
[Oct 01, 08:40:41] len(self.emb2pid) = 26544040
[Oct 01, 08:40:43] tensor.size() =  torch.Size([26544552, 128])
[Oct 01, 08:40:43] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/OpenSC_OpenSC/OpenSC_OpenSC/0.pt ...
[Oct 01, 08:40:46] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/OpenSC_OpenSC/OpenSC_OpenSC/1.pt ...
[Oct 01, 08:40:48] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/OpenSC_OpenSC/OpenSC_OpenSC/2.pt ...
[Oct 01, 08:40:50] #> Using strides [317, 426]..
[Oct 01, 08:40:52] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenSC_OpenSC/retrieve.py/2023-10-01_08.40.23/ranking.tsv
0 A buffer overflow when handling string concatenation in util_acl_to_str in tools/util.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 150 150 29.38446044921875 105020 2163.301467895508 ms
1 A double free when handling responses in read_file in tools/egk-tool.c ( aka the eGK card tool ) in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 200 200 29.471145629882812 105015 1670.536994934082 ms
2 Endless recursion when handling responses from an IAS-ECC card in iasecc_select_file in libopensc/card-iasecc.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to hang or crash the opensc library using programs . 250 250 30.107925415039062 105020 1514.4484043121338 ms
3 Heap buffer overflow issues were found in Opensc before version 0.22.0 in pkcs15-oberthur.c that could potentially crash programs using the library . 100 100 31.232257843017578 105015 1432.0918917655945 ms
4 OpenSC before 0.20.0-rc1 has an out-of-bounds access of an ASN.1 Octet string in asn1_decode_entry in libopensc/asn1.c . 75 75 30.260400772094727 105012 1384.1046810150146 ms
5 Stack buffer overflow issues were found in Opensc before version 0.22.0 in various places that could potentially crash programs using the library . 50 50 31.089521408081055 105015 1358.2077423731487 ms
6 OpenSC before 0.20.0-rc1 has an out-of-bounds access of an ASN.1 Bitstring in decode_bit_string in libopensc/asn1.c . 75 75 30.29996109008789 10001 1331.836496080671 ms
7 A heap double free issue was found in Opensc before version 0.22.0 in sc_pkcs15_free_tokeninfo . 150 150 30.688732147216797 105015 1314.806878566742 ms
8 An issue was discovered in OpenSC through 0.19.0 and 0.20.x through 0.20.0-rc3 . libopensc/pkcs15-prkey.c has an incorrect free operation in sc_pkcs15_decode_prkdf_entry . 50 50 30.89885139465332 105018 1299.2736498514812 ms
9 The TCOS smart card software driver in OpenSC before 0.21.0-rc1 has a stack-based buffer overflow in tcos_decipher . 50 50 30.68683433532715 105018 1288.7558460235596 ms
10 An issue was discovered in OpenSC through 0.19.0 and 0.20.x through 0.20.0-rc3 . libopensc/card-setcos.c has an incorrect read operation during parsing of a SETCOS file attribute . 50 50 30.89885139465332 105018 1276.976542039351 ms
11 Several buffer overflows when handling responses from a Gemsafe V1 Smartcard in gemsafe_get_cert_len in libopensc/pkcs15-gemsafeV1.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 125 125 29.20328140258789 125022 1268.6551014582317 ms
12 Several buffer overflows when handling responses from a CAC Card in cac_get_serial_nr_from_CUID in libopensc/card-cac.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 175 175 30.553733825683594 125022 1262.1262623713567 ms
13 OpenSC before 0.20.0 has a double free in coolkey_free_private_data because coolkey_add_object in libopensc/card-coolkey.c lacks a uniqueness check . 175 175 30.20412826538086 125023 1258.3751848765783 ms
14 A single byte buffer overflow when handling responses from an esteid Card in sc_pkcs15emu_esteid_init in libopensc/pkcs15-esteid.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 225 225 29.778167724609375 125024 1252.8196334838867 ms
15 Several buffer overflows when handling responses from a TCOS Card in tcos_select_file in libopensc/card-tcos.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 200 200 30.380619049072266 105018 1248.9687502384186 ms
16 A double free when handling responses from an HSM Card in sc_pkcs15emu_sc_hsm_init in libopensc/pkcs15-sc-hsm.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 225 225 29.50848388671875 125024 1245.3522682189941 ms
17 Several buffer overflows when handling responses from a Cryptoflex card in read_public_key in tools/cryptoflex-tool.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 100 100 29.246910095214844 105015 1242.6863378948635 ms
18 The Oberthur smart card software driver in OpenSC before 0.21.0-rc1 has a heap-based buffer overflow in sc_oberthur_read_file . 75 75 30.89453125 105015 1242.5576887632672 ms
19 A use after return issue was found in Opensc before version 0.22.0 in insert_pin function that could potentially crash programs using the library . 50 50 30.9068603515625 105018 1243.5029983520508 ms
20 A double free when handling responses from a smartcard in sc_file_set_sec_attr in libopensc/sc.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 200 200 30.32990264892578 105012 1241.8797356741768 ms
21 Several buffer overflows when handling responses from a Muscle Card in muscle_list_files in libopensc/card-muscle.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 225 225 30.571651458740234 125021 1243.0512363260443 ms
22 A heap use after free issue was found in Opensc before version 0.22.0 in sc_file_valid . 75 75 30.926652908325195 105015 1242.2388221906579 ms
23 Several buffer overflows when handling responses from an ePass 2003 Card in decrypt_response in libopensc/card-epass2003.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to cause a denial of service ( application crash ) or possibly have unspecified other impact . 225 225 30.58056640625 125021 1240.2303020159404 ms
24 An issue was discovered in OpenSC through 0.19.0 and 0.20.x through 0.20.0-rc3 . libopensc/card-cac1.c mishandles buffer limits for CAC certificates . 50 50 30.89885139465332 105018 1237.250862121582 ms
[Oct 01, 08:41:23] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/OpenSC_OpenSC/retrieve.py/2023-10-01_08.40.23/ranking.tsv
#> Done.




2023-10-01 08:41:26,564 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:41:26,564 INFO rerun retrieving PCRE2Project_pcre2
2023-10-01 08:41:52,015 INFO 

[Oct 01, 08:41:28] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/PCRE2Project_pcre2/retrieve.py/2023-10-01_08.41.28 




[Oct 01, 08:41:30] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/PCRE2Project_pcre2/retrieve.py/2023-10-01_08.41.28/logs/ 


[Oct 01, 08:41:30] {'root': 'run/retrieve_output', 'experiment': 'PCRE2Project_pcre2', 'run': '2023-10-01_08.41.28', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/PCRE2Project_pcre2.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/PCRE2Project_pcre2', 'index_name': 'PCRE2Project_pcre2', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:41:41] #> Loading model checkpoint.
[Oct 01, 08:41:41] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:41:42] #> checkpoint['epoch'] = 0
[Oct 01, 08:41:42] #> checkpoint['batch'] = 346000
[Oct 01, 08:41:42] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:41:42] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/PCRE2Project_pcre2.tsv ...
[Oct 01, 08:41:42] #> Got 2 queries. All QIDs are unique.

[Oct 01, 08:41:44] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/PCRE2Project_pcre2/PCRE2Project_pcre2/ivfpq.70.faiss ..
[Oct 01, 08:41:44] #> Building the emb2pid mapping..
[Oct 01, 08:41:44] len(self.emb2pid) = 783023
[Oct 01, 08:41:46] tensor.size() =  torch.Size([783535, 128])
[Oct 01, 08:41:46] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/PCRE2Project_pcre2/PCRE2Project_pcre2/0.pt ...
[Oct 01, 08:41:46] #> Using strides [348, 394]..
[Oct 01, 08:41:48] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/PCRE2Project_pcre2/retrieve.py/2023-10-01_08.41.28/ranking.tsv
0 An out-of-bounds read vulnerability was discovered in the PCRE2 library in the compile_xclass_matchingpath ( ) function of the pcre2_jit_compile.c file . This involves a unicode property matching issue in JIT-compiled regular expressions . The issue occurs because the character was not fully read in case-less matching within JIT . 1254 1254 27.218738555908203 2977 938.0621910095215 ms
1 An out-of-bounds read vulnerability was discovered in the PCRE2 library in the get_recurse_data_length ( ) function of the pcre2_jit_compile.c file . This issue affects recursions in JIT-compiled regular expressions caused by duplicate data transfers . 1061 1061 26.816150665283203 1488 518.7503099441528 ms
[Oct 01, 08:41:49] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/PCRE2Project_pcre2/retrieve.py/2023-10-01_08.41.28/ranking.tsv
#> Done.




2023-10-01 08:41:52,016 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:41:52,016 INFO rerun retrieving SELinuxProject_selinux
2023-10-01 08:42:18,949 INFO 

[Oct 01, 08:41:54] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/SELinuxProject_selinux/retrieve.py/2023-10-01_08.41.53 




[Oct 01, 08:41:55] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/SELinuxProject_selinux/retrieve.py/2023-10-01_08.41.53/logs/ 


[Oct 01, 08:41:56] {'root': 'run/retrieve_output', 'experiment': 'SELinuxProject_selinux', 'run': '2023-10-01_08.41.53', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/SELinuxProject_selinux.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/SELinuxProject_selinux', 'index_name': 'SELinuxProject_selinux', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:42:06] #> Loading model checkpoint.
[Oct 01, 08:42:06] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:42:07] #> checkpoint['epoch'] = 0
[Oct 01, 08:42:07] #> checkpoint['batch'] = 346000
[Oct 01, 08:42:07] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:42:07] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/SELinuxProject_selinux.tsv ...
[Oct 01, 08:42:07] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:42:10] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/SELinuxProject_selinux/SELinuxProject_selinux/ivfpq.70.faiss ..
[Oct 01, 08:42:10] #> Building the emb2pid mapping..
[Oct 01, 08:42:10] len(self.emb2pid) = 3214231
[Oct 01, 08:42:11] tensor.size() =  torch.Size([3214743, 128])
[Oct 01, 08:42:11] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/SELinuxProject_selinux/SELinuxProject_selinux/0.pt ...
[Oct 01, 08:42:12] #> Using strides [340, 423]..
[Oct 01, 08:42:14] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/SELinuxProject_selinux/retrieve.py/2023-10-01_08.41.53/ranking.tsv
0 The CIL compiler in SELinux 3.2 has a use-after-free in cil_reset_classpermission ( called from cil_reset_classperms_set and cil_reset_classperms_list ) . 12 12 30.806325912475586 13788 1113.157033920288 ms
1 The CIL compiler in SELinux 3.2 has a use-after-free in __cil_verify_classperms ( called from __cil_verify_classpermission and __cil_pre_verify_helper ) . 12 12 30.750816345214844 13788 632.3318481445312 ms
2 The CIL compiler in SELinux 3.2 has a heap-based buffer over-read in ebitmap_match_any ( called indirectly from cil_check_neverallow ) . This occurs because there is sometimes a lack of checks for invalid statements in an optional block . 12 12 30.03427505493164 13788 467.25066502888996 ms
3 The CIL compiler in SELinux 3.2 has a use-after-free in __cil_verify_classperms ( called from __verify_map_perm_classperms and hashtab_map ) . 12 12 30.750816345214844 13788 383.31884145736694 ms
[Oct 01, 08:42:16] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/SELinuxProject_selinux/retrieve.py/2023-10-01_08.41.53/ranking.tsv
#> Done.




2023-10-01 08:42:18,950 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:42:18,950 INFO rerun retrieving Uninett_mod_auth_mellon
2023-10-01 08:42:42,688 INFO 

[Oct 01, 08:42:21] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Uninett_mod_auth_mellon/retrieve.py/2023-10-01_08.42.20 




[Oct 01, 08:42:22] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Uninett_mod_auth_mellon/retrieve.py/2023-10-01_08.42.20/logs/ 


[Oct 01, 08:42:23] {'root': 'run/retrieve_output', 'experiment': 'Uninett_mod_auth_mellon', 'run': '2023-10-01_08.42.20', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/Uninett_mod_auth_mellon.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/Uninett_mod_auth_mellon', 'index_name': 'Uninett_mod_auth_mellon', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:42:33] #> Loading model checkpoint.
[Oct 01, 08:42:33] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:42:34] #> checkpoint['epoch'] = 0
[Oct 01, 08:42:34] #> checkpoint['batch'] = 346000
[Oct 01, 08:42:34] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:42:34] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/Uninett_mod_auth_mellon.tsv ...
[Oct 01, 08:42:34] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:42:36] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/Uninett_mod_auth_mellon/Uninett_mod_auth_mellon/ivfpq.70.faiss ..
[Oct 01, 08:42:36] #> Building the emb2pid mapping..
[Oct 01, 08:42:36] len(self.emb2pid) = 721
[Oct 01, 08:42:37] tensor.size() =  torch.Size([1233, 128])
[Oct 01, 08:42:37] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/Uninett_mod_auth_mellon/Uninett_mod_auth_mellon/0.pt ...
[Oct 01, 08:42:37] #> Using strides [224, 312]..
[Oct 01, 08:42:39] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Uninett_mod_auth_mellon/retrieve.py/2023-10-01_08.42.20/ranking.tsv
0 A vulnerability was found in mod_auth_mellon before v0.14.2 . An open redirect in the logout URL allows requests with backslashes to pass through by assuming that it is a relative URL , while the browsers silently convert backslash characters into forward slashes treating them as an absolute URL . This mismatch allows an attacker to bypass the redirect URL validation logic in apr_uri_parse function . 4 4 30.687515258789062 3 950.8702754974365 ms
[Oct 01, 08:42:40] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Uninett_mod_auth_mellon/retrieve.py/2023-10-01_08.42.20/ranking.tsv
#> Done.




2023-10-01 08:42:42,689 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:42:42,690 INFO rerun retrieving Yubico_libu2f-host
2023-10-01 08:43:07,603 INFO 

[Oct 01, 08:42:44] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Yubico_libu2f-host/retrieve.py/2023-10-01_08.42.44 




[Oct 01, 08:42:46] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Yubico_libu2f-host/retrieve.py/2023-10-01_08.42.44/logs/ 


[Oct 01, 08:42:47] {'root': 'run/retrieve_output', 'experiment': 'Yubico_libu2f-host', 'run': '2023-10-01_08.42.44', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/Yubico_libu2f-host.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/Yubico_libu2f-host', 'index_name': 'Yubico_libu2f-host', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:42:57] #> Loading model checkpoint.
[Oct 01, 08:42:57] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:42:58] #> checkpoint['epoch'] = 0
[Oct 01, 08:42:58] #> checkpoint['batch'] = 346000
[Oct 01, 08:42:58] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:42:58] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/Yubico_libu2f-host.tsv ...
[Oct 01, 08:42:58] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:43:00] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/Yubico_libu2f-host/Yubico_libu2f-host/ivfpq.70.faiss ..
[Oct 01, 08:43:00] #> Building the emb2pid mapping..
[Oct 01, 08:43:00] len(self.emb2pid) = 37200
[Oct 01, 08:43:01] tensor.size() =  torch.Size([37712, 128])
[Oct 01, 08:43:01] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/Yubico_libu2f-host/Yubico_libu2f-host/0.pt ...
[Oct 01, 08:43:01] #> Using strides [266, 367]..
[Oct 01, 08:43:04] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Yubico_libu2f-host/retrieve.py/2023-10-01_08.42.44/ranking.tsv
0 In devs.c in Yubico libu2f-host before 1.1.8 , the response to init is misparsed , leaking uninitialized stack memory back to the device . 19 19 20.596172332763672 303 955.5001258850098 ms
[Oct 01, 08:43:04] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/Yubico_libu2f-host/retrieve.py/2023-10-01_08.42.44/ranking.tsv
#> Done.




2023-10-01 08:43:07,604 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:43:07,605 INFO rerun retrieving bitlbee_bitlbee
2023-10-01 08:43:36,693 INFO 

[Oct 01, 08:43:09] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bitlbee_bitlbee/retrieve.py/2023-10-01_08.43.09 




[Oct 01, 08:43:11] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bitlbee_bitlbee/retrieve.py/2023-10-01_08.43.09/logs/ 


[Oct 01, 08:43:12] {'root': 'run/retrieve_output', 'experiment': 'bitlbee_bitlbee', 'run': '2023-10-01_08.43.09', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/bitlbee_bitlbee.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/bitlbee_bitlbee', 'index_name': 'bitlbee_bitlbee', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:43:22] #> Loading model checkpoint.
[Oct 01, 08:43:22] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:43:23] #> checkpoint['epoch'] = 0
[Oct 01, 08:43:23] #> checkpoint['batch'] = 346000
[Oct 01, 08:43:23] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:43:23] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/bitlbee_bitlbee.tsv ...
[Oct 01, 08:43:23] #> Got 2 queries. All QIDs are unique.

[Oct 01, 08:43:29] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/bitlbee_bitlbee/bitlbee_bitlbee/ivfpq.70.faiss ..
[Oct 01, 08:43:29] #> Building the emb2pid mapping..
[Oct 01, 08:43:29] len(self.emb2pid) = 1306052
[Oct 01, 08:43:29] tensor.size() =  torch.Size([1306564, 128])
[Oct 01, 08:43:29] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/bitlbee_bitlbee/bitlbee_bitlbee/0.pt ...
[Oct 01, 08:43:30] #> Using strides [299, 414]..
[Oct 01, 08:43:32] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bitlbee_bitlbee/retrieve.py/2023-10-01_08.43.09/ranking.tsv
0 BitlBee before 3.5 allows remote attackers to cause a denial of service ( NULL pointer dereference and crash ) and possibly execute arbitrary code via a file transfer request for a contact that is not in the contact list . 42 42 29.7655086517334 6943 1070.7030296325684 ms
1 bitlbee-libpurple before 3.5.1 allows remote attackers to cause a denial of service ( NULL pointer dereference and crash ) and possibly execute arbitrary code via a file transfer request for a contact that is not in the contact list . NOTE : this vulnerability exists because of an incomplete fix for CVE-2016-10189 . 44 44 30.0296688079834 6943 585.4214429855347 ms
[Oct 01, 08:43:34] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bitlbee_bitlbee/retrieve.py/2023-10-01_08.43.09/ranking.tsv
#> Done.




2023-10-01 08:43:36,693 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:43:36,694 INFO rerun retrieving bratsche_pango
2023-10-01 08:44:02,267 INFO 

[Oct 01, 08:43:38] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bratsche_pango/retrieve.py/2023-10-01_08.43.38 




[Oct 01, 08:43:40] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bratsche_pango/retrieve.py/2023-10-01_08.43.38/logs/ 


[Oct 01, 08:43:41] {'root': 'run/retrieve_output', 'experiment': 'bratsche_pango', 'run': '2023-10-01_08.43.38', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/bratsche_pango.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/bratsche_pango', 'index_name': 'bratsche_pango', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:43:51] #> Loading model checkpoint.
[Oct 01, 08:43:51] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:43:52] #> checkpoint['epoch'] = 0
[Oct 01, 08:43:52] #> checkpoint['batch'] = 346000
[Oct 01, 08:43:52] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:43:52] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/bratsche_pango.tsv ...
[Oct 01, 08:43:52] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:43:54] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/bratsche_pango/bratsche_pango/ivfpq.70.faiss ..
[Oct 01, 08:43:55] #> Building the emb2pid mapping..
[Oct 01, 08:43:55] len(self.emb2pid) = 669906
[Oct 01, 08:43:55] tensor.size() =  torch.Size([670418, 128])
[Oct 01, 08:43:55] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/bratsche_pango/bratsche_pango/0.pt ...
[Oct 01, 08:43:55] #> Using strides [330, 387]..
[Oct 01, 08:43:58] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bratsche_pango/retrieve.py/2023-10-01_08.43.38/ranking.tsv
0 Integer overflow in the pango_glyph_string_set_size function in pango/glyphstring.c in Pango before 1.24 allows context-dependent attackers to cause a denial of service ( application crash ) or possibly execute arbitrary code via a long glyph string that triggers a heap-based buffer overflow , as demonstrated by a long document.location value in Firefox . 907 907 28.85573959350586 2459 1063.4500980377197 ms
[Oct 01, 08:43:59] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/bratsche_pango/retrieve.py/2023-10-01_08.43.38/ranking.tsv
#> Done.




2023-10-01 08:44:02,267 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:44:02,268 INFO rerun retrieving brianmario_yajl-ruby
2023-10-01 08:44:27,414 INFO 

[Oct 01, 08:44:04] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/brianmario_yajl-ruby/retrieve.py/2023-10-01_08.44.03 




[Oct 01, 08:44:06] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/brianmario_yajl-ruby/retrieve.py/2023-10-01_08.44.03/logs/ 


[Oct 01, 08:44:06] {'root': 'run/retrieve_output', 'experiment': 'brianmario_yajl-ruby', 'run': '2023-10-01_08.44.03', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/brianmario_yajl-ruby.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/brianmario_yajl-ruby', 'index_name': 'brianmario_yajl-ruby', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:44:17] #> Loading model checkpoint.
[Oct 01, 08:44:17] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:44:18] #> checkpoint['epoch'] = 0
[Oct 01, 08:44:18] #> checkpoint['batch'] = 346000
[Oct 01, 08:44:18] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:44:18] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/brianmario_yajl-ruby.tsv ...
[Oct 01, 08:44:18] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:44:20] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/brianmario_yajl-ruby/brianmario_yajl-ruby/ivfpq.70.faiss ..
[Oct 01, 08:44:20] #> Building the emb2pid mapping..
[Oct 01, 08:44:20] len(self.emb2pid) = 121474
[Oct 01, 08:44:21] tensor.size() =  torch.Size([121986, 128])
[Oct 01, 08:44:21] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/brianmario_yajl-ruby/brianmario_yajl-ruby/0.pt ...
[Oct 01, 08:44:21] #> Using strides [296, 423]..
[Oct 01, 08:44:23] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/brianmario_yajl-ruby/retrieve.py/2023-10-01_08.44.03/ranking.tsv
0 yajl-ruby is a C binding to the YAJL JSON parsing and generation library . The 1.x branch and the 2.x branch of ` yajl ` contain an integer overflow which leads to subsequent heap memory corruption when dealing with large ( ~2GB ) inputs . The reallocation logic at ` yajl_buf.c # L64 ` may result in the ` need ` 32bit integer wrapping to 0 when ` need ` approaches a value of 0x80000000 ( i.e . ~2GB of data ) , which results in a reallocation of buf- > alloc into a small heap chunk . These integers are declared as ` size_t ` in the 2.x branch of ` yajl ` , which practically prevents the issue from triggering on 64bit platforms , however this does not preclude this issue triggering on 32bit builds on which ` size_t ` is a 32bit integer . Subsequent population of this under-allocated heap chunk is based on the original buffer size , leading to heap memory corruption . This vulnerability mostly impacts process availability . Maintainers believe exploitation for arbitrary code execution is unlikely . A patch is available and anticipated to be part of yajl-ruby version 1.4.2 . As a workaround , avoid passing large inputs to YAJL . 24 24 30.164600372314453 786 1003.3769607543945 ms
[Oct 01, 08:44:24] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/brianmario_yajl-ruby/retrieve.py/2023-10-01_08.44.03/ranking.tsv
#> Done.




2023-10-01 08:44:27,414 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:44:27,415 INFO rerun retrieving ccxvii_mujs
2023-10-01 08:44:53,053 INFO 

[Oct 01, 08:44:29] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ccxvii_mujs/retrieve.py/2023-10-01_08.44.29 




[Oct 01, 08:44:31] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ccxvii_mujs/retrieve.py/2023-10-01_08.44.29/logs/ 


[Oct 01, 08:44:31] {'root': 'run/retrieve_output', 'experiment': 'ccxvii_mujs', 'run': '2023-10-01_08.44.29', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/ccxvii_mujs.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/ccxvii_mujs', 'index_name': 'ccxvii_mujs', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:44:42] #> Loading model checkpoint.
[Oct 01, 08:44:42] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:44:43] #> checkpoint['epoch'] = 0
[Oct 01, 08:44:43] #> checkpoint['batch'] = 346000
[Oct 01, 08:44:43] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:44:43] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/ccxvii_mujs.tsv ...
[Oct 01, 08:44:43] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:44:45] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/ccxvii_mujs/ccxvii_mujs/ivfpq.70.faiss ..
[Oct 01, 08:44:45] #> Building the emb2pid mapping..
[Oct 01, 08:44:45] len(self.emb2pid) = 596236
[Oct 01, 08:44:46] tensor.size() =  torch.Size([596748, 128])
[Oct 01, 08:44:46] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/ccxvii_mujs/ccxvii_mujs/0.pt ...
[Oct 01, 08:44:46] #> Using strides [299, 448]..
[Oct 01, 08:44:49] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ccxvii_mujs/retrieve.py/2023-10-01_08.44.29/ranking.tsv
0 An issue was discovered in Artifex MuJS 1.0.5 . It has unlimited recursion because the match function in regexp.c lacks a depth check . 16 16 29.714780807495117 2926 1018.88108253479 ms
1 An issue was discovered in Artifex MuJS 1.0.5 . The Number # toFixed ( ) and numtostr implementations in jsnumber.c have a stack-based buffer overflow . 16 16 30.111591339111328 1462 539.6876335144043 ms
2 An issue was discovered in Artifex MuJS 1.0.5. jscompile.c can cause a denial of service ( invalid stack-frame jump ) because it lacks an ENDTRY opcode call . 16 16 30.49726104736328 2926 380.7881673177083 ms
3 Artifex MuJS v1.1.3 was discovered to contain a heap buffer overflow which is caused by conflicting JumpList of nested try/finally statements . 16 16 30.25784683227539 2926 300.58157444000244 ms
[Oct 01, 08:44:50] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ccxvii_mujs/retrieve.py/2023-10-01_08.44.29/ranking.tsv
#> Done.




2023-10-01 08:44:53,054 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:44:53,055 INFO rerun retrieving coturn_coturn
2023-10-01 08:45:18,459 INFO 

[Oct 01, 08:44:55] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/coturn_coturn/retrieve.py/2023-10-01_08.44.54 




[Oct 01, 08:44:57] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/coturn_coturn/retrieve.py/2023-10-01_08.44.54/logs/ 


[Oct 01, 08:44:57] {'root': 'run/retrieve_output', 'experiment': 'coturn_coturn', 'run': '2023-10-01_08.44.54', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/coturn_coturn.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/coturn_coturn', 'index_name': 'coturn_coturn', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:45:08] #> Loading model checkpoint.
[Oct 01, 08:45:08] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:45:09] #> checkpoint['epoch'] = 0
[Oct 01, 08:45:09] #> checkpoint['batch'] = 346000
[Oct 01, 08:45:09] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:45:09] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/coturn_coturn.tsv ...
[Oct 01, 08:45:09] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:45:11] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/coturn_coturn/coturn_coturn/ivfpq.70.faiss ..
[Oct 01, 08:45:11] #> Building the emb2pid mapping..
[Oct 01, 08:45:11] len(self.emb2pid) = 271610
[Oct 01, 08:45:13] tensor.size() =  torch.Size([272122, 128])
[Oct 01, 08:45:13] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/coturn_coturn/coturn_coturn/0.pt ...
[Oct 01, 08:45:13] #> Using strides [300, 462]..
[Oct 01, 08:45:15] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/coturn_coturn/retrieve.py/2023-10-01_08.44.54/ranking.tsv
0 Coturn is free open source implementation of TURN and STUN Server . Coturn before version 4.5.2 by default does not allow peers to connect and relay packets to loopback addresses in the range of ` 127.x.x.x ` . However , it was observed that when sending a ` CONNECT ` request with the ` XOR-PEER-ADDRESS ` value of ` 0.0.0.0 ` , a successful response was received and subsequently , ` CONNECTIONBIND ` also received a successful response . Coturn then is able to relay packets to the loopback interface . Additionally , when coturn is listening on IPv6 , which is default , the loopback interface can also be reached by making use of either ` [ : :1 ] ` or ` [ : : ] ` as the peer address . By using the address ` 0.0.0.0 ` as the peer address , a malicious user will be able to relay packets to the loopback interface , unless ` -- denied-peer-ip=0.0.0.0 ` ( or similar ) has been specified . Since the default configuration implies that loopback peers are not allowed , coturn administrators may choose to not set the ` denied-peer-ip ` setting . The issue patched in version 4.5.2 . As a workaround the addresses in the address block ` 0.0.0.0/8 ` , ` [ : :1 ] ` and ` [ : : ] ` should be denied by default unless ` -- allow-loopback-peers ` has been specified . 89 89 27.61077880859375 1522 860.9151840209961 ms
[Oct 01, 08:45:15] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/coturn_coturn/retrieve.py/2023-10-01_08.44.54/ranking.tsv
#> Done.




2023-10-01 08:45:18,459 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:45:18,460 INFO rerun retrieving crawl_crawl
2023-10-01 08:45:44,360 INFO 

[Oct 01, 08:45:20] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/crawl_crawl/retrieve.py/2023-10-01_08.45.20 




[Oct 01, 08:45:22] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/crawl_crawl/retrieve.py/2023-10-01_08.45.20/logs/ 


[Oct 01, 08:45:23] {'root': 'run/retrieve_output', 'experiment': 'crawl_crawl', 'run': '2023-10-01_08.45.20', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/crawl_crawl.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/crawl_crawl', 'index_name': 'crawl_crawl', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:45:33] #> Loading model checkpoint.
[Oct 01, 08:45:33] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:45:34] #> checkpoint['epoch'] = 0
[Oct 01, 08:45:34] #> checkpoint['batch'] = 346000
[Oct 01, 08:45:34] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:45:34] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/crawl_crawl.tsv ...
[Oct 01, 08:45:34] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:45:36] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/crawl_crawl/crawl_crawl/ivfpq.70.faiss ..
[Oct 01, 08:45:36] #> Building the emb2pid mapping..
[Oct 01, 08:45:36] len(self.emb2pid) = 956235
[Oct 01, 08:45:37] tensor.size() =  torch.Size([956747, 128])
[Oct 01, 08:45:37] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/crawl_crawl/crawl_crawl/0.pt ...
[Oct 01, 08:45:37] #> Using strides [317, 455]..
[Oct 01, 08:45:40] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/crawl_crawl/retrieve.py/2023-10-01_08.45.20/ranking.tsv
0 Dungeon Crawl Stone Soup ( aka DCSS or crawl ) before 0.25 allows remote attackers to execute arbitrary code via Lua bytecode embedded in an uploaded .crawlrc file . 28 28 26.8819580078125 5000 1070.192813873291 ms
[Oct 01, 08:45:41] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/crawl_crawl/retrieve.py/2023-10-01_08.45.20/ranking.tsv
#> Done.




2023-10-01 08:45:44,361 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:45:44,362 INFO rerun retrieving davidben_nspluginwrapper
2023-10-01 08:46:09,531 INFO 

[Oct 01, 08:45:46] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/davidben_nspluginwrapper/retrieve.py/2023-10-01_08.45.46 




[Oct 01, 08:45:48] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/davidben_nspluginwrapper/retrieve.py/2023-10-01_08.45.46/logs/ 


[Oct 01, 08:45:49] {'root': 'run/retrieve_output', 'experiment': 'davidben_nspluginwrapper', 'run': '2023-10-01_08.45.46', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/davidben_nspluginwrapper.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/davidben_nspluginwrapper', 'index_name': 'davidben_nspluginwrapper', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:45:59] #> Loading model checkpoint.
[Oct 01, 08:45:59] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:46:00] #> checkpoint['epoch'] = 0
[Oct 01, 08:46:00] #> checkpoint['batch'] = 346000
[Oct 01, 08:46:00] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:46:00] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/davidben_nspluginwrapper.tsv ...
[Oct 01, 08:46:00] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:46:02] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/davidben_nspluginwrapper/davidben_nspluginwrapper/ivfpq.70.faiss ..
[Oct 01, 08:46:02] #> Building the emb2pid mapping..
[Oct 01, 08:46:02] len(self.emb2pid) = 43734
[Oct 01, 08:46:04] tensor.size() =  torch.Size([44246, 128])
[Oct 01, 08:46:04] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/davidben_nspluginwrapper/davidben_nspluginwrapper/0.pt ...
[Oct 01, 08:46:04] #> Using strides [323, 378]..
[Oct 01, 08:46:06] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/davidben_nspluginwrapper/retrieve.py/2023-10-01_08.45.46/ranking.tsv
0 nspluginwrapper before 1.4.4 does not properly provide access to NPNVprivateModeBool variable settings , which could prevent Firefox plugins from determining if they should run in Private Browsing mode and allow remote attackers to bypass intended access restrictions , as demonstrated using Flash . 167 167 19.658029556274414 209 830.5704593658447 ms
[Oct 01, 08:46:07] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/davidben_nspluginwrapper/retrieve.py/2023-10-01_08.45.46/ranking.tsv
#> Done.




2023-10-01 08:46:09,532 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:46:09,532 INFO rerun retrieving dbry_WavPack
2023-10-01 08:46:39,529 INFO 

[Oct 01, 08:46:11] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dbry_WavPack/retrieve.py/2023-10-01_08.46.11 




[Oct 01, 08:46:13] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dbry_WavPack/retrieve.py/2023-10-01_08.46.11/logs/ 


[Oct 01, 08:46:14] {'root': 'run/retrieve_output', 'experiment': 'dbry_WavPack', 'run': '2023-10-01_08.46.11', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/dbry_WavPack.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/dbry_WavPack', 'index_name': 'dbry_WavPack', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:46:24] #> Loading model checkpoint.
[Oct 01, 08:46:24] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:46:25] #> checkpoint['epoch'] = 0
[Oct 01, 08:46:25] #> checkpoint['batch'] = 346000
[Oct 01, 08:46:25] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:46:25] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/dbry_WavPack.tsv ...
[Oct 01, 08:46:25] #> Got 18 queries. All QIDs are unique.

[Oct 01, 08:46:27] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/dbry_WavPack/dbry_WavPack/ivfpq.70.faiss ..
[Oct 01, 08:46:28] #> Building the emb2pid mapping..
[Oct 01, 08:46:28] len(self.emb2pid) = 3400089
[Oct 01, 08:46:29] tensor.size() =  torch.Size([3400601, 128])
[Oct 01, 08:46:29] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/dbry_WavPack/dbry_WavPack/0.pt ...
[Oct 01, 08:46:29] #> Using strides [321, 399]..
[Oct 01, 08:46:32] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dbry_WavPack/retrieve.py/2023-10-01_08.46.11/ranking.tsv
0 The function WavpackVerifySingleBlock in open_utils.c in libwavpack.a in WavPack through 5.1.0 allows attackers to cause a denial-of-service ( out-of-bounds read and application crash ) via a crafted WavPack Lossless Audio file , as demonstrated by wvunpack . 486 486 29.187707901000977 14527 1190.4525756835938 ms
1 The ParseCaffHeaderConfig function of the cli/caff.c file of WavPack 5.1.0 allows a remote attacker to cause a denial-of-service ( global buffer over-read ) , or possibly trigger a buffer overflow or incorrect memory allocation , via a maliciously crafted CAF file . 486 486 28.55449104309082 14530 686.4460706710815 ms
2 The ParseDsdiffHeaderConfig function of the cli/dsdiff.c file of WavPack 5.1.0 allows a remote attacker to cause a denial-of-service ( heap-based buffer over-read ) or possibly overwrite the heap via a maliciously crafted DSDIFF file . 432 432 28.838077545166016 14529 516.9313748677572 ms
3 An issue was discovered in WavPack 5.1.0 and earlier for W64 input . Out-of-bounds writes can occur because ParseWave64HeaderConfig in wave64.c does not validate the sizes of unknown chunks before attempting memory allocation , related to a lack of integer-overflow protection within a bytes_to_copy calculation and subsequent malloc call , leading to insufficient memory allocation . 324 324 29.89664077758789 14527 432.4483275413513 ms
4 An issue was discovered in WavPack 5.1.0 and earlier for WAV input . Out-of-bounds writes can occur because ParseRiffHeaderConfig in riff.c does not validate the sizes of unknown chunks before attempting memory allocation , related to a lack of integer-overflow protection within a bytes_to_copy calculation and subsequent malloc call , leading to insufficient memory allocation . 306 306 29.799182891845703 14527 380.7912349700928 ms
5 A stack-based buffer over-read in the ParseRiffHeaderConfig function of cli/riff.c file of WavPack 5.1.0 allows a remote attacker to cause a denial-of-service attack or possibly have unspecified other impact via a maliciously crafted RF64 file . 342 342 28.37049102783203 14527 346.48724397023517 ms
6 WavpackSetConfiguration64 in pack_utils.c in libwavpack.a in WavPack through 5.1.0 has a `` Conditional jump or move depends on uninitialised value '' condition , which might allow attackers to cause a denial of service ( application crash ) via a DFF file that lacks valid sample-rate data . 540 540 28.246551513671875 14527 324.85413551330566 ms
7 WavPack 5.1 and earlier is affected by : CWE 369 : Divide by Zero . The impact is : Divide by zero can lead to sudden crash of a software/service that tries to parse a .wav file . The component is : ParseDsdiffHeaderConfig ( dsdiff.c:282 ) . The attack vector is : Maliciously crafted .wav file . The fixed version is : After commit https : //github.com/dbry/WavPack/commit/4c0faba32fddbd0745cbfaf1e1aeb3da5d35b9fc . 324 324 29.387962341308594 14527 306.0580790042877 ms
8 WavPack 5.1.0 and earlier is affected by : CWE-457 : Use of Uninitialized Variable . The impact is : Unexpected control flow , crashes , and segfaults . The component is : ParseWave64HeaderConfig ( wave64.c:211 ) . The attack vector is : Maliciously crafted .wav file . The fixed version is : After commit https : //github.com/dbry/WavPack/commit/33a0025d1d63ccd05d9dbaa6923d52b1446a62fe . 324 324 29.310388565063477 14527 291.6228241390652 ms
9 WavPack 5.1.0 and earlier is affected by : CWE-457 : Use of Uninitialized Variable . The impact is : Unexpected control flow , crashes , and segfaults . The component is : ParseCaffHeaderConfig ( caff.c:486 ) . The attack vector is : Maliciously crafted .wav file . The fixed version is : After commit https : //github.com/dbry/WavPack/commit/f68a9555b548306c5b1ee45199ccdc4a16a6101b . 324 324 29.310388565063477 14527 279.8913240432739 ms
10 The WriteCaffHeader function in cli/caff.c in Wavpack before 5.1.0 allows remote attackers to cause a denial of service ( out-of-bounds read ) via a crafted WV file . 468 468 28.763620376586914 14527 271.7902660369873 ms
11 An issue was discovered in WavPack 5.1.0 and earlier for DSDiff input . Out-of-bounds writes can occur because ParseDsdiffHeaderConfig in dsdiff.c does not validate the sizes of unknown chunks before attempting memory allocation , related to a lack of integer-overflow protection within a bytes_to_copy calculation and subsequent malloc call , leading to insufficient memory allocation . 342 342 29.69839859008789 14527 264.6689216295878 ms
12 The read_new_config_info function in open_utils.c in Wavpack before 5.1.0 allows remote attackers to cause a denial of service ( out-of-bounds read ) via a crafted WV file . 486 486 28.87103271484375 14527 258.54976360614484 ms
13 An issue was discovered in WavPack 5.1.0 and earlier . The W64 parser component contains a vulnerability that allows writing to memory because ParseWave64HeaderConfig in wave64.c does not reject multiple format chunks . 324 324 29.436519622802734 14527 252.9139689036778 ms
14 The function WavpackPackInit in pack_utils.c in libwavpack.a in WavPack through 5.1.0 allows attackers to cause a denial-of-service ( resource exhaustion caused by an infinite loop ) via a crafted wav audio file because WavpackSetConfiguration64 mishandles a sample rate of zero . 522 522 28.556690216064453 14527 248.06483586629233 ms
15 The read_code function in read_words.c in Wavpack before 5.1.0 allows remote attackers to cause a denial of service ( out-of-bounds read ) via a crafted WV file . 468 468 29.068572998046875 14527 243.50489675998688 ms
16 The unreorder_channels function in cli/wvunpack.c in Wavpack before 5.1.0 allows remote attackers to cause a denial of service ( out-of-bounds read ) via a crafted WV file . 522 522 28.13909339904785 14527 239.62232645820168 ms
17 An issue was discovered in WavPack 5.1.0 and earlier . The WAV parser component contains a vulnerability that allows writing to memory because ParseRiffHeaderConfig in riff.c does not reject multiple format chunks . 306 306 29.412479400634766 14527 235.83702246348062 ms
[Oct 01, 08:46:36] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dbry_WavPack/retrieve.py/2023-10-01_08.46.11/ranking.tsv
#> Done.




2023-10-01 08:46:39,530 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:46:39,531 INFO rerun retrieving dlitz_pycrypto
2023-10-01 08:47:04,980 INFO 

[Oct 01, 08:46:41] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dlitz_pycrypto/retrieve.py/2023-10-01_08.46.41 




[Oct 01, 08:46:43] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dlitz_pycrypto/retrieve.py/2023-10-01_08.46.41/logs/ 


[Oct 01, 08:46:44] {'root': 'run/retrieve_output', 'experiment': 'dlitz_pycrypto', 'run': '2023-10-01_08.46.41', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/dlitz_pycrypto.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/dlitz_pycrypto', 'index_name': 'dlitz_pycrypto', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:46:54] #> Loading model checkpoint.
[Oct 01, 08:46:54] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:46:55] #> checkpoint['epoch'] = 0
[Oct 01, 08:46:55] #> checkpoint['batch'] = 346000
[Oct 01, 08:46:55] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:46:55] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/dlitz_pycrypto.tsv ...
[Oct 01, 08:46:55] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:46:57] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/dlitz_pycrypto/dlitz_pycrypto/ivfpq.70.faiss ..
[Oct 01, 08:46:57] #> Building the emb2pid mapping..
[Oct 01, 08:46:57] len(self.emb2pid) = 211800
[Oct 01, 08:46:58] tensor.size() =  torch.Size([212312, 128])
[Oct 01, 08:46:58] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/dlitz_pycrypto/dlitz_pycrypto/0.pt ...
[Oct 01, 08:46:58] #> Using strides [321, 406]..
[Oct 01, 08:47:01] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dlitz_pycrypto/retrieve.py/2023-10-01_08.46.41/ranking.tsv
0 Heap-based buffer overflow in the ALGnew function in block_templace.c in Python Cryptography Toolkit ( aka pycrypto ) allows remote attackers to execute arbitrary code as demonstrated by a crafted iv parameter to cryptmsg.py . 13 13 28.887897491455078 956 997.208833694458 ms
[Oct 01, 08:47:02] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/dlitz_pycrypto/retrieve.py/2023-10-01_08.46.41/ranking.tsv
#> Done.




2023-10-01 08:47:04,981 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:47:04,981 INFO rerun retrieving facebook_folly
2023-10-01 08:47:32,559 INFO 

[Oct 01, 08:47:07] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_folly/retrieve.py/2023-10-01_08.47.06 




[Oct 01, 08:47:08] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_folly/retrieve.py/2023-10-01_08.47.06/logs/ 


[Oct 01, 08:47:09] {'root': 'run/retrieve_output', 'experiment': 'facebook_folly', 'run': '2023-10-01_08.47.06', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebook_folly.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_folly', 'index_name': 'facebook_folly', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:47:20] #> Loading model checkpoint.
[Oct 01, 08:47:20] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:47:21] #> checkpoint['epoch'] = 0
[Oct 01, 08:47:21] #> checkpoint['batch'] = 346000
[Oct 01, 08:47:21] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:47:21] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebook_folly.tsv ...
[Oct 01, 08:47:21] #> Got 3 queries. All QIDs are unique.

[Oct 01, 08:47:23] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_folly/facebook_folly/ivfpq.70.faiss ..
[Oct 01, 08:47:23] #> Building the emb2pid mapping..
[Oct 01, 08:47:23] len(self.emb2pid) = 4123021
[Oct 01, 08:47:24] tensor.size() =  torch.Size([4123533, 128])
[Oct 01, 08:47:24] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_folly/facebook_folly/0.pt ...
[Oct 01, 08:47:25] #> Using strides [350, 449]..
[Oct 01, 08:47:28] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_folly/retrieve.py/2023-10-01_08.47.06/ranking.tsv
0 Passing an attacker controlled size when creating an IOBuf could cause integer overflow , leading to an out of bounds write on the heap with the possibility of remote code execution . This issue affects versions of folly prior to v2021.07.22.00 . This issue affects HHVM versions prior to 4.80.5 , all versions between 4.81.0 and 4.102.1 , all versions between 4.103.0 and 4.113.0 , and versions 4.114.0 , 4.115.0 , 4.116.0 , 4.117.0 , 4.118.0 and 4.118.1 . 114 114 30.887874603271484 10001 1176.1834621429443 ms
1 folly : :secureRandom will re-use a buffer between parent and child processes when fork ( ) is called . That will result in multiple forked children producing repeat ( or similar ) results . This affects HHVM 3.26 prior to 3.26.3 and the folly library between v2017.12.11.00 and v2018.08.09.00 . 99 99 30.849729537963867 15002 686.3694190979004 ms
2 Improper handling of close_notify alerts can result in an out-of-bounds read in AsyncSSLSocket . This issue affects folly prior to v2019.11.04.00 . 141 141 30.605388641357422 10000 521.4213530222574 ms
[Oct 01, 08:47:29] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_folly/retrieve.py/2023-10-01_08.47.06/ranking.tsv
#> Done.




2023-10-01 08:47:32,560 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:47:32,561 INFO rerun retrieving facebook_proxygen
2023-10-01 08:48:03,062 INFO 

[Oct 01, 08:47:34] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_proxygen/retrieve.py/2023-10-01_08.47.34 




[Oct 01, 08:47:36] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_proxygen/retrieve.py/2023-10-01_08.47.34/logs/ 


[Oct 01, 08:47:37] {'root': 'run/retrieve_output', 'experiment': 'facebook_proxygen', 'run': '2023-10-01_08.47.34', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebook_proxygen.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_proxygen', 'index_name': 'facebook_proxygen', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:47:48] #> Loading model checkpoint.
[Oct 01, 08:47:48] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:47:48] #> checkpoint['epoch'] = 0
[Oct 01, 08:47:48] #> checkpoint['batch'] = 346000
[Oct 01, 08:47:48] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:47:48] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebook_proxygen.tsv ...
[Oct 01, 08:47:48] #> Got 5 queries. All QIDs are unique.

[Oct 01, 08:47:51] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_proxygen/facebook_proxygen/ivfpq.70.faiss ..
[Oct 01, 08:47:51] #> Building the emb2pid mapping..
[Oct 01, 08:47:52] len(self.emb2pid) = 7514597
[Oct 01, 08:47:53] tensor.size() =  torch.Size([7515109, 128])
[Oct 01, 08:47:53] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_proxygen/facebook_proxygen/0.pt ...
[Oct 01, 08:47:54] #> Using strides [416, 448]..
[Oct 01, 08:47:57] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_proxygen/retrieve.py/2023-10-01_08.47.34/ranking.tsv
0 A potential denial-of-service issue in the Proxygen handling of invalid HTTP2 priority settings ( specifically a circular dependency ) . This affects Proxygen prior to v2018.12.31.00 . 5 5 31.053924560546875 25001 1344.3362712860107 ms
1 Proxygen fails to validate that a secondary auth manager is set before dereferencing it . That can cause a denial of service issue when parsing a Certificate/CertificateRequest HTTP2 Frame over a fizz ( TLS 1.3 ) transport . This issue affects Proxygen releases starting from v2018.10.29.00 until the fix in v2018.11.19.00 . 5 5 31.006046295166016 25000 840.4250144958496 ms
2 In the course of decompressing HPACK inside the HTTP2 protocol , an unexpected sequence of header table resize operations can place the header table into a corrupted state , leading to a use-after-free condition and undefined behavior . This issue affects Proxygen from v0.29.0 until v2017.04.03.00 . 5 5 30.17011260986328 25004 680.1638603210449 ms
3 An out of bounds write is possible via a specially crafted packet in certain configurations of Proxygen due to improper handling of Base64 when parsing malformed binary content in Structured HTTP Headers . This issue affects versions of proxygen prior to v2019.07.22.00 . 5 5 31.006454467773438 25003 592.522919178009 ms
4 An issue in the Proxygen handling of HTTP2 parsing of headers/trailers can lead to a denial-of-service attack . This affects Proxygen prior to v2018.12.31.00 . 5 5 30.98097801208496 25001 541.4199352264404 ms
[Oct 01, 08:48:00] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_proxygen/retrieve.py/2023-10-01_08.47.34/ranking.tsv
#> Done.




2023-10-01 08:48:03,063 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:48:03,063 INFO rerun retrieving facebook_wangle
2023-10-01 08:48:29,164 INFO 

[Oct 01, 08:48:05] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_wangle/retrieve.py/2023-10-01_08.48.04 




[Oct 01, 08:48:06] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_wangle/retrieve.py/2023-10-01_08.48.04/logs/ 


[Oct 01, 08:48:07] {'root': 'run/retrieve_output', 'experiment': 'facebook_wangle', 'run': '2023-10-01_08.48.04', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebook_wangle.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_wangle', 'index_name': 'facebook_wangle', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:48:18] #> Loading model checkpoint.
[Oct 01, 08:48:18] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:48:19] #> checkpoint['epoch'] = 0
[Oct 01, 08:48:19] #> checkpoint['batch'] = 346000
[Oct 01, 08:48:19] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:48:19] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebook_wangle.tsv ...
[Oct 01, 08:48:19] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:48:21] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_wangle/facebook_wangle/ivfpq.70.faiss ..
[Oct 01, 08:48:21] #> Building the emb2pid mapping..
[Oct 01, 08:48:21] len(self.emb2pid) = 1596790
[Oct 01, 08:48:23] tensor.size() =  torch.Size([1597302, 128])
[Oct 01, 08:48:23] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/facebook_wangle/facebook_wangle/0.pt ...
[Oct 01, 08:48:23] #> Using strides [416, 427]..
[Oct 01, 08:48:25] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_wangle/retrieve.py/2023-10-01_08.48.04/ranking.tsv
0 Wangle 's LineBasedFrameDecoder contains logic for identifying newlines which incorrectly advances a buffer , leading to a potential underflow . This affects versions of Wangle prior to v2019.04.22.00 1674 1674 28.497957229614258 5000 1085.1013660430908 ms
[Oct 01, 08:48:26] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebook_wangle/retrieve.py/2023-10-01_08.48.04/ranking.tsv
#> Done.




2023-10-01 08:48:29,164 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:48:29,165 INFO rerun retrieving facebookincubator_mvfst
2023-10-01 08:48:55,792 INFO 

[Oct 01, 08:48:31] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebookincubator_mvfst/retrieve.py/2023-10-01_08.48.30 




[Oct 01, 08:48:33] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebookincubator_mvfst/retrieve.py/2023-10-01_08.48.30/logs/ 


[Oct 01, 08:48:34] {'root': 'run/retrieve_output', 'experiment': 'facebookincubator_mvfst', 'run': '2023-10-01_08.48.30', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebookincubator_mvfst.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/facebookincubator_mvfst', 'index_name': 'facebookincubator_mvfst', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:48:44] #> Loading model checkpoint.
[Oct 01, 08:48:44] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:48:45] #> checkpoint['epoch'] = 0
[Oct 01, 08:48:45] #> checkpoint['batch'] = 346000
[Oct 01, 08:48:45] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:48:45] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/facebookincubator_mvfst.tsv ...
[Oct 01, 08:48:45] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:48:47] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/facebookincubator_mvfst/facebookincubator_mvfst/ivfpq.70.faiss ..
[Oct 01, 08:48:47] #> Building the emb2pid mapping..
[Oct 01, 08:48:47] len(self.emb2pid) = 1674231
[Oct 01, 08:48:48] tensor.size() =  torch.Size([1674743, 128])
[Oct 01, 08:48:48] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/facebookincubator_mvfst/facebookincubator_mvfst/0.pt ...
[Oct 01, 08:48:49] #> Using strides [416, 431]..
[Oct 01, 08:48:51] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebookincubator_mvfst/retrieve.py/2023-10-01_08.48.30/ranking.tsv
0 A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session , which causes a crash via a failed assertion . Per QUIC specification , this particular message should be treated as a connection error . This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00 . 1513 1513 30.508638381958008 5000 1151.3488292694092 ms
[Oct 01, 08:48:53] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/facebookincubator_mvfst/retrieve.py/2023-10-01_08.48.30/ranking.tsv
#> Done.




2023-10-01 08:48:55,792 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:48:55,793 INFO rerun retrieving fatcerberus_minisphere
2023-10-01 08:49:21,952 INFO 

[Oct 01, 08:48:57] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/fatcerberus_minisphere/retrieve.py/2023-10-01_08.48.57 




[Oct 01, 08:48:59] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/fatcerberus_minisphere/retrieve.py/2023-10-01_08.48.57/logs/ 


[Oct 01, 08:49:00] {'root': 'run/retrieve_output', 'experiment': 'fatcerberus_minisphere', 'run': '2023-10-01_08.48.57', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/fatcerberus_minisphere.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/fatcerberus_minisphere', 'index_name': 'fatcerberus_minisphere', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:49:11] #> Loading model checkpoint.
[Oct 01, 08:49:11] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:49:12] #> checkpoint['epoch'] = 0
[Oct 01, 08:49:12] #> checkpoint['batch'] = 346000
[Oct 01, 08:49:12] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:49:12] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/fatcerberus_minisphere.tsv ...
[Oct 01, 08:49:12] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:49:14] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/fatcerberus_minisphere/fatcerberus_minisphere/ivfpq.70.faiss ..
[Oct 01, 08:49:14] #> Building the emb2pid mapping..
[Oct 01, 08:49:14] len(self.emb2pid) = 903663
[Oct 01, 08:49:15] tensor.size() =  torch.Size([904175, 128])
[Oct 01, 08:49:15] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/fatcerberus_minisphere/fatcerberus_minisphere/0.pt ...
[Oct 01, 08:49:15] #> Using strides [327, 384]..
[Oct 01, 08:49:18] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/fatcerberus_minisphere/retrieve.py/2023-10-01_08.48.57/ranking.tsv
0 miniSphere version 5.2.9 and earlier contains a Integer Overflow vulnerability in layer_resize ( ) function in map_engine.c that can result in remote denial of service . This attack appear to be exploitable via the victim must load a specially-crafted map which calls SetLayerSize in its entry script . This vulnerability appears to have been fixed in 5.0.3 , 5.1.5 , 5.2.10 and later . 991 991 31.234390258789062 3449 1037.2655391693115 ms
[Oct 01, 08:49:19] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/fatcerberus_minisphere/retrieve.py/2023-10-01_08.48.57/ranking.tsv
#> Done.




2023-10-01 08:49:21,953 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:49:21,954 INFO rerun retrieving glennrp_libpng
2023-10-01 08:49:48,572 INFO 

[Oct 01, 08:49:24] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/glennrp_libpng/retrieve.py/2023-10-01_08.49.23 




[Oct 01, 08:49:26] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/glennrp_libpng/retrieve.py/2023-10-01_08.49.23/logs/ 


[Oct 01, 08:49:27] {'root': 'run/retrieve_output', 'experiment': 'glennrp_libpng', 'run': '2023-10-01_08.49.23', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/glennrp_libpng.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/glennrp_libpng', 'index_name': 'glennrp_libpng', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:49:37] #> Loading model checkpoint.
[Oct 01, 08:49:37] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:49:38] #> checkpoint['epoch'] = 0
[Oct 01, 08:49:38] #> checkpoint['batch'] = 346000
[Oct 01, 08:49:38] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:49:38] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/glennrp_libpng.tsv ...
[Oct 01, 08:49:38] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:49:40] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/glennrp_libpng/glennrp_libpng/ivfpq.70.faiss ..
[Oct 01, 08:49:40] #> Building the emb2pid mapping..
[Oct 01, 08:49:40] len(self.emb2pid) = 1176228
[Oct 01, 08:49:41] tensor.size() =  torch.Size([1176740, 128])
[Oct 01, 08:49:41] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/glennrp_libpng/glennrp_libpng/0.pt ...
[Oct 01, 08:49:42] #> Using strides [341, 409]..
[Oct 01, 08:49:44] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/glennrp_libpng/retrieve.py/2023-10-01_08.49.23/ranking.tsv
0 In libpng 1.6.34 , a wrong calculation of row_factor in the png_check_chunk_length function ( pngrutil.c ) may trigger an integer overflow and resultant divide-by-zero while processing a crafted PNG file , leading to a denial of service . 92 92 30.495952606201172 4166 1080.7013511657715 ms
[Oct 01, 08:49:45] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/glennrp_libpng/retrieve.py/2023-10-01_08.49.23/ranking.tsv
#> Done.




2023-10-01 08:49:48,573 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:49:48,573 INFO rerun retrieving gsliepen_tinc
2023-10-01 08:50:14,594 INFO 

[Oct 01, 08:49:50] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gsliepen_tinc/retrieve.py/2023-10-01_08.49.50 




[Oct 01, 08:49:52] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gsliepen_tinc/retrieve.py/2023-10-01_08.49.50/logs/ 


[Oct 01, 08:49:53] {'root': 'run/retrieve_output', 'experiment': 'gsliepen_tinc', 'run': '2023-10-01_08.49.50', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/gsliepen_tinc.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/gsliepen_tinc', 'index_name': 'gsliepen_tinc', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:50:04] #> Loading model checkpoint.
[Oct 01, 08:50:04] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:50:04] #> checkpoint['epoch'] = 0
[Oct 01, 08:50:04] #> checkpoint['batch'] = 346000
[Oct 01, 08:50:04] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:50:04] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/gsliepen_tinc.tsv ...
[Oct 01, 08:50:04] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:50:07] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/gsliepen_tinc/gsliepen_tinc/ivfpq.70.faiss ..
[Oct 01, 08:50:07] #> Building the emb2pid mapping..
[Oct 01, 08:50:07] len(self.emb2pid) = 664973
[Oct 01, 08:50:08] tensor.size() =  torch.Size([665485, 128])
[Oct 01, 08:50:08] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/gsliepen_tinc/gsliepen_tinc/0.pt ...
[Oct 01, 08:50:08] #> Using strides [322, 474]..
[Oct 01, 08:50:10] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gsliepen_tinc/retrieve.py/2023-10-01_08.49.50/ranking.tsv
0 Stack-based buffer overflow in the receive_tcppacket function in net_packet.c in tinc before 1.0.21 and 1.1 before 1.1pre7 allows remote authenticated peers to cause a denial of service ( crash ) or possibly execute arbitrary code via a large TCP packet . 182 182 30.98659896850586 3158 1069.6418285369873 ms
[Oct 01, 08:50:11] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gsliepen_tinc/retrieve.py/2023-10-01_08.49.50/ranking.tsv
#> Done.




2023-10-01 08:50:14,594 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:50:14,594 INFO rerun retrieving gssapi_gssproxy
2023-10-01 08:50:40,516 INFO 

[Oct 01, 08:50:16] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gssapi_gssproxy/retrieve.py/2023-10-01_08.50.16 




[Oct 01, 08:50:18] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gssapi_gssproxy/retrieve.py/2023-10-01_08.50.16/logs/ 


[Oct 01, 08:50:19] {'root': 'run/retrieve_output', 'experiment': 'gssapi_gssproxy', 'run': '2023-10-01_08.50.16', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/gssapi_gssproxy.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/gssapi_gssproxy', 'index_name': 'gssapi_gssproxy', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:50:30] #> Loading model checkpoint.
[Oct 01, 08:50:30] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:50:31] #> checkpoint['epoch'] = 0
[Oct 01, 08:50:31] #> checkpoint['batch'] = 346000
[Oct 01, 08:50:31] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:50:31] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/gssapi_gssproxy.tsv ...
[Oct 01, 08:50:31] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:50:33] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/gssapi_gssproxy/gssapi_gssproxy/ivfpq.70.faiss ..
[Oct 01, 08:50:33] #> Building the emb2pid mapping..
[Oct 01, 08:50:33] len(self.emb2pid) = 162419
[Oct 01, 08:50:34] tensor.size() =  torch.Size([162931, 128])
[Oct 01, 08:50:34] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/gssapi_gssproxy/gssapi_gssproxy/0.pt ...
[Oct 01, 08:50:34] #> Using strides [325, 393]..
[Oct 01, 08:50:36] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gssapi_gssproxy/retrieve.py/2023-10-01_08.50.16/ranking.tsv
0 * * DISPUTED * * gssproxy ( aka gss-proxy ) before 0.8.3 does not unlock cond_mutex before pthread exit in gp_worker_main ( ) in gp_workers.c . NOTE : An upstream comment states `` We are already on a shutdown path when running the code in question , so a DoS there does n't make any sense , and there has been no additional information provided us ( as upstream ) to indicate why this would be a problem . '' 529 529 29.23573875427246 713 994.66872215271 ms
[Oct 01, 08:50:37] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/gssapi_gssproxy/retrieve.py/2023-10-01_08.50.16/ranking.tsv
#> Done.




2023-10-01 08:50:40,516 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:50:40,517 INFO rerun retrieving h2o_h2o
2023-10-01 08:51:07,649 INFO 

[Oct 01, 08:50:42] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/h2o_h2o/retrieve.py/2023-10-01_08.50.42 




[Oct 01, 08:50:44] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/h2o_h2o/retrieve.py/2023-10-01_08.50.42/logs/ 


[Oct 01, 08:50:45] {'root': 'run/retrieve_output', 'experiment': 'h2o_h2o', 'run': '2023-10-01_08.50.42', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/h2o_h2o.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/h2o_h2o', 'index_name': 'h2o_h2o', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:50:56] #> Loading model checkpoint.
[Oct 01, 08:50:56] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:50:57] #> checkpoint['epoch'] = 0
[Oct 01, 08:50:57] #> checkpoint['batch'] = 346000
[Oct 01, 08:50:57] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:50:57] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/h2o_h2o.tsv ...
[Oct 01, 08:50:57] #> Got 2 queries. All QIDs are unique.

[Oct 01, 08:50:59] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/h2o_h2o/h2o_h2o/ivfpq.70.faiss ..
[Oct 01, 08:50:59] #> Building the emb2pid mapping..
[Oct 01, 08:50:59] len(self.emb2pid) = 1749884
[Oct 01, 08:51:00] tensor.size() =  torch.Size([1750396, 128])
[Oct 01, 08:51:00] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/h2o_h2o/h2o_h2o/0.pt ...
[Oct 01, 08:51:00] #> Using strides [309, 463]..
[Oct 01, 08:51:03] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/h2o_h2o/retrieve.py/2023-10-01_08.50.42/ranking.tsv
0 lib/http2/connection.c in H2O before 1.7.3 and 2.x before 2.0.0-beta5 mishandles HTTP/2 disconnection , which allows remote attackers to cause a denial of service ( use-after-free and application crash ) or possibly execute arbitrary code via a crafted packet . 132 132 31.124351501464844 10000 1102.4811267852783 ms
1 h2o is an open source http server . In code prior to the ` 8c0eca3 ` commit h2o may attempt to access uninitialized memory . When receiving QUIC frames in certain order , HTTP/3 server-side implementation of h2o can be misguided to treat uninitialized memory as HTTP/3 frames that have been received . When h2o is used as a reverse proxy , an attacker can abuse this vulnerability to send internal state of h2o to backend servers controlled by the attacker or third party . Also , if there is an HTTP endpoint that reflects the traffic sent from the client , an attacker can use that reflector to obtain internal state of h2o . This internal state includes traffic of other connections in unencrypted form and TLS session tickets . This vulnerability exists in h2o server with HTTP/3 support , between commit 93af138 and d1f0f65 . None of the released versions of h2o are affected by this vulnerability . There are no known workarounds . Users of unreleased versions of h2o using HTTP/3 are advised to upgrade immediately . 76 76 30.433368682861328 10000 609.7956895828247 ms
[Oct 01, 08:51:04] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/h2o_h2o/retrieve.py/2023-10-01_08.50.42/ranking.tsv
#> Done.




2023-10-01 08:51:07,649 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:51:07,650 INFO rerun retrieving hexchat_hexchat
2023-10-01 08:51:34,159 INFO 

[Oct 01, 08:51:09] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/hexchat_hexchat/retrieve.py/2023-10-01_08.51.09 




[Oct 01, 08:51:11] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/hexchat_hexchat/retrieve.py/2023-10-01_08.51.09/logs/ 


[Oct 01, 08:51:12] {'root': 'run/retrieve_output', 'experiment': 'hexchat_hexchat', 'run': '2023-10-01_08.51.09', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/hexchat_hexchat.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/hexchat_hexchat', 'index_name': 'hexchat_hexchat', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:51:23] #> Loading model checkpoint.
[Oct 01, 08:51:23] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:51:24] #> checkpoint['epoch'] = 0
[Oct 01, 08:51:24] #> checkpoint['batch'] = 346000
[Oct 01, 08:51:24] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:51:24] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/hexchat_hexchat.tsv ...
[Oct 01, 08:51:24] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:51:26] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/hexchat_hexchat/hexchat_hexchat/ivfpq.70.faiss ..
[Oct 01, 08:51:26] #> Building the emb2pid mapping..
[Oct 01, 08:51:26] len(self.emb2pid) = 625955
[Oct 01, 08:51:27] tensor.size() =  torch.Size([626467, 128])
[Oct 01, 08:51:27] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/hexchat_hexchat/hexchat_hexchat/0.pt ...
[Oct 01, 08:51:27] #> Using strides [299, 406]..
[Oct 01, 08:51:30] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/hexchat_hexchat/retrieve.py/2023-10-01_08.51.09/ranking.tsv
0 The ssl_do_connect function in common/server.c in HexChat before 2.10.2 , XChat , and XChat-GNOME does not verify that the server hostname matches a domain name in the X.509 certificate , which allows man-in-the-middle attackers to spoof SSL servers via an arbitrary valid certificate . 243 243 29.0734806060791 3558 1034.9178314208984 ms
[Oct 01, 08:51:31] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/hexchat_hexchat/retrieve.py/2023-10-01_08.51.09/ranking.tsv
#> Done.




2023-10-01 08:51:34,159 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:51:34,160 INFO rerun retrieving joyent_node
2023-10-01 08:51:59,588 INFO 

[Oct 01, 08:51:36] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/joyent_node/retrieve.py/2023-10-01_08.51.35 




[Oct 01, 08:51:38] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/joyent_node/retrieve.py/2023-10-01_08.51.35/logs/ 


[Oct 01, 08:51:39] {'root': 'run/retrieve_output', 'experiment': 'joyent_node', 'run': '2023-10-01_08.51.35', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/joyent_node.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/joyent_node', 'index_name': 'joyent_node', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:51:50] #> Loading model checkpoint.
[Oct 01, 08:51:50] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:51:51] #> checkpoint['epoch'] = 0
[Oct 01, 08:51:51] #> checkpoint['batch'] = 346000
[Oct 01, 08:51:51] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:51:51] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/joyent_node.tsv ...
[Oct 01, 08:51:51] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:51:53] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/joyent_node/joyent_node/ivfpq.70.faiss ..
[Oct 01, 08:51:53] #> Building the emb2pid mapping..
[Oct 01, 08:51:53] len(self.emb2pid) = 492
[Oct 01, 08:51:54] tensor.size() =  torch.Size([1004, 128])
[Oct 01, 08:51:54] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/joyent_node/joyent_node/0.pt ...
[Oct 01, 08:51:54] #> Using strides [163, 268]..
[Oct 01, 08:51:56] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/joyent_node/retrieve.py/2023-10-01_08.51.35/ranking.tsv
0 The Update method in src/node_http_parser.cc in Node.js before 0.6.17 and 0.7 before 0.7.8 does not properly check the length of a string , which allows remote attackers to obtain sensitive information ( request header contents ) and possibly spoof HTTP headers via a zero length string . 3 3 20.057933807373047 2 969.4185256958008 ms
[Oct 01, 08:51:57] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/joyent_node/retrieve.py/2023-10-01_08.51.35/ranking.tsv
#> Done.




2023-10-01 08:51:59,589 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:51:59,589 INFO rerun retrieving keepkey_keepkey-firmware
2023-10-01 08:52:27,690 INFO 

[Oct 01, 08:52:01] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/keepkey_keepkey-firmware/retrieve.py/2023-10-01_08.52.01 




[Oct 01, 08:52:03] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/keepkey_keepkey-firmware/retrieve.py/2023-10-01_08.52.01/logs/ 


[Oct 01, 08:52:04] {'root': 'run/retrieve_output', 'experiment': 'keepkey_keepkey-firmware', 'run': '2023-10-01_08.52.01', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/keepkey_keepkey-firmware.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/keepkey_keepkey-firmware', 'index_name': 'keepkey_keepkey-firmware', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:52:15] #> Loading model checkpoint.
[Oct 01, 08:52:15] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:52:16] #> checkpoint['epoch'] = 0
[Oct 01, 08:52:16] #> checkpoint['batch'] = 346000
[Oct 01, 08:52:16] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:52:16] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/keepkey_keepkey-firmware.tsv ...
[Oct 01, 08:52:16] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:52:18] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/keepkey_keepkey-firmware/keepkey_keepkey-firmware/ivfpq.70.faiss ..
[Oct 01, 08:52:18] #> Building the emb2pid mapping..
[Oct 01, 08:52:18] len(self.emb2pid) = 3338384
[Oct 01, 08:52:19] tensor.size() =  torch.Size([3338896, 128])
[Oct 01, 08:52:19] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/keepkey_keepkey-firmware/keepkey_keepkey-firmware/0.pt ...
[Oct 01, 08:52:20] #> Using strides [319, 425]..
[Oct 01, 08:52:23] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/keepkey_keepkey-firmware/retrieve.py/2023-10-01_08.52.01/ranking.tsv
0 Insufficient checks in the finite state machine of the ShapeShift KeepKey hardware wallet before firmware 6.2.2 allow a partial reset of cryptographic secrets to known values via crafted messages . Notably , this breaks the security of U2F for new server registrations and invalidates existing registrations . This vulnerability can be exploited by unauthenticated attackers and the interface is reachable via WebUSB . 268 268 28.971851348876953 12875 1143.446683883667 ms
1 In the KeepKey firmware before 7.3.2 , Flaws in the supervisor interface can be exploited to bypass important security restrictions on firmware operations . Using these flaws , malicious firmware code can elevate privileges , permanently make the device inoperable or overwrite the trusted bootloader code to compromise the hardware wallet across reboots or storage wipes . 236 236 29.32503890991211 12875 668.4650182723999 ms
2 Insufficient length checks in the ShapeShift KeepKey hardware wallet firmware before 7.1.0 allow a stack buffer overflow via crafted messages . The overflow in ethereum_extractThorchainSwapData ( ) in ethereum.c can circumvent stack protections and lead to code execution . The vulnerable interface is reachable remotely over WebUSB . 268 268 29.07113265991211 12875 507.8280766805013 ms
3 Insufficient checks in the USB packet handling of the ShapeShift KeepKey hardware wallet before firmware 6.2.2 allow out-of-bounds writes in the .bss segment via crafted messages . The vulnerability could allow code execution or other forms of impact . It can be triggered by unauthenticated attackers and the interface is reachable via WebUSB . 276 276 29.04800033569336 12875 428.22903394699097 ms
[Oct 01, 08:52:24] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/keepkey_keepkey-firmware/retrieve.py/2023-10-01_08.52.01/ranking.tsv
#> Done.




2023-10-01 08:52:27,691 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:52:27,692 INFO rerun retrieving kr_beanstalkd
2023-10-01 08:52:54,126 INFO 

[Oct 01, 08:52:29] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/kr_beanstalkd/retrieve.py/2023-10-01_08.52.29 




[Oct 01, 08:52:31] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/kr_beanstalkd/retrieve.py/2023-10-01_08.52.29/logs/ 


[Oct 01, 08:52:32] {'root': 'run/retrieve_output', 'experiment': 'kr_beanstalkd', 'run': '2023-10-01_08.52.29', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/kr_beanstalkd.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/kr_beanstalkd', 'index_name': 'kr_beanstalkd', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:52:43] #> Loading model checkpoint.
[Oct 01, 08:52:43] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:52:44] #> checkpoint['epoch'] = 0
[Oct 01, 08:52:44] #> checkpoint['batch'] = 346000
[Oct 01, 08:52:44] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:52:44] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/kr_beanstalkd.tsv ...
[Oct 01, 08:52:44] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:52:46] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/kr_beanstalkd/kr_beanstalkd/ivfpq.70.faiss ..
[Oct 01, 08:52:46] #> Building the emb2pid mapping..
[Oct 01, 08:52:46] len(self.emb2pid) = 149294
[Oct 01, 08:52:47] tensor.size() =  torch.Size([149806, 128])
[Oct 01, 08:52:47] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/kr_beanstalkd/kr_beanstalkd/0.pt ...
[Oct 01, 08:52:47] #> Using strides [289, 418]..
[Oct 01, 08:52:50] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/kr_beanstalkd/retrieve.py/2023-10-01_08.52.29/ranking.tsv
0 The put command functionality in beanstalkd 1.4.5 and earlier allows remote attackers to execute arbitrary Beanstalk commands via the body in a job that is too big , which is not properly handled by the dispatch_cmd function in prot.c . 176 176 31.20685577392578 837 1011.8880271911621 ms
[Oct 01, 08:52:51] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/kr_beanstalkd/retrieve.py/2023-10-01_08.52.29/ranking.tsv
#> Done.




2023-10-01 08:52:54,126 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:52:54,127 INFO rerun retrieving laverdet_isolated-vm
2023-10-01 08:53:19,913 INFO 

[Oct 01, 08:52:56] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/laverdet_isolated-vm/retrieve.py/2023-10-01_08.52.55 




[Oct 01, 08:52:58] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/laverdet_isolated-vm/retrieve.py/2023-10-01_08.52.55/logs/ 


[Oct 01, 08:52:59] {'root': 'run/retrieve_output', 'experiment': 'laverdet_isolated-vm', 'run': '2023-10-01_08.52.55', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/laverdet_isolated-vm.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/laverdet_isolated-vm', 'index_name': 'laverdet_isolated-vm', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:53:09] #> Loading model checkpoint.
[Oct 01, 08:53:09] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:53:10] #> checkpoint['epoch'] = 0
[Oct 01, 08:53:10] #> checkpoint['batch'] = 346000
[Oct 01, 08:53:10] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:53:10] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/laverdet_isolated-vm.tsv ...
[Oct 01, 08:53:10] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:53:12] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/laverdet_isolated-vm/laverdet_isolated-vm/ivfpq.70.faiss ..
[Oct 01, 08:53:12] #> Building the emb2pid mapping..
[Oct 01, 08:53:12] len(self.emb2pid) = 108094
[Oct 01, 08:53:13] tensor.size() =  torch.Size([108606, 128])
[Oct 01, 08:53:13] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/laverdet_isolated-vm/laverdet_isolated-vm/0.pt ...
[Oct 01, 08:53:13] #> Using strides [295, 407]..
[Oct 01, 08:53:16] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/laverdet_isolated-vm/retrieve.py/2023-10-01_08.52.55/ranking.tsv
0 isolated-vm is a library for nodejs which gives you access to v8 's Isolate interface . Versions of isolated-vm before v4.0.0 have API pitfalls which may make it easy for implementers to expose supposed secure isolates to the permissions of the main nodejs isolate . Reference objects allow access to the underlying reference 's full prototype chain . In an environment where the implementer has exposed a Reference instance to an attacker they would be able to use it to acquire a Reference to the nodejs context 's Function object . Similar application-specific attacks could be possible by modifying the local prototype of other API objects . Access to NativeModule objects could allow an attacker to load and run native code from anywhere on the filesystem . If combined with , for example , a file upload API this would allow for arbitrary code execution . This is addressed in v4.0.0 through a series of related changes . 314 314 24.620990753173828 557 991.4956092834473 ms
[Oct 01, 08:53:17] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/laverdet_isolated-vm/retrieve.py/2023-10-01_08.52.55/ranking.tsv
#> Done.




2023-10-01 08:53:19,913 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:53:19,914 INFO rerun retrieving libgit2_libgit2
2023-10-01 08:53:52,375 INFO 

[Oct 01, 08:53:21] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libgit2_libgit2/retrieve.py/2023-10-01_08.53.21 




[Oct 01, 08:53:24] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libgit2_libgit2/retrieve.py/2023-10-01_08.53.21/logs/ 


[Oct 01, 08:53:25] {'root': 'run/retrieve_output', 'experiment': 'libgit2_libgit2', 'run': '2023-10-01_08.53.21', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/libgit2_libgit2.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/libgit2_libgit2', 'index_name': 'libgit2_libgit2', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:53:35] #> Loading model checkpoint.
[Oct 01, 08:53:35] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:53:36] #> checkpoint['epoch'] = 0
[Oct 01, 08:53:36] #> checkpoint['batch'] = 346000
[Oct 01, 08:53:36] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:53:36] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/libgit2_libgit2.tsv ...
[Oct 01, 08:53:36] #> Got 9 queries. All QIDs are unique.

[Oct 01, 08:53:38] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/libgit2_libgit2/libgit2_libgit2/ivfpq.70.faiss ..
[Oct 01, 08:53:39] #> Building the emb2pid mapping..
[Oct 01, 08:53:39] len(self.emb2pid) = 7920111
[Oct 01, 08:53:40] tensor.size() =  torch.Size([7920623, 128])
[Oct 01, 08:53:40] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/libgit2_libgit2/libgit2_libgit2/0.pt ...
[Oct 01, 08:53:42] #> Using strides [312, 432]..
[Oct 01, 08:53:45] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libgit2_libgit2/retrieve.py/2023-10-01_08.53.21/ranking.tsv
0 Integer overflow in the index.c : read_entry ( ) function while decompressing a compressed prefix length in libgit2 before v0.26.2 allows an attacker to cause a denial of service ( out-of-bounds read ) via a crafted repository index file . 612 612 30.17074966430664 30004 1322.5996494293213 ms
1 A flaw was found in libgit2 before version 0.27.3 . A missing check in git_delta_apply function in delta.c file , may lead to an out-of-bound read while reading a binary delta file . An attacker may use this flaw to cause a Denial of Service . 621 621 30.890451431274414 45006 855.6104898452759 ms
2 The Git Smart Protocol support in libgit2 before 0.24.6 and 0.25.x before 0.25.1 allows remote attackers to cause a denial of service ( NULL pointer dereference ) via an empty packet line . 477 477 30.885709762573242 45007 683.1045150756836 ms
3 An issue was discovered in libgit2 before 0.28.4 and 0.9x before 0.99.0. path.c mishandles equivalent filenames that exist because of NTFS Alternate Data Streams . This may allow remote code execution when cloning a repository . This issue is similar to CVE-2019-1352 . 435 435 30.82593536376953 45007 593.4287905693054 ms
4 Incorrect returning of an error code in the index.c : read_entry ( ) function leads to a double free in libgit2 before v0.26.2 , which allows an attacker to cause a denial of service via a crafted repository index file . 630 630 30.486064910888672 30004 543.6655521392822 ms
5 In ng_pkt in transports/smart_pkt.c in libgit2 before 0.26.6 and 0.27.x before 0.27.4 , a remote attacker can send a crafted smart-protocol `` ng '' packet that lacks a '\0 ' byte to trigger an out-of-bounds read that leads to DoS . 856 856 30.859012603759766 45007 511.0830068588257 ms
6 Buffer overflow in the git_pkt_parse_line function in transports/smart_pkt.c in the Git Smart Protocol support in libgit2 before 0.24.6 and 0.25.x before 0.25.1 allows remote attackers to have unspecified impact via a crafted non-flush packet . 837 837 31.158021926879883 30000 486.4781584058489 ms
7 A flaw was found in libgit2 before version 0.27.3 . It has been discovered that an unexpected sign extension in git_delta_apply function in delta.c file may lead to an integer overflow which in turn leads to an out of bound read , allowing to read before the base object . An attacker may use this flaw to leak memory addresses or cause a Denial of Service . 495 495 30.812789916992188 45007 466.00908041000366 ms
8 The http_connect function in transports/http.c in libgit2 before 0.24.6 and 0.25.x before 0.25.1 might allow man-in-the-middle attackers to spoof servers by leveraging clobbering of the error variable . 603 603 30.71517562866211 45007 450.5360656314426 ms
[Oct 01, 08:53:49] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libgit2_libgit2/retrieve.py/2023-10-01_08.53.21/ranking.tsv
#> Done.




2023-10-01 08:53:52,375 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:53:52,376 INFO rerun retrieving libidn_libidn2
2023-10-01 08:54:18,821 INFO 

[Oct 01, 08:53:54] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libidn_libidn2/retrieve.py/2023-10-01_08.53.54 




[Oct 01, 08:53:56] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libidn_libidn2/retrieve.py/2023-10-01_08.53.54/logs/ 


[Oct 01, 08:53:57] {'root': 'run/retrieve_output', 'experiment': 'libidn_libidn2', 'run': '2023-10-01_08.53.54', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/libidn_libidn2.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/libidn_libidn2', 'index_name': 'libidn_libidn2', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:54:08] #> Loading model checkpoint.
[Oct 01, 08:54:08] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:54:09] #> checkpoint['epoch'] = 0
[Oct 01, 08:54:09] #> checkpoint['batch'] = 346000
[Oct 01, 08:54:09] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:54:09] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/libidn_libidn2.tsv ...
[Oct 01, 08:54:09] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:54:11] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/libidn_libidn2/libidn_libidn2/ivfpq.70.faiss ..
[Oct 01, 08:54:11] #> Building the emb2pid mapping..
[Oct 01, 08:54:11] len(self.emb2pid) = 174314
[Oct 01, 08:54:12] tensor.size() =  torch.Size([174826, 128])
[Oct 01, 08:54:12] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/libidn_libidn2/libidn_libidn2/0.pt ...
[Oct 01, 08:54:12] #> Using strides [311, 421]..
[Oct 01, 08:54:15] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libidn_libidn2/retrieve.py/2023-10-01_08.53.54/ranking.tsv
0 idn2_to_ascii_4i in lib/lookup.c in GNU libidn2 before 2.1.1 has a heap-based buffer overflow via a long domain string . 555 555 29.401615142822266 976 993.3350086212158 ms
[Oct 01, 08:54:16] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libidn_libidn2/retrieve.py/2023-10-01_08.53.54/ranking.tsv
#> Done.




2023-10-01 08:54:18,821 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:54:18,822 INFO rerun retrieving libofx_libofx
2023-10-01 08:54:45,050 INFO 

[Oct 01, 08:54:20] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libofx_libofx/retrieve.py/2023-10-01_08.54.20 




[Oct 01, 08:54:22] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libofx_libofx/retrieve.py/2023-10-01_08.54.20/logs/ 


[Oct 01, 08:54:24] {'root': 'run/retrieve_output', 'experiment': 'libofx_libofx', 'run': '2023-10-01_08.54.20', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/libofx_libofx.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/libofx_libofx', 'index_name': 'libofx_libofx', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:54:34] #> Loading model checkpoint.
[Oct 01, 08:54:34] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:54:35] #> checkpoint['epoch'] = 0
[Oct 01, 08:54:35] #> checkpoint['batch'] = 346000
[Oct 01, 08:54:35] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:54:35] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/libofx_libofx.tsv ...
[Oct 01, 08:54:35] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:54:38] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/libofx_libofx/libofx_libofx/ivfpq.70.faiss ..
[Oct 01, 08:54:38] #> Building the emb2pid mapping..
[Oct 01, 08:54:38] len(self.emb2pid) = 73856
[Oct 01, 08:54:39] tensor.size() =  torch.Size([74368, 128])
[Oct 01, 08:54:39] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/libofx_libofx/libofx_libofx/0.pt ...
[Oct 01, 08:54:39] #> Using strides [342, 404]..
[Oct 01, 08:54:41] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libofx_libofx/retrieve.py/2023-10-01_08.54.20/ranking.tsv
0 An memory corruption vulnerability exists in the .SVG parsing functionality of Computerinsel Photoline 20.02 . A specially crafted .SVG file can cause a vulnerability resulting in memory corruption , which can potentially lead to arbitrary code execution . An attacker can send a specific .SVG file to trigger this vulnerability . 14 14 29.388160705566406 330 852.0112037658691 ms
[Oct 01, 08:54:42] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libofx_libofx/retrieve.py/2023-10-01_08.54.20/ranking.tsv
#> Done.




2023-10-01 08:54:45,050 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:54:45,051 INFO rerun retrieving libtom_libtomcrypt
2023-10-01 08:55:11,693 INFO 

[Oct 01, 08:54:47] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libtom_libtomcrypt/retrieve.py/2023-10-01_08.54.46 




[Oct 01, 08:54:49] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libtom_libtomcrypt/retrieve.py/2023-10-01_08.54.46/logs/ 


[Oct 01, 08:54:50] {'root': 'run/retrieve_output', 'experiment': 'libtom_libtomcrypt', 'run': '2023-10-01_08.54.46', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/libtom_libtomcrypt.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/libtom_libtomcrypt', 'index_name': 'libtom_libtomcrypt', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:55:01] #> Loading model checkpoint.
[Oct 01, 08:55:01] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:55:02] #> checkpoint['epoch'] = 0
[Oct 01, 08:55:02] #> checkpoint['batch'] = 346000
[Oct 01, 08:55:02] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:55:02] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/libtom_libtomcrypt.tsv ...
[Oct 01, 08:55:02] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:55:04] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/libtom_libtomcrypt/libtom_libtomcrypt/ivfpq.70.faiss ..
[Oct 01, 08:55:04] #> Building the emb2pid mapping..
[Oct 01, 08:55:04] len(self.emb2pid) = 401560
[Oct 01, 08:55:05] tensor.size() =  torch.Size([402072, 128])
[Oct 01, 08:55:05] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/libtom_libtomcrypt/libtom_libtomcrypt/0.pt ...
[Oct 01, 08:55:05] #> Using strides [318, 461]..
[Oct 01, 08:55:08] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libtom_libtomcrypt/retrieve.py/2023-10-01_08.54.46/ranking.tsv
0 The rsa_verify_hash_ex function in rsa_verify_hash.c in LibTomCrypt , as used in OP-TEE before 2.2.0 , does not validate that the message length is equal to the ASN.1 encoded data length , which makes it easier for remote attackers to forge RSA signatures or public certificates by leveraging a Bleichenbacher signature forgery attack . 39 39 28.382375717163086 2154 1024.674892425537 ms
[Oct 01, 08:55:09] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/libtom_libtomcrypt/retrieve.py/2023-10-01_08.54.46/ranking.tsv
#> Done.




2023-10-01 08:55:11,694 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:55:11,695 INFO rerun retrieving madler_pigz
2023-10-01 08:55:37,680 INFO 

[Oct 01, 08:55:13] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/madler_pigz/retrieve.py/2023-10-01_08.55.13 




[Oct 01, 08:55:15] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/madler_pigz/retrieve.py/2023-10-01_08.55.13/logs/ 


[Oct 01, 08:55:17] {'root': 'run/retrieve_output', 'experiment': 'madler_pigz', 'run': '2023-10-01_08.55.13', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/madler_pigz.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/madler_pigz', 'index_name': 'madler_pigz', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:55:27] #> Loading model checkpoint.
[Oct 01, 08:55:27] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:55:28] #> checkpoint['epoch'] = 0
[Oct 01, 08:55:28] #> checkpoint['batch'] = 346000
[Oct 01, 08:55:28] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:55:28] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/madler_pigz.tsv ...
[Oct 01, 08:55:28] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:55:30] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/madler_pigz/madler_pigz/ivfpq.70.faiss ..
[Oct 01, 08:55:30] #> Building the emb2pid mapping..
[Oct 01, 08:55:30] len(self.emb2pid) = 48237
[Oct 01, 08:55:31] tensor.size() =  torch.Size([48749, 128])
[Oct 01, 08:55:31] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/madler_pigz/madler_pigz/0.pt ...
[Oct 01, 08:55:31] #> Using strides [324, 396]..
[Oct 01, 08:55:34] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/madler_pigz/retrieve.py/2023-10-01_08.55.13/ranking.tsv
0 Multiple directory traversal vulnerabilities in pigz 2.3.1 allow remote attackers to write to arbitrary files via a ( 1 ) full pathname or ( 2 ) .. ( dot dot ) in an archive . 189 189 30.438337326049805 247 962.9671573638916 ms
[Oct 01, 08:55:35] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/madler_pigz/retrieve.py/2023-10-01_08.55.13/ranking.tsv
#> Done.




2023-10-01 08:55:37,680 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:55:37,681 INFO rerun retrieving maekitalo_tntnet
2023-10-01 08:56:05,593 INFO 

[Oct 01, 08:55:39] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/maekitalo_tntnet/retrieve.py/2023-10-01_08.55.39 




[Oct 01, 08:55:41] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/maekitalo_tntnet/retrieve.py/2023-10-01_08.55.39/logs/ 


[Oct 01, 08:55:43] {'root': 'run/retrieve_output', 'experiment': 'maekitalo_tntnet', 'run': '2023-10-01_08.55.39', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/maekitalo_tntnet.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/maekitalo_tntnet', 'index_name': 'maekitalo_tntnet', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:55:54] #> Loading model checkpoint.
[Oct 01, 08:55:54] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:55:55] #> checkpoint['epoch'] = 0
[Oct 01, 08:55:55] #> checkpoint['batch'] = 346000
[Oct 01, 08:55:55] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:55:55] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/maekitalo_tntnet.tsv ...
[Oct 01, 08:55:55] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:55:58] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/maekitalo_tntnet/maekitalo_tntnet/ivfpq.70.faiss ..
[Oct 01, 08:55:58] #> Building the emb2pid mapping..
[Oct 01, 08:55:58] len(self.emb2pid) = 367795
[Oct 01, 08:55:59] tensor.size() =  torch.Size([368307, 128])
[Oct 01, 08:55:59] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/maekitalo_tntnet/maekitalo_tntnet/0.pt ...
[Oct 01, 08:55:59] #> Using strides [307, 466]..
[Oct 01, 08:56:01] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/maekitalo_tntnet/retrieve.py/2023-10-01_08.55.39/ranking.tsv
0 framework/common/messageheaderparser.cpp in Tntnet before 2.2.1 allows remote attackers to obtain sensitive information via a header that ends in \n instead of \r\n , which prevents a null terminator from being added and causes Tntnet to include headers from other requests . 530 530 21.490821838378906 1833 1003.9036273956299 ms
[Oct 01, 08:56:02] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/maekitalo_tntnet/retrieve.py/2023-10-01_08.55.39/ranking.tsv
#> Done.




2023-10-01 08:56:05,593 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:56:05,594 INFO rerun retrieving michaelrsweet_htmldoc
2023-10-01 08:56:32,408 INFO 

[Oct 01, 08:56:07] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/michaelrsweet_htmldoc/retrieve.py/2023-10-01_08.56.07 




[Oct 01, 08:56:09] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/michaelrsweet_htmldoc/retrieve.py/2023-10-01_08.56.07/logs/ 


[Oct 01, 08:56:10] {'root': 'run/retrieve_output', 'experiment': 'michaelrsweet_htmldoc', 'run': '2023-10-01_08.56.07', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/michaelrsweet_htmldoc.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/michaelrsweet_htmldoc', 'index_name': 'michaelrsweet_htmldoc', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:56:21] #> Loading model checkpoint.
[Oct 01, 08:56:21] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:56:22] #> checkpoint['epoch'] = 0
[Oct 01, 08:56:22] #> checkpoint['batch'] = 346000
[Oct 01, 08:56:22] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:56:22] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/michaelrsweet_htmldoc.tsv ...
[Oct 01, 08:56:22] #> Got 3 queries. All QIDs are unique.

[Oct 01, 08:56:24] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/michaelrsweet_htmldoc/michaelrsweet_htmldoc/ivfpq.70.faiss ..
[Oct 01, 08:56:24] #> Building the emb2pid mapping..
[Oct 01, 08:56:24] len(self.emb2pid) = 688324
[Oct 01, 08:56:25] tensor.size() =  torch.Size([688836, 128])
[Oct 01, 08:56:25] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/michaelrsweet_htmldoc/michaelrsweet_htmldoc/0.pt ...
[Oct 01, 08:56:25] #> Using strides [318, 454]..
[Oct 01, 08:56:28] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/michaelrsweet_htmldoc/retrieve.py/2023-10-01_08.56.07/ranking.tsv
0 A flaw was found in htmldoc in v1.9.12 and before . Null pointer dereference in file_extension ( ) , in file.c may lead to execute arbitrary code and denial of service . 33 33 26.85584259033203 3029 980.2601337432861 ms
1 A flaw was found in htmldoc in v1.9.12 . Double-free in function pspdf_export ( ) , in ps-pdf.cxx may result in a write-what-where condition , allowing an attacker to execute arbitrary code and denial of service . 36 36 26.628551483154297 3029 517.5513029098511 ms
2 A security issue was found in htmldoc v1.9.12 and before . A NULL pointer dereference in the function image_load_jpeg ( ) in image.cxx may result in denial of service . 33 33 26.17458724975586 3029 362.50774065653485 ms
[Oct 01, 08:56:29] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/michaelrsweet_htmldoc/retrieve.py/2023-10-01_08.56.07/ranking.tsv
#> Done.




2023-10-01 08:56:32,408 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:56:32,409 INFO rerun retrieving miniupnp_ngiflib
2023-10-01 08:56:58,668 INFO 

[Oct 01, 08:56:34] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/miniupnp_ngiflib/retrieve.py/2023-10-01_08.56.34 




[Oct 01, 08:56:36] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/miniupnp_ngiflib/retrieve.py/2023-10-01_08.56.34/logs/ 


[Oct 01, 08:56:37] {'root': 'run/retrieve_output', 'experiment': 'miniupnp_ngiflib', 'run': '2023-10-01_08.56.34', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/miniupnp_ngiflib.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/miniupnp_ngiflib', 'index_name': 'miniupnp_ngiflib', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:56:48] #> Loading model checkpoint.
[Oct 01, 08:56:48] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:56:49] #> checkpoint['epoch'] = 0
[Oct 01, 08:56:49] #> checkpoint['batch'] = 346000
[Oct 01, 08:56:49] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:56:49] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/miniupnp_ngiflib.tsv ...
[Oct 01, 08:56:49] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:56:51] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/miniupnp_ngiflib/miniupnp_ngiflib/ivfpq.70.faiss ..
[Oct 01, 08:56:51] #> Building the emb2pid mapping..
[Oct 01, 08:56:51] len(self.emb2pid) = 86946
[Oct 01, 08:56:53] tensor.size() =  torch.Size([87458, 128])
[Oct 01, 08:56:53] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/miniupnp_ngiflib/miniupnp_ngiflib/0.pt ...
[Oct 01, 08:56:53] #> Using strides [276, 335]..
[Oct 01, 08:56:55] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/miniupnp_ngiflib/retrieve.py/2023-10-01_08.56.34/ranking.tsv
0 ngiflib 0.4 has a heap-based buffer overflow in WritePixels ( ) in ngiflib.c when called from DecodeGifImg , because deinterlacing for small pictures is mishandled . 160 160 26.778728485107422 136 847.4678993225098 ms
1 The DecodeGifImg function in ngiflib.c in MiniUPnP ngiflib 0.4 lacks certain checks against width and height , which allows remote attackers to cause a denial of service ( WritePixels heap-based buffer overflow and application crash ) or possibly have unspecified other impact via a crafted GIF file . 228 228 27.500654220581055 545 444.4073438644409 ms
2 ngiflib 0.4 has a heap-based buffer overflow in WritePixel ( ) in ngiflib.c when called from DecodeGifImg , because deinterlacing for small pictures is mishandled . 156 156 26.818939208984375 136 305.70324261983234 ms
3 The DecodeGifImg function in ngiflib.c in MiniUPnP ngiflib 0.4 does not consider the bounds of the pixels data structure , which allows remote attackers to cause a denial of service ( WritePixels heap-based buffer overflow and application crash ) or possibly have unspecified other impact via a crafted GIF file , a different vulnerability than CVE-2018-10677 . 232 232 27.113636016845703 545 237.310528755188 ms
[Oct 01, 08:56:56] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/miniupnp_ngiflib/retrieve.py/2023-10-01_08.56.34/ranking.tsv
#> Done.




2023-10-01 08:56:58,668 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:56:58,669 INFO rerun retrieving mjg59_linux
2023-10-01 08:57:26,316 INFO 

[Oct 01, 08:57:00] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/mjg59_linux/retrieve.py/2023-10-01_08.57.00 




[Oct 01, 08:57:02] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/mjg59_linux/retrieve.py/2023-10-01_08.57.00/logs/ 


[Oct 01, 08:57:04] {'root': 'run/retrieve_output', 'experiment': 'mjg59_linux', 'run': '2023-10-01_08.57.00', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/mjg59_linux.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/mjg59_linux', 'index_name': 'mjg59_linux', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:57:14] #> Loading model checkpoint.
[Oct 01, 08:57:14] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:57:15] #> checkpoint['epoch'] = 0
[Oct 01, 08:57:15] #> checkpoint['batch'] = 346000
[Oct 01, 08:57:15] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:57:15] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/mjg59_linux.tsv ...
[Oct 01, 08:57:15] #> Got 3 queries. All QIDs are unique.

[Oct 01, 08:57:17] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/mjg59_linux/mjg59_linux/ivfpq.70.faiss ..
[Oct 01, 08:57:18] #> Building the emb2pid mapping..
[Oct 01, 08:57:18] len(self.emb2pid) = 4076563
[Oct 01, 08:57:19] tensor.size() =  torch.Size([4077075, 128])
[Oct 01, 08:57:19] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/mjg59_linux/mjg59_linux/0.pt ...
[Oct 01, 08:57:20] #> Using strides [354, 463]..
[Oct 01, 08:57:22] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/mjg59_linux/retrieve.py/2023-10-01_08.57.00/ranking.tsv
0 The Linux kernel , as used in Red Hat Enterprise Linux 7.2 and Red Hat Enterprise MRG 2 and when booted with UEFI Secure Boot enabled , allows local users to bypass intended Secure Boot restrictions and execute untrusted code by appending ACPI tables to the initrd . 12 12 29.82586669921875 5000 1008.4137916564941 ms
1 The einj_error_inject function in drivers/acpi/apei/einj.c in the Linux kernel allows local users to simulate hardware errors and consequently cause a denial of service by leveraging failure to disable APEI error injection through EINJ when securelevel is set . 12 12 30.899776458740234 15001 611.7923259735107 ms
2 The Linux kernel , as used in Red Hat Enterprise Linux 7 , kernel-rt , and Enterprise MRG 2 and when booted with UEFI Secure Boot enabled , allows local users to bypass intended securelevel/secureboot restrictions by leveraging improper handling of secure_boot flag across kexec reboot . 12 12 29.56736183166504 5000 465.9971396128337 ms
[Oct 01, 08:57:23] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/mjg59_linux/retrieve.py/2023-10-01_08.57.00/ranking.tsv
#> Done.




2023-10-01 08:57:26,317 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:57:26,318 INFO rerun retrieving netblue30_firejail
2023-10-01 08:57:55,034 INFO 

[Oct 01, 08:57:28] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netblue30_firejail/retrieve.py/2023-10-01_08.57.28 




[Oct 01, 08:57:30] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netblue30_firejail/retrieve.py/2023-10-01_08.57.28/logs/ 


[Oct 01, 08:57:32] {'root': 'run/retrieve_output', 'experiment': 'netblue30_firejail', 'run': '2023-10-01_08.57.28', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/netblue30_firejail.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/netblue30_firejail', 'index_name': 'netblue30_firejail', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:57:43] #> Loading model checkpoint.
[Oct 01, 08:57:43] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:57:44] #> checkpoint['epoch'] = 0
[Oct 01, 08:57:44] #> checkpoint['batch'] = 346000
[Oct 01, 08:57:44] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:57:44] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/netblue30_firejail.tsv ...
[Oct 01, 08:57:44] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:57:46] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/netblue30_firejail/netblue30_firejail/ivfpq.70.faiss ..
[Oct 01, 08:57:46] #> Building the emb2pid mapping..
[Oct 01, 08:57:46] len(self.emb2pid) = 3161179
[Oct 01, 08:57:48] tensor.size() =  torch.Size([3161691, 128])
[Oct 01, 08:57:48] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/netblue30_firejail/netblue30_firejail/0.pt ...
[Oct 01, 08:57:48] #> Using strides [307, 449]..
[Oct 01, 08:57:50] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netblue30_firejail/retrieve.py/2023-10-01_08.57.28/ranking.tsv
0 Firejail before 0.9.44.4 , when running a bandwidth command , allows local users to gain root privileges via the -- shell argument . 570 570 29.493804931640625 20001 1060.936689376831 ms
1 Firejail before 0.9.44.4 , when running on a Linux kernel before 4.8 , allows context-dependent attackers to bypass a seccomp-based sandbox protection mechanism via the -- allow-debuggers argument . 509 509 29.251867294311523 20001 607.8643798828125 ms
2 In Firejail before 0.9.60 , seccomp filters are writable inside the jail , leading to a lack of intended seccomp restrictions for a process that is joined to the jail after a filter has been modified by an attacker . 628 628 28.671985626220703 20001 460.16112963358563 ms
3 Firejail before 0.9.44.6 and 0.9.38.x LTS before 0.9.38.10 LTS does not comprehensively address dotfile cases during its attempt to prevent accessing user files with an euid of zero , which allows local users to conduct sandbox-escape attacks via vectors involving a symlink and the -- private option . NOTE : this vulnerability exists because of an incomplete fix for CVE-2017-5180 . 593 593 29.188152313232422 20001 385.1292133331299 ms
[Oct 01, 08:57:52] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netblue30_firejail/retrieve.py/2023-10-01_08.57.28/ranking.tsv
#> Done.




2023-10-01 08:57:55,035 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:57:55,036 INFO rerun retrieving netdata_netdata
2023-10-01 08:58:21,714 INFO 

[Oct 01, 08:57:57] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netdata_netdata/retrieve.py/2023-10-01_08.57.56 




[Oct 01, 08:57:59] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netdata_netdata/retrieve.py/2023-10-01_08.57.56/logs/ 


[Oct 01, 08:58:00] {'root': 'run/retrieve_output', 'experiment': 'netdata_netdata', 'run': '2023-10-01_08.57.56', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/netdata_netdata.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/netdata_netdata', 'index_name': 'netdata_netdata', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:58:11] #> Loading model checkpoint.
[Oct 01, 08:58:11] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:58:12] #> checkpoint['epoch'] = 0
[Oct 01, 08:58:12] #> checkpoint['batch'] = 346000
[Oct 01, 08:58:12] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:58:12] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/netdata_netdata.tsv ...
[Oct 01, 08:58:12] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:58:14] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/netdata_netdata/netdata_netdata/ivfpq.70.faiss ..
[Oct 01, 08:58:14] #> Building the emb2pid mapping..
[Oct 01, 08:58:14] len(self.emb2pid) = 840366
[Oct 01, 08:58:16] tensor.size() =  torch.Size([840878, 128])
[Oct 01, 08:58:16] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/netdata_netdata/netdata_netdata/0.pt ...
[Oct 01, 08:58:16] #> Using strides [303, 448]..
[Oct 01, 08:58:18] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netdata_netdata/retrieve.py/2023-10-01_08.57.56/ranking.tsv
0 * * DISPUTED * * An issue was discovered in Netdata 1.10.0 . Full Path Disclosure ( FPD ) exists via api/v1/alarms . NOTE : the vendor says `` is intentional . '' 77 77 29.3127384185791 4995 894.707441329956 ms
[Oct 01, 08:58:19] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/netdata_netdata/retrieve.py/2023-10-01_08.57.56/ranking.tsv
#> Done.




2023-10-01 08:58:21,714 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:58:21,715 INFO rerun retrieving ntop_nDPI
2023-10-01 08:58:52,029 INFO 

[Oct 01, 08:58:23] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ntop_nDPI/retrieve.py/2023-10-01_08.58.23 




[Oct 01, 08:58:25] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ntop_nDPI/retrieve.py/2023-10-01_08.58.23/logs/ 


[Oct 01, 08:58:27] {'root': 'run/retrieve_output', 'experiment': 'ntop_nDPI', 'run': '2023-10-01_08.58.23', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/ntop_nDPI.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/ntop_nDPI', 'index_name': 'ntop_nDPI', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:58:38] #> Loading model checkpoint.
[Oct 01, 08:58:38] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:58:39] #> checkpoint['epoch'] = 0
[Oct 01, 08:58:39] #> checkpoint['batch'] = 346000
[Oct 01, 08:58:39] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:58:39] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/ntop_nDPI.tsv ...
[Oct 01, 08:58:39] #> Got 8 queries. All QIDs are unique.

[Oct 01, 08:58:41] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/ntop_nDPI/ntop_nDPI/ivfpq.70.faiss ..
[Oct 01, 08:58:41] #> Building the emb2pid mapping..
[Oct 01, 08:58:41] len(self.emb2pid) = 5992756
[Oct 01, 08:58:43] tensor.size() =  torch.Size([5993268, 128])
[Oct 01, 08:58:43] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/ntop_nDPI/ntop_nDPI/0.pt ...
[Oct 01, 08:58:44] #> Using strides [308, 410]..
[Oct 01, 08:58:46] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ntop_nDPI/retrieve.py/2023-10-01_08.58.23/ranking.tsv
0 In nDPI through 3.2 , the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c . 146 146 30.93130111694336 31447 1131.5569877624512 ms
1 In nDPI through 3.2 , ndpi_reset_packet_line_info in lib/ndpi_main.c omits certain reinitialization , leading to a use-after-free . 376 376 29.75790786743164 31447 707.0819139480591 ms
2 In nDPI through 3.2 Stable , the SSH protocol dissector has multiple KEXINIT integer overflows that result in a controlled remote heap overflow in concat_hash_string in ssh.c . Due to the granular nature of the overflow primitive and the ability to control both the contents and layout of the nDPI library 's heap memory through remote input , this vulnerability may be abused to achieve full Remote Code Execution against any network inspection stack that is linked against nDPI and uses it to perform network traffic analysis . 232 232 30.01831817626953 31447 553.9604822794596 ms
3 In nDPI through 3.2 , the Oracle protocol dissector has a heap-based buffer over-read in ndpi_search_oracle in lib/protocols/oracle.c . 192 192 30.86667251586914 31447 475.0409722328186 ms
4 In nDPI through 3.2 , the OpenVPN dissector is vulnerable to a heap-based buffer over-read in ndpi_search_openvpn in lib/protocols/openvpn.c . 192 192 30.196096420288086 31447 428.6308765411377 ms
5 In nDPI through 3.2 Stable , an out-of-bounds read in concat_hash_string in ssh.c can be exploited by a network-positioned attacker that can send malformed SSH protocol messages on a network segment monitored by nDPI 's library . 278 278 30.667770385742188 31442 397.6993163426717 ms
6 In nDPI through 3.2 , there is a stack overflow in extractRDNSequence in lib/protocols/tls.c . 320 320 30.540115356445312 31445 375.38347925458635 ms
7 In nDPI through 3.2 , the H.323 dissector is vulnerable to a heap-based buffer over-read in ndpi_search_h323 in lib/protocols/h323.c , as demonstrated by a payload packet length that is too short . 152 152 30.894004821777344 31447 358.4108352661133 ms
[Oct 01, 08:58:49] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/ntop_nDPI/retrieve.py/2023-10-01_08.58.23/ranking.tsv
#> Done.




2023-10-01 08:58:52,030 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:58:52,031 INFO rerun retrieving open5gs_open5gs
2023-10-01 08:59:19,863 INFO 

[Oct 01, 08:58:54] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/open5gs_open5gs/retrieve.py/2023-10-01_08.58.53 




[Oct 01, 08:58:56] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/open5gs_open5gs/retrieve.py/2023-10-01_08.58.53/logs/ 


[Oct 01, 08:58:57] {'root': 'run/retrieve_output', 'experiment': 'open5gs_open5gs', 'run': '2023-10-01_08.58.53', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/open5gs_open5gs.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/open5gs_open5gs', 'index_name': 'open5gs_open5gs', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:59:08] #> Loading model checkpoint.
[Oct 01, 08:59:08] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:59:09] #> checkpoint['epoch'] = 0
[Oct 01, 08:59:09] #> checkpoint['batch'] = 346000
[Oct 01, 08:59:09] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:59:09] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/open5gs_open5gs.tsv ...
[Oct 01, 08:59:09] #> Got 4 queries. All QIDs are unique.

[Oct 01, 08:59:11] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/open5gs_open5gs/open5gs_open5gs/ivfpq.70.faiss ..
[Oct 01, 08:59:11] #> Building the emb2pid mapping..
[Oct 01, 08:59:11] len(self.emb2pid) = 3541176
[Oct 01, 08:59:13] tensor.size() =  torch.Size([3541688, 128])
[Oct 01, 08:59:13] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/open5gs_open5gs/open5gs_open5gs/0.pt ...
[Oct 01, 08:59:13] #> Using strides [309, 419]..
[Oct 01, 08:59:15] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/open5gs_open5gs/retrieve.py/2023-10-01_08.58.53/ranking.tsv
0 In Open5GS 2.4.0 , a crafted packet from UE can crash SGW-U/UPF . 64 64 29.35651397705078 15387 962.4793529510498 ms
1 A buffer overflow in lib/sbi/message.c in Open5GS 2.3.6 and earlier allows remote attackers to Denial of Service via a crafted sbi request . 56 56 30.604278564453125 15387 575.3123760223389 ms
2 A null pointer dereference in src/amf/namf-handler.c in Open5GS 2.3.6 and earlier allows remote attackers to Denial of Service via a crafted sbi request to amf . 68 68 30.006811141967773 15387 441.01754824320477 ms
3 A vulnerability was found in Open5GS up to 2.4.10 . It has been declared as problematic . Affected by this vulnerability is an unknown functionality in the library lib/sbi/client.c of the component AMF . The manipulation leads to denial of service . The attack can be launched remotely . The name of the patch is 724fa568435dae45ef0c3a48b2aabde052afae88 . It is recommended to apply a patch to fix this issue . The identifier VDB-209545 was assigned to this vulnerability . 52 52 30.686309814453125 15387 374.04531240463257 ms
[Oct 01, 08:59:17] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/open5gs_open5gs/retrieve.py/2023-10-01_08.58.53/ranking.tsv
#> Done.




2023-10-01 08:59:19,864 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:59:19,865 INFO rerun retrieving opencryptoki_opencryptoki
2023-10-01 08:59:46,477 INFO 

[Oct 01, 08:59:22] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/opencryptoki_opencryptoki/retrieve.py/2023-10-01_08.59.21 




[Oct 01, 08:59:24] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/opencryptoki_opencryptoki/retrieve.py/2023-10-01_08.59.21/logs/ 


[Oct 01, 08:59:25] {'root': 'run/retrieve_output', 'experiment': 'opencryptoki_opencryptoki', 'run': '2023-10-01_08.59.21', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/opencryptoki_opencryptoki.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/opencryptoki_opencryptoki', 'index_name': 'opencryptoki_opencryptoki', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 08:59:36] #> Loading model checkpoint.
[Oct 01, 08:59:36] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 08:59:37] #> checkpoint['epoch'] = 0
[Oct 01, 08:59:37] #> checkpoint['batch'] = 346000
[Oct 01, 08:59:37] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 08:59:37] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/opencryptoki_opencryptoki.tsv ...
[Oct 01, 08:59:37] #> Got 1 queries. All QIDs are unique.

[Oct 01, 08:59:39] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/opencryptoki_opencryptoki/opencryptoki_opencryptoki/ivfpq.70.faiss ..
[Oct 01, 08:59:39] #> Building the emb2pid mapping..
[Oct 01, 08:59:39] len(self.emb2pid) = 705295
[Oct 01, 08:59:41] tensor.size() =  torch.Size([705807, 128])
[Oct 01, 08:59:41] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/opencryptoki_opencryptoki/opencryptoki_opencryptoki/0.pt ...
[Oct 01, 08:59:41] #> Using strides [329, 428]..
[Oct 01, 08:59:43] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/opencryptoki_opencryptoki/retrieve.py/2023-10-01_08.59.21/ranking.tsv
0 A flaw was found in openCryptoki . The openCryptoki Soft token does not check if an EC key is valid when an EC key is created via C_CreateObject , nor when C_DeriveKey is used with ECDH public data . This may allow a malicious user to extract the private key by performing an invalid curve attack . 765 765 29.356685638427734 2760 847.062349319458 ms
[Oct 01, 08:59:43] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/opencryptoki_opencryptoki/retrieve.py/2023-10-01_08.59.21/ranking.tsv
#> Done.




2023-10-01 08:59:46,477 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 08:59:46,478 INFO rerun retrieving projectacrn_acrn-hypervisor
2023-10-01 09:00:14,718 INFO 

[Oct 01, 08:59:48] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/projectacrn_acrn-hypervisor/retrieve.py/2023-10-01_08.59.48 




[Oct 01, 08:59:50] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/projectacrn_acrn-hypervisor/retrieve.py/2023-10-01_08.59.48/logs/ 


[Oct 01, 08:59:52] {'root': 'run/retrieve_output', 'experiment': 'projectacrn_acrn-hypervisor', 'run': '2023-10-01_08.59.48', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/projectacrn_acrn-hypervisor.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/projectacrn_acrn-hypervisor', 'index_name': 'projectacrn_acrn-hypervisor', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:00:03] #> Loading model checkpoint.
[Oct 01, 09:00:03] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:00:04] #> checkpoint['epoch'] = 0
[Oct 01, 09:00:04] #> checkpoint['batch'] = 346000
[Oct 01, 09:00:04] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:00:04] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/projectacrn_acrn-hypervisor.tsv ...
[Oct 01, 09:00:04] #> Got 3 queries. All QIDs are unique.

[Oct 01, 09:00:06] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/projectacrn_acrn-hypervisor/projectacrn_acrn-hypervisor/ivfpq.70.faiss ..
[Oct 01, 09:00:06] #> Building the emb2pid mapping..
[Oct 01, 09:00:06] len(self.emb2pid) = 4116673
[Oct 01, 09:00:08] tensor.size() =  torch.Size([4117185, 128])
[Oct 01, 09:00:08] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/projectacrn_acrn-hypervisor/projectacrn_acrn-hypervisor/0.pt ...
[Oct 01, 09:00:08] #> Using strides [342, 426]..
[Oct 01, 09:00:10] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/projectacrn_acrn-hypervisor/retrieve.py/2023-10-01_08.59.48/ranking.tsv
0 An issue was discovered in ACRN before 2.5. dmar_free_irte in hypervisor/arch/x86/vtd.c allows an irte_alloc_bitmap buffer overflow . 108 108 30.375934600830078 15002 993.0663108825684 ms
1 The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h ( instead of other mechanisms for propagating error information or diagnostic information ) , which might allow attackers to cause a denial of service ( assertion failure ) within pci core . This is fixed in 1.2 . 6199e653418e is a mitigation for pre-1.1 versions , whereas 2b3dedfb9ba1 is a mitigation for 1.1 . 111 111 30.21009063720703 15001 579.1068077087402 ms
2 ACRN before 2.5 has a hw/pci/virtio/virtio.c vq_endchains NULL Pointer Dereference . 111 111 30.769851684570312 15001 446.15864753723145 ms
[Oct 01, 09:00:12] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/projectacrn_acrn-hypervisor/retrieve.py/2023-10-01_08.59.48/ranking.tsv
#> Done.




2023-10-01 09:00:14,719 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:00:14,720 INFO rerun retrieving qpdf_qpdf
2023-10-01 09:00:43,882 INFO 

[Oct 01, 09:00:16] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/qpdf_qpdf/retrieve.py/2023-10-01_09.00.16 




[Oct 01, 09:00:18] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/qpdf_qpdf/retrieve.py/2023-10-01_09.00.16/logs/ 


[Oct 01, 09:00:20] {'root': 'run/retrieve_output', 'experiment': 'qpdf_qpdf', 'run': '2023-10-01_09.00.16', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/qpdf_qpdf.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/qpdf_qpdf', 'index_name': 'qpdf_qpdf', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:00:31] #> Loading model checkpoint.
[Oct 01, 09:00:31] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:00:31] #> checkpoint['epoch'] = 0
[Oct 01, 09:00:31] #> checkpoint['batch'] = 346000
[Oct 01, 09:00:31] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:00:31] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/qpdf_qpdf.tsv ...
[Oct 01, 09:00:31] #> Got 6 queries. All QIDs are unique.

[Oct 01, 09:00:34] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/qpdf_qpdf/qpdf_qpdf/ivfpq.70.faiss ..
[Oct 01, 09:00:34] #> Building the emb2pid mapping..
[Oct 01, 09:00:34] len(self.emb2pid) = 4085670
[Oct 01, 09:00:35] tensor.size() =  torch.Size([4086182, 128])
[Oct 01, 09:00:35] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/qpdf_qpdf/qpdf_qpdf/0.pt ...
[Oct 01, 09:00:36] #> Using strides [347, 450]..
[Oct 01, 09:00:39] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/qpdf_qpdf/retrieve.py/2023-10-01_09.00.16/ranking.tsv
0 An issue was discovered in QPDF before 7.0.0 . Endless recursion causes stack exhaustion in QPDFTokenizer : :resolveLiteral ( ) in QPDFTokenizer.cc , related to the QPDF : :resolve function in QPDF.cc . 24 24 30.623394012451172 16842 1111.2470626831055 ms
1 An issue was discovered in QPDF before 7.0.0 . There is an infinite loop due to looping xref tables in QPDF.cc . 24 24 30.786922454833984 16842 632.758617401123 ms
2 An issue was discovered in QPDF before 7.0.0 . There is an infinite loop in the QPDFWriter : :enqueueObject ( ) function in libqpdf/QPDFWriter.cc . 24 24 30.88486671447754 16842 482.8036626180013 ms
3 An issue was discovered in QPDF before 7.0.0 . There is a stack-based out-of-bounds read in the function iterate_rc4 in QPDF_encryption.cc . 24 24 30.996826171875 16842 402.71395444869995 ms
4 libqpdf.a in QPDF through 8.0.2 mishandles certain `` expected dictionary key but found non-name object '' cases , allowing remote attackers to cause a denial of service ( stack exhaustion ) , related to the QPDFObjectHandle and QPDF_Dictionary classes , because nesting in direct objects is not restricted . 24 24 30.148408889770508 16847 356.697940826416 ms
5 The tokenizer in QPDF 6.0.0 and 7.0.b1 is recursive for arrays and dictionaries , which allows remote attackers to cause a denial of service ( stack consumption and segmentation fault ) or possibly have unspecified other impact via a PDF document with a deep data structure , as demonstrated by a crash in QPDFObjectHandle : :parseInternal in libqpdf/QPDFObjectHandle.cc . 24 24 30.514755249023438 16842 327.167272567749 ms
[Oct 01, 09:00:41] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/qpdf_qpdf/retrieve.py/2023-10-01_09.00.16/ranking.tsv
#> Done.




2023-10-01 09:00:43,882 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:00:43,883 INFO rerun retrieving relan_exfat
2023-10-01 09:01:10,596 INFO 

[Oct 01, 09:00:45] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/relan_exfat/retrieve.py/2023-10-01_09.00.45 




[Oct 01, 09:00:48] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/relan_exfat/retrieve.py/2023-10-01_09.00.45/logs/ 


[Oct 01, 09:00:49] {'root': 'run/retrieve_output', 'experiment': 'relan_exfat', 'run': '2023-10-01_09.00.45', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/relan_exfat.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/relan_exfat', 'index_name': 'relan_exfat', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:01:00] #> Loading model checkpoint.
[Oct 01, 09:01:00] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:01:01] #> checkpoint['epoch'] = 0
[Oct 01, 09:01:01] #> checkpoint['batch'] = 346000
[Oct 01, 09:01:01] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:01:01] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/relan_exfat.tsv ...
[Oct 01, 09:01:01] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:01:03] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/relan_exfat/relan_exfat/ivfpq.70.faiss ..
[Oct 01, 09:01:03] #> Building the emb2pid mapping..
[Oct 01, 09:01:03] len(self.emb2pid) = 102305
[Oct 01, 09:01:04] tensor.size() =  torch.Size([102817, 128])
[Oct 01, 09:01:04] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/relan_exfat/relan_exfat/0.pt ...
[Oct 01, 09:01:04] #> Using strides [295, 383]..
[Oct 01, 09:01:07] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/relan_exfat/retrieve.py/2023-10-01_09.00.45/ranking.tsv
0 Heap-based buffer overflow in the verify_vbr_checksum function in exfatfsck in exfat-utils before 1.2.1 allows remote attackers to cause a denial of service ( infinite loop ) or possibly execute arbitrary code via a crafted filesystem . 323 323 28.736331939697266 542 972.7809429168701 ms
[Oct 01, 09:01:08] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/relan_exfat/retrieve.py/2023-10-01_09.00.45/ranking.tsv
#> Done.




2023-10-01 09:01:10,596 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:01:10,597 INFO rerun retrieving rizinorg_rizin
2023-10-01 09:01:42,017 INFO 

[Oct 01, 09:01:12] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/rizinorg_rizin/retrieve.py/2023-10-01_09.01.12 




[Oct 01, 09:01:14] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/rizinorg_rizin/retrieve.py/2023-10-01_09.01.12/logs/ 


[Oct 01, 09:01:16] {'root': 'run/retrieve_output', 'experiment': 'rizinorg_rizin', 'run': '2023-10-01_09.01.12', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/rizinorg_rizin.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/rizinorg_rizin', 'index_name': 'rizinorg_rizin', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:01:27] #> Loading model checkpoint.
[Oct 01, 09:01:27] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:01:28] #> checkpoint['epoch'] = 0
[Oct 01, 09:01:28] #> checkpoint['batch'] = 346000
[Oct 01, 09:01:28] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:01:28] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/rizinorg_rizin.tsv ...
[Oct 01, 09:01:28] #> Got 7 queries. All QIDs are unique.

[Oct 01, 09:01:30] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/rizinorg_rizin/rizinorg_rizin/ivfpq.70.faiss ..
[Oct 01, 09:01:30] #> Building the emb2pid mapping..
[Oct 01, 09:01:30] len(self.emb2pid) = 7173574
[Oct 01, 09:01:31] tensor.size() =  torch.Size([7174086, 128])
[Oct 01, 09:01:31] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/rizinorg_rizin/rizinorg_rizin/0.pt ...
[Oct 01, 09:01:33] #> Using strides [297, 413]..
[Oct 01, 09:01:36] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/rizinorg_rizin/retrieve.py/2023-10-01_09.01.12/ranking.tsv
0 Rizin is a UNIX-like reverse engineering framework and command-line toolset . Versions 0.4.0 and prior are vulnerable to an out-of-bounds write when getting data from dyld cache files . A user opening a malicious dyld cache file could be affected by this vulnerability , allowing an attacker to execute code on the user 's machine . Commit number 556ca2f9eef01ec0f4a76d1fbacfcf3a87a44810 contains a patch . 161 161 28.801116943359375 35000 1267.232894897461 ms
1 Rizin is a UNIX-like reverse engineering framework and command-line toolset . Versions 0.4.0 and prior are vulnerable to a double free in bobj.c : rz_bin_reloc_storage_free ( ) when freeing relocations generated from qnx binary plugin . A user opening a malicious qnx binary could be affected by this vulnerability , allowing an attacker to execute code on the user 's machine . Commit number a3d50c1ea185f3f642f2d8180715f82d98840784 contains a patch for this issue . 161 161 28.826112747192383 35000 768.5599327087402 ms
2 Rizin is a UNIX-like reverse engineering framework and command-line toolset . In versions up to and including 0.3.1 there is a heap-based out of bounds write in parse_die ( ) when reversing an AMD64 ELF binary with DWARF debug info . When a malicious AMD64 ELF binary is opened by a victim user , Rizin may crash or execute unintended actions . No workaround are known and users are advised to upgrade . 168 168 28.76873016357422 35000 605.1062742869059 ms
3 Rizin is a UNIX-like reverse engineering framework and command-line toolset . Versions 0.4.0 and prior are vulnerable to out-of-bounds write when parsing DEX files . A user opening a malicious DEX file could be affected by this vulnerability , allowing an attacker to execute code on the user 's machine . A patch is available on the ` dev ` branch of the repository . 161 161 28.784635543823242 35000 535.5075001716614 ms
4 Rizin is a UNIX-like reverse engineering framework and command-line toolset . Versions 0.4.0 and prior are vulnerable to an out-of-bounds write when getting data from PYC ( python ) files . A user opening a malicious PYC file could be affected by this vulnerability , allowing an attacker to execute code on the user 's machine . Commit number 68948017423a12786704e54227b8b2f918c2fd27 contains a patch . 161 161 28.801116943359375 35000 482.7815532684326 ms
5 Rizin is a UNIX-like reverse engineering framework and command-line toolset . Versions 0.4.0 and prior are vulnerable to an out-of-bounds write when getting data from Luac files . A user opening a malicious Luac file could be affected by this vulnerability , allowing an attacker to execute code on the user 's machine . Commits 07b43bc8aa1ffebd9b68d60624c9610cf7e460c7 and 05bbd147caccc60162d6fba9baaaf24befa281cd contain fixes for the issue . 161 161 28.801116943359375 35000 446.89913590749103 ms
6 Rizin is a UNIX-like reverse engineering framework and command-line toolset . Versions 0.4.0 and prior are vulnerable to an out-of-bounds write when parsing Mach-O files . A user opening a malicious Mach-O file could be affected by this vulnerability , allowing an attacker to execute code on the user 's machine . Commit number 7323e64d68ecccfb0ed3ee480f704384c38676b2 contains a patch . 161 161 28.801116943359375 35000 421.3588237762451 ms
[Oct 01, 09:01:39] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/rizinorg_rizin/retrieve.py/2023-10-01_09.01.12/ranking.tsv
#> Done.




2023-10-01 09:01:42,017 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:01:42,018 INFO rerun retrieving shadowsocks_shadowsocks-libev
2023-10-01 09:02:08,880 INFO 

[Oct 01, 09:01:44] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shadowsocks_shadowsocks-libev/retrieve.py/2023-10-01_09.01.43 




[Oct 01, 09:01:46] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shadowsocks_shadowsocks-libev/retrieve.py/2023-10-01_09.01.43/logs/ 


[Oct 01, 09:01:47] {'root': 'run/retrieve_output', 'experiment': 'shadowsocks_shadowsocks-libev', 'run': '2023-10-01_09.01.43', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/shadowsocks_shadowsocks-libev.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/shadowsocks_shadowsocks-libev', 'index_name': 'shadowsocks_shadowsocks-libev', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:01:58] #> Loading model checkpoint.
[Oct 01, 09:01:58] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:01:59] #> checkpoint['epoch'] = 0
[Oct 01, 09:01:59] #> checkpoint['batch'] = 346000
[Oct 01, 09:01:59] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:01:59] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/shadowsocks_shadowsocks-libev.tsv ...
[Oct 01, 09:01:59] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:02:01] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/shadowsocks_shadowsocks-libev/shadowsocks_shadowsocks-libev/ivfpq.70.faiss ..
[Oct 01, 09:02:01] #> Building the emb2pid mapping..
[Oct 01, 09:02:01] len(self.emb2pid) = 399193
[Oct 01, 09:02:02] tensor.size() =  torch.Size([399705, 128])
[Oct 01, 09:02:02] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/shadowsocks_shadowsocks-libev/shadowsocks_shadowsocks-libev/0.pt ...
[Oct 01, 09:02:02] #> Using strides [294, 397]..
[Oct 01, 09:02:05] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shadowsocks_shadowsocks-libev/retrieve.py/2023-10-01_09.01.43/ranking.tsv
0 In manager.c in ss-manager in shadowsocks-libev 3.1.0 , improper parsing allows command injection via shell metacharacters in a JSON configuration request received via 127.0.0.1 UDP traffic , related to the add_server , build_config , and construct_command_line functions . 103 103 26.769989013671875 2377 973.8242626190186 ms
[Oct 01, 09:02:06] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shadowsocks_shadowsocks-libev/retrieve.py/2023-10-01_09.01.43/ranking.tsv
#> Done.




2023-10-01 09:02:08,881 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:02:08,882 INFO rerun retrieving shellinabox_shellinabox
2023-10-01 09:02:35,900 INFO 

[Oct 01, 09:02:10] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shellinabox_shellinabox/retrieve.py/2023-10-01_09.02.10 




[Oct 01, 09:02:13] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shellinabox_shellinabox/retrieve.py/2023-10-01_09.02.10/logs/ 


[Oct 01, 09:02:14] {'root': 'run/retrieve_output', 'experiment': 'shellinabox_shellinabox', 'run': '2023-10-01_09.02.10', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/shellinabox_shellinabox.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/shellinabox_shellinabox', 'index_name': 'shellinabox_shellinabox', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:02:25] #> Loading model checkpoint.
[Oct 01, 09:02:25] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:02:26] #> checkpoint['epoch'] = 0
[Oct 01, 09:02:26] #> checkpoint['batch'] = 346000
[Oct 01, 09:02:26] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:02:26] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/shellinabox_shellinabox.tsv ...
[Oct 01, 09:02:26] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:02:28] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/shellinabox_shellinabox/shellinabox_shellinabox/ivfpq.70.faiss ..
[Oct 01, 09:02:28] #> Building the emb2pid mapping..
[Oct 01, 09:02:28] len(self.emb2pid) = 91874
[Oct 01, 09:02:29] tensor.size() =  torch.Size([92386, 128])
[Oct 01, 09:02:29] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/shellinabox_shellinabox/shellinabox_shellinabox/0.pt ...
[Oct 01, 09:02:29] #> Using strides [316, 405]..
[Oct 01, 09:02:32] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shellinabox_shellinabox/retrieve.py/2023-10-01_09.02.10/ranking.tsv
0 libhttp/url.c in shellinabox through 2.20 has an implementation flaw in the HTTP request parsing logic . By sending a crafted multipart/form-data HTTP request , an attacker could exploit this to force shellinaboxd into an infinite loop , exhausting available CPU resources and taking the service down . 261 261 24.09830665588379 430 995.917558670044 ms
[Oct 01, 09:02:33] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/shellinabox_shellinabox/retrieve.py/2023-10-01_09.02.10/ranking.tsv
#> Done.




2023-10-01 09:02:35,900 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:02:35,901 INFO rerun retrieving silnrsi_graphite
2023-10-01 09:03:02,729 INFO 

[Oct 01, 09:02:37] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/silnrsi_graphite/retrieve.py/2023-10-01_09.02.37 




[Oct 01, 09:02:40] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/silnrsi_graphite/retrieve.py/2023-10-01_09.02.37/logs/ 


[Oct 01, 09:02:41] {'root': 'run/retrieve_output', 'experiment': 'silnrsi_graphite', 'run': '2023-10-01_09.02.37', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/silnrsi_graphite.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/silnrsi_graphite', 'index_name': 'silnrsi_graphite', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:02:52] #> Loading model checkpoint.
[Oct 01, 09:02:52] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:02:53] #> checkpoint['epoch'] = 0
[Oct 01, 09:02:53] #> checkpoint['batch'] = 346000
[Oct 01, 09:02:53] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:02:53] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/silnrsi_graphite.tsv ...
[Oct 01, 09:02:53] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:02:55] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/silnrsi_graphite/silnrsi_graphite/ivfpq.70.faiss ..
[Oct 01, 09:02:55] #> Building the emb2pid mapping..
[Oct 01, 09:02:55] len(self.emb2pid) = 423405
[Oct 01, 09:02:57] tensor.size() =  torch.Size([423917, 128])
[Oct 01, 09:02:57] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/silnrsi_graphite/silnrsi_graphite/0.pt ...
[Oct 01, 09:02:57] #> Using strides [318, 440]..
[Oct 01, 09:02:59] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/silnrsi_graphite/retrieve.py/2023-10-01_09.02.37/ranking.tsv
0 In libgraphite2 in graphite2 1.3.11 , a NULL pointer dereference vulnerability was found in Segment.cpp during a dumbRendering operation , which may allow attackers to cause a denial of service or possibly have unspecified other impact via a crafted .ttf file . 38 38 26.368576049804688 1933 867.6865100860596 ms
[Oct 01, 09:03:00] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/silnrsi_graphite/retrieve.py/2023-10-01_09.02.37/ranking.tsv
#> Done.




2023-10-01 09:03:02,730 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:03:02,731 INFO rerun retrieving simsong_tcpflow
2023-10-01 09:03:30,102 INFO 

[Oct 01, 09:03:04] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/simsong_tcpflow/retrieve.py/2023-10-01_09.03.04 




[Oct 01, 09:03:07] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/simsong_tcpflow/retrieve.py/2023-10-01_09.03.04/logs/ 


[Oct 01, 09:03:08] {'root': 'run/retrieve_output', 'experiment': 'simsong_tcpflow', 'run': '2023-10-01_09.03.04', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/simsong_tcpflow.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/simsong_tcpflow', 'index_name': 'simsong_tcpflow', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:03:19] #> Loading model checkpoint.
[Oct 01, 09:03:19] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:03:20] #> checkpoint['epoch'] = 0
[Oct 01, 09:03:20] #> checkpoint['batch'] = 346000
[Oct 01, 09:03:20] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:03:20] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/simsong_tcpflow.tsv ...
[Oct 01, 09:03:20] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:03:22] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/simsong_tcpflow/simsong_tcpflow/ivfpq.70.faiss ..
[Oct 01, 09:03:22] #> Building the emb2pid mapping..
[Oct 01, 09:03:22] len(self.emb2pid) = 151440
[Oct 01, 09:03:23] tensor.size() =  torch.Size([151952, 128])
[Oct 01, 09:03:23] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/simsong_tcpflow/simsong_tcpflow/0.pt ...
[Oct 01, 09:03:23] #> Using strides [313, 384]..
[Oct 01, 09:03:26] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/simsong_tcpflow/retrieve.py/2023-10-01_09.03.04/ranking.tsv
0 An issue was discovered in wifipcap/wifipcap.cpp in TCPFLOW through 1.5.0-alpha . There is an integer overflow in the function handle_prism during caplen processing . If the caplen is less than 144 , one can cause an integer overflow in the function handle_80211 , which will result in an out-of-bounds read and may allow access to sensitive memory ( or a denial of service ) . 27 27 28.577808380126953 788 1003.6535263061523 ms
[Oct 01, 09:03:27] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/simsong_tcpflow/retrieve.py/2023-10-01_09.03.04/ranking.tsv
#> Done.




2023-10-01 09:03:30,102 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:03:30,103 INFO rerun retrieving sroracle_abuild
2023-10-01 09:03:57,115 INFO 

[Oct 01, 09:03:32] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/sroracle_abuild/retrieve.py/2023-10-01_09.03.31 




[Oct 01, 09:03:34] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/sroracle_abuild/retrieve.py/2023-10-01_09.03.31/logs/ 


[Oct 01, 09:03:36] {'root': 'run/retrieve_output', 'experiment': 'sroracle_abuild', 'run': '2023-10-01_09.03.31', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/sroracle_abuild.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/sroracle_abuild', 'index_name': 'sroracle_abuild', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:03:46] #> Loading model checkpoint.
[Oct 01, 09:03:46] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:03:47] #> checkpoint['epoch'] = 0
[Oct 01, 09:03:47] #> checkpoint['batch'] = 346000
[Oct 01, 09:03:47] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:03:47] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/sroracle_abuild.tsv ...
[Oct 01, 09:03:47] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:03:49] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/sroracle_abuild/sroracle_abuild/ivfpq.70.faiss ..
[Oct 01, 09:03:49] #> Building the emb2pid mapping..
[Oct 01, 09:03:49] len(self.emb2pid) = 156171
[Oct 01, 09:03:50] tensor.size() =  torch.Size([156683, 128])
[Oct 01, 09:03:50] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/sroracle_abuild/sroracle_abuild/0.pt ...
[Oct 01, 09:03:50] #> Using strides [264, 360]..
[Oct 01, 09:03:53] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/sroracle_abuild/retrieve.py/2023-10-01_09.03.31/ranking.tsv
0 Alpine Linux abuild through 3.4.0 allows an unprivileged member of the abuild group to add an untrusted package via a -- keys-dir option that causes acceptance of an untrusted signing key . 430 430 29.389799118041992 1166 1029.3707847595215 ms
[Oct 01, 09:03:54] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/sroracle_abuild/retrieve.py/2023-10-01_09.03.31/ranking.tsv
#> Done.




2023-10-01 09:03:57,115 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:03:57,116 INFO rerun retrieving stefanberger_swtpm
2023-10-01 09:04:24,279 INFO 

[Oct 01, 09:03:59] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stefanberger_swtpm/retrieve.py/2023-10-01_09.03.58 




[Oct 01, 09:04:01] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stefanberger_swtpm/retrieve.py/2023-10-01_09.03.58/logs/ 


[Oct 01, 09:04:03] {'root': 'run/retrieve_output', 'experiment': 'stefanberger_swtpm', 'run': '2023-10-01_09.03.58', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/stefanberger_swtpm.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/stefanberger_swtpm', 'index_name': 'stefanberger_swtpm', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:04:13] #> Loading model checkpoint.
[Oct 01, 09:04:13] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:04:14] #> checkpoint['epoch'] = 0
[Oct 01, 09:04:14] #> checkpoint['batch'] = 346000
[Oct 01, 09:04:14] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:04:14] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/stefanberger_swtpm.tsv ...
[Oct 01, 09:04:14] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:04:16] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/stefanberger_swtpm/stefanberger_swtpm/ivfpq.70.faiss ..
[Oct 01, 09:04:16] #> Building the emb2pid mapping..
[Oct 01, 09:04:16] len(self.emb2pid) = 321149
[Oct 01, 09:04:17] tensor.size() =  torch.Size([321661, 128])
[Oct 01, 09:04:17] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/stefanberger_swtpm/stefanberger_swtpm/0.pt ...
[Oct 01, 09:04:17] #> Using strides [320, 445]..
[Oct 01, 09:04:20] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stefanberger_swtpm/retrieve.py/2023-10-01_09.03.58/ranking.tsv
0 swtpm is a libtpms-based TPM emulator with socket , character device , and Linux CUSE interface . Versions prior to 0.5.3 , 0.6.2 , and 0.7.1 are vulnerable to out-of-bounds read . A specially crafted header of swtpm 's state , where the blobheader 's hdrsize indicator has an invalid value , may cause an out-of-bounds access when the byte array representing the state of the TPM is accessed . This will likely crash swtpm or prevent it from starting since the state can not be understood . Users should upgrade to swtpm v0.5.3 , v0.6.2 , or v0.7.1 to receive a patch . There are currently no known workarounds . 852 852 28.442806243896484 1413 1008.4822177886963 ms
[Oct 01, 09:04:21] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stefanberger_swtpm/retrieve.py/2023-10-01_09.03.58/ranking.tsv
#> Done.




2023-10-01 09:04:24,279 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:04:24,280 INFO rerun retrieving stephane_libmodbus
2023-10-01 09:04:51,491 INFO 

[Oct 01, 09:04:26] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stephane_libmodbus/retrieve.py/2023-10-01_09.04.25 




[Oct 01, 09:04:28] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stephane_libmodbus/retrieve.py/2023-10-01_09.04.25/logs/ 


[Oct 01, 09:04:30] {'root': 'run/retrieve_output', 'experiment': 'stephane_libmodbus', 'run': '2023-10-01_09.04.25', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/stephane_libmodbus.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/stephane_libmodbus', 'index_name': 'stephane_libmodbus', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:04:40] #> Loading model checkpoint.
[Oct 01, 09:04:40] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:04:41] #> checkpoint['epoch'] = 0
[Oct 01, 09:04:41] #> checkpoint['batch'] = 346000
[Oct 01, 09:04:41] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:04:41] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/stephane_libmodbus.tsv ...
[Oct 01, 09:04:41] #> Got 3 queries. All QIDs are unique.

[Oct 01, 09:04:43] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/stephane_libmodbus/stephane_libmodbus/ivfpq.70.faiss ..
[Oct 01, 09:04:44] #> Building the emb2pid mapping..
[Oct 01, 09:04:44] len(self.emb2pid) = 456072
[Oct 01, 09:04:44] tensor.size() =  torch.Size([456584, 128])
[Oct 01, 09:04:44] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/stephane_libmodbus/stephane_libmodbus/0.pt ...
[Oct 01, 09:04:45] #> Using strides [309, 381]..
[Oct 01, 09:04:47] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stephane_libmodbus/retrieve.py/2023-10-01_09.04.25/ranking.tsv
0 A heap-based buffer overflow flaw was found in libmodbus in function modbus_reply ( ) in src/modbus.c . 84 84 30.458297729492188 2492 1030.322551727295 ms
1 An issue was discovered in libmodbus before 3.0.7 and 3.1.x before 3.1.5 . There is an out-of-bounds read for the MODBUS_FC_WRITE_MULTIPLE_REGISTERS case , aka VD-1301 . 81 81 30.62847137451172 2492 539.6511554718018 ms
2 An issue was discovered in libmodbus before 3.0.7 and 3.1.x before 3.1.5 . There is an out-of-bounds read for the MODBUS_FC_WRITE_MULTIPLE_COILS case , aka VD-1302 . 81 81 30.62847137451172 2492 375.3516674041748 ms
[Oct 01, 09:04:48] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stephane_libmodbus/retrieve.py/2023-10-01_09.04.25/ranking.tsv
#> Done.




2023-10-01 09:04:51,492 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:04:51,492 INFO rerun retrieving stoth68000_media-tree
2023-10-01 09:05:19,024 INFO 

[Oct 01, 09:04:53] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stoth68000_media-tree/retrieve.py/2023-10-01_09.04.53 




[Oct 01, 09:04:55] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stoth68000_media-tree/retrieve.py/2023-10-01_09.04.53/logs/ 


[Oct 01, 09:04:57] {'root': 'run/retrieve_output', 'experiment': 'stoth68000_media-tree', 'run': '2023-10-01_09.04.53', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/stoth68000_media-tree.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/stoth68000_media-tree', 'index_name': 'stoth68000_media-tree', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:05:08] #> Loading model checkpoint.
[Oct 01, 09:05:08] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:05:09] #> checkpoint['epoch'] = 0
[Oct 01, 09:05:09] #> checkpoint['batch'] = 346000
[Oct 01, 09:05:09] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:05:09] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/stoth68000_media-tree.tsv ...
[Oct 01, 09:05:09] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:05:11] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/stoth68000_media-tree/stoth68000_media-tree/ivfpq.70.faiss ..
[Oct 01, 09:05:11] #> Building the emb2pid mapping..
[Oct 01, 09:05:11] len(self.emb2pid) = 1366139
[Oct 01, 09:05:12] tensor.size() =  torch.Size([1366651, 128])
[Oct 01, 09:05:12] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/stoth68000_media-tree/stoth68000_media-tree/0.pt ...
[Oct 01, 09:05:12] #> Using strides [357, 436]..
[Oct 01, 09:05:15] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stoth68000_media-tree/retrieve.py/2023-10-01_09.04.53/ranking.tsv
0 The saa7164_bus_get function in drivers/media/pci/saa7164/saa7164-bus.c in the Linux kernel through 4.11.5 allows local users to cause a denial of service ( out-of-bounds array access ) or possibly have unspecified other impact by changing a certain sequence-number value , aka a `` double fetch '' vulnerability . 900 900 30.35399627685547 5000 1070.5974102020264 ms
[Oct 01, 09:05:16] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/stoth68000_media-tree/retrieve.py/2023-10-01_09.04.53/ranking.tsv
#> Done.




2023-10-01 09:05:19,024 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:05:19,025 INFO rerun retrieving strukturag_libde265
2023-10-01 09:05:46,284 INFO 

[Oct 01, 09:05:21] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libde265/retrieve.py/2023-10-01_09.05.20 




[Oct 01, 09:05:23] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libde265/retrieve.py/2023-10-01_09.05.20/logs/ 


[Oct 01, 09:05:25] {'root': 'run/retrieve_output', 'experiment': 'strukturag_libde265', 'run': '2023-10-01_09.05.20', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/strukturag_libde265.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/strukturag_libde265', 'index_name': 'strukturag_libde265', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:05:35] #> Loading model checkpoint.
[Oct 01, 09:05:35] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:05:36] #> checkpoint['epoch'] = 0
[Oct 01, 09:05:36] #> checkpoint['batch'] = 346000
[Oct 01, 09:05:36] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:05:36] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/strukturag_libde265.tsv ...
[Oct 01, 09:05:36] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:05:38] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/strukturag_libde265/strukturag_libde265/ivfpq.70.faiss ..
[Oct 01, 09:05:38] #> Building the emb2pid mapping..
[Oct 01, 09:05:38] len(self.emb2pid) = 444685
[Oct 01, 09:05:39] tensor.size() =  torch.Size([445197, 128])
[Oct 01, 09:05:39] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/strukturag_libde265/strukturag_libde265/0.pt ...
[Oct 01, 09:05:39] #> Using strides [308, 360]..
[Oct 01, 09:05:42] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libde265/retrieve.py/2023-10-01_09.05.20/ranking.tsv
0 Heap-based Buffer Overflow in GitHub repository strukturag/libde265 prior to and including 1.0.8 . The fix is established in commit 8e89fe0e175d2870c39486fdd09250b230ec10b8 but does not yet belong to an official release . 25 25 25.967121124267578 2154 1010.246753692627 ms
[Oct 01, 09:05:43] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libde265/retrieve.py/2023-10-01_09.05.20/ranking.tsv
#> Done.




2023-10-01 09:05:46,284 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:05:46,285 INFO rerun retrieving strukturag_libheif
2023-10-01 09:06:13,874 INFO 

[Oct 01, 09:05:48] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libheif/retrieve.py/2023-10-01_09.05.47 




[Oct 01, 09:05:50] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libheif/retrieve.py/2023-10-01_09.05.47/logs/ 


[Oct 01, 09:05:52] {'root': 'run/retrieve_output', 'experiment': 'strukturag_libheif', 'run': '2023-10-01_09.05.47', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/strukturag_libheif.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/strukturag_libheif', 'index_name': 'strukturag_libheif', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:06:02] #> Loading model checkpoint.
[Oct 01, 09:06:02] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:06:03] #> checkpoint['epoch'] = 0
[Oct 01, 09:06:03] #> checkpoint['batch'] = 346000
[Oct 01, 09:06:03] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:06:03] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/strukturag_libheif.tsv ...
[Oct 01, 09:06:03] #> Got 3 queries. All QIDs are unique.

[Oct 01, 09:06:06] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/strukturag_libheif/strukturag_libheif/ivfpq.70.faiss ..
[Oct 01, 09:06:06] #> Building the emb2pid mapping..
[Oct 01, 09:06:06] len(self.emb2pid) = 1023852
[Oct 01, 09:06:07] tensor.size() =  torch.Size([1024364, 128])
[Oct 01, 09:06:07] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/strukturag_libheif/strukturag_libheif/0.pt ...
[Oct 01, 09:06:07] #> Using strides [296, 443]..
[Oct 01, 09:06:09] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libheif/retrieve.py/2023-10-01_09.05.47/ranking.tsv
0 An issue was discovered in heif : :Box_iref : :get_references in libheif 1.4.0 , allows attackers to cause a Denial of Service or possibly other unspecified impact due to an invalid memory read . 96 96 28.378849029541016 5968 1047.135353088379 ms
1 Floating point exception in function Fraction in libheif 1.4.0 , allows attackers to cause a Denial of Service or possibly other unspecified impacts . 66 66 29.39288330078125 5968 566.3717985153198 ms
2 libheif 1.4.0 has a use-after-free in heif : :HeifContext : :Image : :set_alpha_channel in heif_context.h because heif_context.cc mishandles references to non-existing alpha images . 96 96 28.490644454956055 5968 406.0768286387126 ms
[Oct 01, 09:06:11] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/strukturag_libheif/retrieve.py/2023-10-01_09.05.47/ranking.tsv
#> Done.




2023-10-01 09:06:13,875 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:06:13,876 INFO rerun retrieving swaywm_swaylock
2023-10-01 09:06:40,723 INFO 

[Oct 01, 09:06:16] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swaywm_swaylock/retrieve.py/2023-10-01_09.06.15 




[Oct 01, 09:06:18] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swaywm_swaylock/retrieve.py/2023-10-01_09.06.15/logs/ 


[Oct 01, 09:06:20] {'root': 'run/retrieve_output', 'experiment': 'swaywm_swaylock', 'run': '2023-10-01_09.06.15', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/swaywm_swaylock.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/swaywm_swaylock', 'index_name': 'swaywm_swaylock', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:06:30] #> Loading model checkpoint.
[Oct 01, 09:06:30] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:06:31] #> checkpoint['epoch'] = 0
[Oct 01, 09:06:31] #> checkpoint['batch'] = 346000
[Oct 01, 09:06:31] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:06:31] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/swaywm_swaylock.tsv ...
[Oct 01, 09:06:31] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:06:33] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/swaywm_swaylock/swaywm_swaylock/ivfpq.70.faiss ..
[Oct 01, 09:06:33] #> Building the emb2pid mapping..
[Oct 01, 09:06:33] len(self.emb2pid) = 43836
[Oct 01, 09:06:35] tensor.size() =  torch.Size([44348, 128])
[Oct 01, 09:06:35] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/swaywm_swaylock/swaywm_swaylock/0.pt ...
[Oct 01, 09:06:35] #> Using strides [278, 359]..
[Oct 01, 09:06:37] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swaywm_swaylock/retrieve.py/2023-10-01_09.06.15/ranking.tsv
0 swaylock before 1.6 allows attackers to trigger a crash and achieve unlocked access to a Wayland compositor . 161 161 27.548683166503906 284 828.9542198181152 ms
[Oct 01, 09:06:38] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swaywm_swaylock/retrieve.py/2023-10-01_09.06.15/ranking.tsv
#> Done.




2023-10-01 09:06:40,724 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:06:40,724 INFO rerun retrieving swoole_swoole-src
2023-10-01 09:07:08,467 INFO 

[Oct 01, 09:06:42] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swoole_swoole-src/retrieve.py/2023-10-01_09.06.42 




[Oct 01, 09:06:45] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swoole_swoole-src/retrieve.py/2023-10-01_09.06.42/logs/ 


[Oct 01, 09:06:46] {'root': 'run/retrieve_output', 'experiment': 'swoole_swoole-src', 'run': '2023-10-01_09.06.42', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/swoole_swoole-src.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/swoole_swoole-src', 'index_name': 'swoole_swoole-src', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:06:57] #> Loading model checkpoint.
[Oct 01, 09:06:57] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:06:58] #> checkpoint['epoch'] = 0
[Oct 01, 09:06:58] #> checkpoint['batch'] = 346000
[Oct 01, 09:06:58] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:06:58] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/swoole_swoole-src.tsv ...
[Oct 01, 09:06:58] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:07:00] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/swoole_swoole-src/swoole_swoole-src/ivfpq.70.faiss ..
[Oct 01, 09:07:00] #> Building the emb2pid mapping..
[Oct 01, 09:07:00] len(self.emb2pid) = 861705
[Oct 01, 09:07:01] tensor.size() =  torch.Size([862217, 128])
[Oct 01, 09:07:01] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/swoole_swoole-src/swoole_swoole-src/0.pt ...
[Oct 01, 09:07:01] #> Using strides [287, 451]..
[Oct 01, 09:07:04] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swoole_swoole-src/retrieve.py/2023-10-01_09.06.42/ranking.tsv
0 The unpack implementation in Swoole version 4.0.4 lacks correct size checks in the deserialization process . An attacker can craft a serialized object to exploit this vulnerability and cause a SEGV . 453 453 28.961292266845703 4338 1008.9669227600098 ms
[Oct 01, 09:07:05] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/swoole_swoole-src/retrieve.py/2023-10-01_09.06.42/ranking.tsv
#> Done.




2023-10-01 09:07:08,467 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:07:08,468 INFO rerun retrieving symless_synergy-core
2023-10-01 09:07:35,986 INFO 

[Oct 01, 09:07:10] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/symless_synergy-core/retrieve.py/2023-10-01_09.07.10 




[Oct 01, 09:07:12] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/symless_synergy-core/retrieve.py/2023-10-01_09.07.10/logs/ 


[Oct 01, 09:07:14] {'root': 'run/retrieve_output', 'experiment': 'symless_synergy-core', 'run': '2023-10-01_09.07.10', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/symless_synergy-core.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/symless_synergy-core', 'index_name': 'symless_synergy-core', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:07:25] #> Loading model checkpoint.
[Oct 01, 09:07:25] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:07:26] #> checkpoint['epoch'] = 0
[Oct 01, 09:07:26] #> checkpoint['batch'] = 346000
[Oct 01, 09:07:26] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:07:26] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/symless_synergy-core.tsv ...
[Oct 01, 09:07:26] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:07:28] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/symless_synergy-core/symless_synergy-core/ivfpq.70.faiss ..
[Oct 01, 09:07:28] #> Building the emb2pid mapping..
[Oct 01, 09:07:28] len(self.emb2pid) = 783979
[Oct 01, 09:07:29] tensor.size() =  torch.Size([784491, 128])
[Oct 01, 09:07:29] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/symless_synergy-core/symless_synergy-core/0.pt ...
[Oct 01, 09:07:29] #> Using strides [316, 404]..
[Oct 01, 09:07:32] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/symless_synergy-core/retrieve.py/2023-10-01_09.07.10/ranking.tsv
0 In Synergy before version 1.12.0 , a Synergy server can be crashed by receiving a kMsgHelloBack packet with a client name length set to 0xffffffff ( 4294967295 ) if the servers memory is less than 4 GB . It was verified that this issue does not cause a crash through the exception handler if the available memory of the Server is more than 4GB . 465 465 30.585994720458984 4159 1026.4461040496826 ms
[Oct 01, 09:07:33] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/symless_synergy-core/retrieve.py/2023-10-01_09.07.10/ranking.tsv
#> Done.




2023-10-01 09:07:35,986 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:07:35,987 INFO rerun retrieving thorfdbg_libjpeg
2023-10-01 09:08:03,056 INFO 

[Oct 01, 09:07:38] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/thorfdbg_libjpeg/retrieve.py/2023-10-01_09.07.37 




[Oct 01, 09:07:40] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/thorfdbg_libjpeg/retrieve.py/2023-10-01_09.07.37/logs/ 


[Oct 01, 09:07:41] {'root': 'run/retrieve_output', 'experiment': 'thorfdbg_libjpeg', 'run': '2023-10-01_09.07.37', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/thorfdbg_libjpeg.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/thorfdbg_libjpeg', 'index_name': 'thorfdbg_libjpeg', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:07:52] #> Loading model checkpoint.
[Oct 01, 09:07:52] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:07:53] #> checkpoint['epoch'] = 0
[Oct 01, 09:07:53] #> checkpoint['batch'] = 346000
[Oct 01, 09:07:53] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:07:53] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/thorfdbg_libjpeg.tsv ...
[Oct 01, 09:07:53] #> Got 5 queries. All QIDs are unique.

[Oct 01, 09:07:55] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/thorfdbg_libjpeg/thorfdbg_libjpeg/ivfpq.70.faiss ..
[Oct 01, 09:07:55] #> Building the emb2pid mapping..
[Oct 01, 09:07:55] len(self.emb2pid) = 89642
[Oct 01, 09:07:56] tensor.size() =  torch.Size([90154, 128])
[Oct 01, 09:07:56] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/thorfdbg_libjpeg/thorfdbg_libjpeg/0.pt ...
[Oct 01, 09:07:56] #> Using strides [328, 371]..
[Oct 01, 09:07:59] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/thorfdbg_libjpeg/retrieve.py/2023-10-01_09.07.37/ranking.tsv
0 In libjpeg before 1.64 , BitStream < false > : :Get in bitstream.hpp has an assertion failure that may cause denial of service . This is related to out-of-bounds array access during arithmetically coded lossless scan or arithmetically coded sequential scan . 25 25 28.783926010131836 318 980.9553623199463 ms
1 In libjpeg 1.63 , there is a NULL pointer dereference in Component : :SubXOf in component.hpp . 25 25 28.7225341796875 318 503.1689405441284 ms
2 In libjpeg 1.63 , there is a NULL pointer dereference in LineBuffer : :FetchRegion in linebuffer.cpp . 25 25 29.200502395629883 318 344.6858723958333 ms
3 There is an assertion failure in SingleComponentLSScan : :ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan . 25 25 28.09418296813965 318 264.9277448654175 ms
4 libjpeg 1.63 has a heap-based buffer over-read in HierarchicalBitmapRequester : :FetchRegion in hierarchicalbitmaprequester.cpp because the MCU size can be different between allocation and use . 30 30 29.602581024169922 318 218.2410717010498 ms
[Oct 01, 09:08:00] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/thorfdbg_libjpeg/retrieve.py/2023-10-01_09.07.37/ranking.tsv
#> Done.




2023-10-01 09:08:03,057 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:08:03,058 INFO rerun retrieving torproject_tor
2023-10-01 09:08:32,594 INFO 

[Oct 01, 09:08:05] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/torproject_tor/retrieve.py/2023-10-01_09.08.04 




[Oct 01, 09:08:07] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/torproject_tor/retrieve.py/2023-10-01_09.08.04/logs/ 


[Oct 01, 09:08:09] {'root': 'run/retrieve_output', 'experiment': 'torproject_tor', 'run': '2023-10-01_09.08.04', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/torproject_tor.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/torproject_tor', 'index_name': 'torproject_tor', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:08:19] #> Loading model checkpoint.
[Oct 01, 09:08:19] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:08:20] #> checkpoint['epoch'] = 0
[Oct 01, 09:08:20] #> checkpoint['batch'] = 346000
[Oct 01, 09:08:20] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:08:20] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/torproject_tor.tsv ...
[Oct 01, 09:08:20] #> Got 5 queries. All QIDs are unique.

[Oct 01, 09:08:22] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/torproject_tor/torproject_tor/ivfpq.70.faiss ..
[Oct 01, 09:08:23] #> Building the emb2pid mapping..
[Oct 01, 09:08:23] len(self.emb2pid) = 4189762
[Oct 01, 09:08:24] tensor.size() =  torch.Size([4190274, 128])
[Oct 01, 09:08:24] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/torproject_tor/torproject_tor/0.pt ...
[Oct 01, 09:08:25] #> Using strides [317, 403]..
[Oct 01, 09:08:27] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/torproject_tor/retrieve.py/2023-10-01_09.08.04/ranking.tsv
0 The rend_service_intro_established function in or/rendservice.c in Tor before 0.2.8.15 , 0.2.9.x before 0.2.9.12 , 0.3.0.x before 0.3.0.11 , 0.3.1.x before 0.3.1.7 , and 0.3.2.x before 0.3.2.1-alpha , when SafeLogging is disabled , allows attackers to obtain sensitive information by leveraging access to the log files of a hidden service , because uninitialized stack data is included in an error message about construction of an introduction point circuit . 75 75 29.776107788085938 25004 1163.8543605804443 ms
1 Tor before 0.2.8.9 and 0.2.9.x before 0.2.9.4-alpha had internal functions that were entitled to expect that buf_t data had NUL termination , but the implementation of or/buffers.c did not ensure that NUL termination was present , which allows remote attackers to cause a denial of service ( client , hidden service , relay , or authority crash ) via crafted data . 10 10 31.314001083374023 25004 668.4764623641968 ms
2 The hidden-service feature in Tor before 0.3.0.8 allows a denial of service ( assertion failure and daemon exit ) in the connection_edge_process_relay_cell function via a BEGIN_DIR cell on a rendezvous circuit . 5 5 31.166276931762695 25003 504.57024574279785 ms
3 The hidden-service feature in Tor before 0.3.0.8 allows a denial of service ( assertion failure and daemon exit ) in the relay_send_end_cell_from_edge_ function via a malformed BEGIN cell . 5 5 31.166276931762695 25003 430.9949278831482 ms
4 Tor 0.3.x before 0.3.0.9 has a guard-selection algorithm that only considers the exit relay ( not the exit relay 's family ) , which might allow remote attackers to defeat intended anonymity properties by leveraging the existence of large families . 10 10 30.898651123046875 25003 383.9231491088867 ms
[Oct 01, 09:08:29] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/torproject_tor/retrieve.py/2023-10-01_09.08.04/ranking.tsv
#> Done.




2023-10-01 09:08:32,595 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:08:32,596 INFO rerun retrieving uWebSockets_uWebSockets
2023-10-01 09:08:59,770 INFO 

[Oct 01, 09:08:34] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uWebSockets_uWebSockets/retrieve.py/2023-10-01_09.08.34 




[Oct 01, 09:08:36] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uWebSockets_uWebSockets/retrieve.py/2023-10-01_09.08.34/logs/ 


[Oct 01, 09:08:38] {'root': 'run/retrieve_output', 'experiment': 'uWebSockets_uWebSockets', 'run': '2023-10-01_09.08.34', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/uWebSockets_uWebSockets.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/uWebSockets_uWebSockets', 'index_name': 'uWebSockets_uWebSockets', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:08:49] #> Loading model checkpoint.
[Oct 01, 09:08:49] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:08:50] #> checkpoint['epoch'] = 0
[Oct 01, 09:08:50] #> checkpoint['batch'] = 346000
[Oct 01, 09:08:50] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:08:50] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/uWebSockets_uWebSockets.tsv ...
[Oct 01, 09:08:50] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:08:52] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/uWebSockets_uWebSockets/uWebSockets_uWebSockets/ivfpq.70.faiss ..
[Oct 01, 09:08:52] #> Building the emb2pid mapping..
[Oct 01, 09:08:52] len(self.emb2pid) = 180460
[Oct 01, 09:08:53] tensor.size() =  torch.Size([180972, 128])
[Oct 01, 09:08:53] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/uWebSockets_uWebSockets/uWebSockets_uWebSockets/0.pt ...
[Oct 01, 09:08:53] #> Using strides [300, 410]..
[Oct 01, 09:08:56] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uWebSockets_uWebSockets/retrieve.py/2023-10-01_09.08.34/ranking.tsv
0 uws is a WebSocket server library . By sending a 256mb websocket message to a uws server instance with permessage-deflate enabled , there is a possibility used compression will shrink said 256mb down to less than 16mb of websocket payload which passes the length check of 16mb payload . This data will then inflate up to 256mb and crash the node process by exceeding V8 's maximum string size . This affects uws > =0.10.0 < =0.10.8 . 145 145 25.459758758544922 939 979.508638381958 ms
[Oct 01, 09:08:57] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uWebSockets_uWebSockets/retrieve.py/2023-10-01_09.08.34/ranking.tsv
#> Done.




2023-10-01 09:08:59,770 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:08:59,771 INFO rerun retrieving uclouvain_openjpeg
2023-10-01 09:09:40,569 INFO 

[Oct 01, 09:09:01] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uclouvain_openjpeg/retrieve.py/2023-10-01_09.09.01 




[Oct 01, 09:09:04] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uclouvain_openjpeg/retrieve.py/2023-10-01_09.09.01/logs/ 


[Oct 01, 09:09:06] {'root': 'run/retrieve_output', 'experiment': 'uclouvain_openjpeg', 'run': '2023-10-01_09.09.01', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/uclouvain_openjpeg.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/uclouvain_openjpeg', 'index_name': 'uclouvain_openjpeg', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:09:16] #> Loading model checkpoint.
[Oct 01, 09:09:16] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:09:17] #> checkpoint['epoch'] = 0
[Oct 01, 09:09:17] #> checkpoint['batch'] = 346000
[Oct 01, 09:09:17] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:09:17] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/uclouvain_openjpeg.tsv ...
[Oct 01, 09:09:17] #> Got 19 queries. All QIDs are unique.

[Oct 01, 09:09:19] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/uclouvain_openjpeg/uclouvain_openjpeg/ivfpq.70.faiss ..
[Oct 01, 09:09:20] #> Building the emb2pid mapping..
[Oct 01, 09:09:20] len(self.emb2pid) = 12123146
[Oct 01, 09:09:21] tensor.size() =  torch.Size([12123658, 128])
[Oct 01, 09:09:21] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/uclouvain_openjpeg/uclouvain_openjpeg/0.pt ...
[Oct 01, 09:09:24] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/uclouvain_openjpeg/uclouvain_openjpeg/1.pt ...
[Oct 01, 09:09:25] #> Using strides [321, 423]..
[Oct 01, 09:09:27] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uclouvain_openjpeg/retrieve.py/2023-10-01_09.09.01/ranking.tsv
0 A stack-based buffer overflow was discovered in the pgxtoimage function in bin/jp2/convert.c in OpenJPEG 2.2.0 . The vulnerability causes an out-of-bounds write , which may lead to remote denial of service or possibly remote code execution . 361 361 30.064592361450195 56733 1435.7664585113525 ms
1 Division-by-zero vulnerabilities in the functions opj_pi_next_cprl , opj_pi_next_pcrl , and opj_pi_next_rpcl in pi.c in OpenJPEG before 2.2.0 allow remote attackers to cause a denial of service ( application crash ) via crafted j2k files . 266 266 29.81448745727539 56720 944.4853067398071 ms
2 Heap-based buffer overflow in the color_cmyk_to_rgb in common/color.c in OpenJPEG before 2.1.1 allows remote attackers to cause a denial of service ( crash ) via a crafted .j2k file . 418 418 30.331600189208984 56723 781.0220718383789 ms
3 A mishandled zero case was discovered in opj_j2k_set_cinema_parameters in lib/openjp2/j2k.c in OpenJPEG 2.2.0 . The vulnerability causes an out-of-bounds write , which may lead to remote denial of service ( heap-based buffer overflow affecting opj_write_bytes_LE in lib/openjp2/cio.c and opj_j2k_write_sot in lib/openjp2/j2k.c ) or possibly remote code execution . 304 304 30.449678421020508 56729 697.7996826171875 ms
4 In OpenJPEG 2.3.1 , there is excessive iteration in the opj_t1_encode_cblks function of openjp2/t1.c . Remote attackers could leverage this vulnerability to cause a denial of service via a crafted bmp file . This issue is similar to CVE-2018-6616 . 494 494 30.56780242919922 56719 650.551176071167 ms
5 The sycc422_t_rgb function in common/color.c in OpenJPEG before 2.1.1 allows remote attackers to cause a denial of service ( out-of-bounds read ) via a crafted jpeg2000 file . 361 361 30.685535430908203 56722 618.4162298838297 ms
6 An off-by-one error was discovered in opj_tcd_code_block_enc_allocate_data in lib/openjp2/tcd.c in OpenJPEG 2.2.0 . The vulnerability causes an out-of-bounds write , which may lead to remote denial of service ( heap-based buffer overflow affecting opj_mqc_flush in lib/openjp2/mqc.c and opj_t1_encode_cblk in lib/openjp2/t1.c ) or possibly remote code execution . 323 323 30.682451248168945 56719 592.8252424512591 ms
7 A heap-based buffer overflow was discovered in the opj_t2_encode_packet function in lib/openjp2/t2.c in OpenJPEG 2.2.0 . The vulnerability causes an out-of-bounds write , which may lead to remote denial of service or possibly unspecified other impact . 301 301 31.000247955322266 56727 574.3156969547272 ms
8 An improper computation of p_tx0 , p_tx1 , p_ty0 and p_ty1 in the function opj_get_encoding_parameters in openjp2/pi.c in OpenJPEG through 2.3.0 can lead to an integer overflow . 285 285 29.730283737182617 11943 561.0958470238579 ms
9 Heap-based buffer overflow in the opj_dwt_interleave_v function in dwt.c in OpenJPEG , as used in PDFium in Google Chrome before 53.0.2785.89 on Windows and OS X and before 53.0.2785.92 on Linux , allows remote attackers to execute arbitrary code via crafted coordinate values in JPEG 2000 data . 361 361 29.712535858154297 56719 547.7425336837769 ms
10 An issue was discovered in mj2/opj_mj2_extract.c in OpenJPEG 2.3.0 . The output prefix was not checked for length , which could overflow a buffer , when providing a prefix with 50 or more characters on the command line . 452 452 30.804092407226562 56732 538.4377566250888 ms
11 Heap-based buffer overflow vulnerability in the opj_mqc_byteout function in mqc.c in OpenJPEG before 2.2.0 allows remote attackers to cause a denial of service ( application crash ) via a crafted bmp file . 361 361 31.222572326660156 56719 529.9981832504272 ms
12 Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file , which triggers an out-of-bounds read or write . 437 437 30.591630935668945 56719 523.50508249723 ms
13 The bmp_read_info_header function in bin/jp2/convertbmp.c in OpenJPEG 2.2.0 does not reject headers with a zero biBitCount , which allows remote attackers to cause a denial of service ( memory allocation failure ) in the opj_image_create function in lib/openjp2/image.c , related to the opj_aligned_alloc_n function in opj_malloc.c . 475 475 30.203720092773438 56733 520.5118315560477 ms
14 Divide-by-zero vulnerability in the opj_tcd_init_tile function in tcd.c in OpenJPEG before 2.1.1 allows remote attackers to cause a denial of service ( application crash ) via a crafted jp2 file . NOTE : this issue exists because of an incorrect fix for CVE-2014-7947 . 449 449 30.527626037597656 56719 515.7419522603353 ms
15 An invalid write access was discovered in bin/jp2/convert.c in OpenJPEG 2.2.0 , triggering a crash in the tgatoimage function . The vulnerability may lead to remote denial of service or possibly unspecified other impact . 361 361 30.843425750732422 56719 511.1414045095444 ms
16 OpenJPEG before 2.3.1 has a heap buffer overflow in color_apply_icc_profile in bin/common/color.c . 361 361 30.5983943939209 56719 506.88812311957867 ms
17 A size-validation issue was discovered in opj_j2k_write_sot in lib/openjp2/j2k.c in OpenJPEG 2.2.0 . The vulnerability causes an out-of-bounds write , which may lead to remote denial of service ( heap-based buffer overflow affecting opj_write_bytes_LE in lib/openjp2/cio.c ) or possibly remote code execution . NOTE : this vulnerability exists because of an incomplete fix for CVE-2017-14152 . 285 285 30.770736694335938 56730 503.46457958221436 ms
18 Integer overflow vulnerability in the bmp24toimage function in convertbmp.c in OpenJPEG before 2.2.0 allows remote attackers to cause a denial of service ( heap-based buffer over-read and application crash ) via a crafted bmp file . 342 342 30.139907836914062 56733 500.3401982156854 ms
[Oct 01, 09:09:37] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/uclouvain_openjpeg/retrieve.py/2023-10-01_09.09.01/ranking.tsv
#> Done.




2023-10-01 09:09:40,570 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:09:40,570 INFO rerun retrieving unrealircd_unrealircd
2023-10-01 09:10:08,435 INFO 

[Oct 01, 09:09:42] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/unrealircd_unrealircd/retrieve.py/2023-10-01_09.09.42 




[Oct 01, 09:09:44] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/unrealircd_unrealircd/retrieve.py/2023-10-01_09.09.42/logs/ 


[Oct 01, 09:09:46] {'root': 'run/retrieve_output', 'experiment': 'unrealircd_unrealircd', 'run': '2023-10-01_09.09.42', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/unrealircd_unrealircd.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/unrealircd_unrealircd', 'index_name': 'unrealircd_unrealircd', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:09:57] #> Loading model checkpoint.
[Oct 01, 09:09:57] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:09:58] #> checkpoint['epoch'] = 0
[Oct 01, 09:09:58] #> checkpoint['batch'] = 346000
[Oct 01, 09:09:58] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:09:58] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/unrealircd_unrealircd.tsv ...
[Oct 01, 09:09:58] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:10:00] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/unrealircd_unrealircd/unrealircd_unrealircd/ivfpq.70.faiss ..
[Oct 01, 09:10:00] #> Building the emb2pid mapping..
[Oct 01, 09:10:00] len(self.emb2pid) = 1050784
[Oct 01, 09:10:01] tensor.size() =  torch.Size([1051296, 128])
[Oct 01, 09:10:01] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/unrealircd_unrealircd/unrealircd_unrealircd/0.pt ...
[Oct 01, 09:10:01] #> Using strides [319, 427]..
[Oct 01, 09:10:04] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/unrealircd_unrealircd/retrieve.py/2023-10-01_09.09.42/ranking.tsv
0 The m_authenticate function in modules/m_sasl.c in UnrealIRCd before 3.2.10.7 and 4.x before 4.0.6 allows remote attackers to spoof certificate fingerprints and consequently log in as another user via a crafted AUTHENTICATE parameter . 628 628 27.8646183013916 1617 1080.367088317871 ms
[Oct 01, 09:10:05] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/unrealircd_unrealircd/retrieve.py/2023-10-01_09.09.42/ranking.tsv
#> Done.




2023-10-01 09:10:08,435 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:10:08,436 INFO rerun retrieving varnish_Varnish-Cache
2023-10-01 09:10:34,056 INFO 

[Oct 01, 09:10:10] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/varnish_Varnish-Cache/retrieve.py/2023-10-01_09.10.10 




[Oct 01, 09:10:12] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/varnish_Varnish-Cache/retrieve.py/2023-10-01_09.10.10/logs/ 


[Oct 01, 09:10:14] {'root': 'run/retrieve_output', 'experiment': 'varnish_Varnish-Cache', 'run': '2023-10-01_09.10.10', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/varnish_Varnish-Cache.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/varnish_Varnish-Cache', 'index_name': 'varnish_Varnish-Cache', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:10:25] #> Loading model checkpoint.
[Oct 01, 09:10:25] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:10:26] #> checkpoint['epoch'] = 0
[Oct 01, 09:10:26] #> checkpoint['batch'] = 346000
[Oct 01, 09:10:26] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:10:26] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/varnish_Varnish-Cache.tsv ...
[Oct 01, 09:10:26] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:10:28] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/varnish_Varnish-Cache/varnish_Varnish-Cache/ivfpq.70.faiss ..
[Oct 01, 09:10:28] #> Building the emb2pid mapping..
[Oct 01, 09:10:28] len(self.emb2pid) = 351
[Oct 01, 09:10:29] tensor.size() =  torch.Size([863, 128])
[Oct 01, 09:10:29] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/varnish_Varnish-Cache/varnish_Varnish-Cache/0.pt ...
[Oct 01, 09:10:29] #> Using strides [60, 291]..
[Oct 01, 09:10:30] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/varnish_Varnish-Cache/retrieve.py/2023-10-01_09.10.10/ranking.tsv
0 Varnish 3.x before 3.0.7 , when used in certain stacked installations , allows remote attackers to inject arbitrary HTTP headers and conduct HTTP response splitting attacks via a header line terminated by a \r ( carriage return ) character in conjunction with multiple Content-Length headers in an HTTP request . 1 1 30.477954864501953 1 965.9342765808105 ms
[Oct 01, 09:10:31] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/varnish_Varnish-Cache/retrieve.py/2023-10-01_09.10.10/ranking.tsv
#> Done.




2023-10-01 09:10:34,056 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:10:34,057 INFO rerun retrieving veracrypt_VeraCrypt
2023-10-01 09:11:01,660 INFO 

[Oct 01, 09:10:36] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/veracrypt_VeraCrypt/retrieve.py/2023-10-01_09.10.35 




[Oct 01, 09:10:38] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/veracrypt_VeraCrypt/retrieve.py/2023-10-01_09.10.35/logs/ 


[Oct 01, 09:10:40] {'root': 'run/retrieve_output', 'experiment': 'veracrypt_VeraCrypt', 'run': '2023-10-01_09.10.35', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/veracrypt_VeraCrypt.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/veracrypt_VeraCrypt', 'index_name': 'veracrypt_VeraCrypt', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:10:51] #> Loading model checkpoint.
[Oct 01, 09:10:51] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:10:51] #> checkpoint['epoch'] = 0
[Oct 01, 09:10:51] #> checkpoint['batch'] = 346000
[Oct 01, 09:10:51] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:10:51] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/veracrypt_VeraCrypt.tsv ...
[Oct 01, 09:10:51] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:10:54] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/veracrypt_VeraCrypt/veracrypt_VeraCrypt/ivfpq.70.faiss ..
[Oct 01, 09:10:54] #> Building the emb2pid mapping..
[Oct 01, 09:10:54] len(self.emb2pid) = 456766
[Oct 01, 09:10:55] tensor.size() =  torch.Size([457278, 128])
[Oct 01, 09:10:55] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/veracrypt_VeraCrypt/veracrypt_VeraCrypt/0.pt ...
[Oct 01, 09:10:55] #> Using strides [342, 454]..
[Oct 01, 09:10:57] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/veracrypt_VeraCrypt/retrieve.py/2023-10-01_09.10.35/ranking.tsv
0 IDRIX , Truecrypt Veracrypt , Truecrypt Prior to 1.23-Hotfix-1 ( Veracrypt ) , all versions ( Truecrypt ) is affected by : Buffer Overflow . The impact is : Minor information disclosure of kernel stack . The component is : Veracrypt NT Driver ( veracrypt.sys ) . The attack vector is : Locally executed code , IOCTL request to driver . The fixed version is : 1.23-Hotfix-1 . 125 125 29.777389526367188 1970 1034.4879627227783 ms
[Oct 01, 09:10:58] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/veracrypt_VeraCrypt/retrieve.py/2023-10-01_09.10.35/ranking.tsv
#> Done.




2023-10-01 09:11:01,660 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:11:01,661 INFO rerun retrieving wesnoth_wesnoth
2023-10-01 09:11:30,223 INFO 

[Oct 01, 09:11:03] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wesnoth_wesnoth/retrieve.py/2023-10-01_09.11.03 




[Oct 01, 09:11:06] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wesnoth_wesnoth/retrieve.py/2023-10-01_09.11.03/logs/ 


[Oct 01, 09:11:08] {'root': 'run/retrieve_output', 'experiment': 'wesnoth_wesnoth', 'run': '2023-10-01_09.11.03', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/wesnoth_wesnoth.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/wesnoth_wesnoth', 'index_name': 'wesnoth_wesnoth', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:11:18] #> Loading model checkpoint.
[Oct 01, 09:11:18] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:11:19] #> checkpoint['epoch'] = 0
[Oct 01, 09:11:19] #> checkpoint['batch'] = 346000
[Oct 01, 09:11:19] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:11:19] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/wesnoth_wesnoth.tsv ...
[Oct 01, 09:11:19] #> Got 2 queries. All QIDs are unique.

[Oct 01, 09:11:21] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/wesnoth_wesnoth/wesnoth_wesnoth/ivfpq.70.faiss ..
[Oct 01, 09:11:21] #> Building the emb2pid mapping..
[Oct 01, 09:11:21] len(self.emb2pid) = 1848350
[Oct 01, 09:11:22] tensor.size() =  torch.Size([1848862, 128])
[Oct 01, 09:11:22] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/wesnoth_wesnoth/wesnoth_wesnoth/0.pt ...
[Oct 01, 09:11:23] #> Using strides [303, 446]..
[Oct 01, 09:11:26] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wesnoth_wesnoth/retrieve.py/2023-10-01_09.11.03/ranking.tsv
0 The ( 1 ) filesystem : :get_wml_location function in filesystem.cpp and ( 2 ) is_legal_file function in filesystem_boost.cpp in Battle for Wesnoth before 1.12.3 and 1.13.x before 1.13.1 allow remote attackers to obtain sensitive information via vectors related to inclusion of .pbl files from WML . 280 280 30.64714241027832 10001 1090.3630256652832 ms
1 The ( 1 ) filesystem : :get_wml_location function in filesystem.cpp and ( 2 ) is_legal_file function in filesystem_boost.cpp in Battle for Wesnoth before 1.12.4 and 1.13.x before 1.13.1 , when a case-insensitive filesystem is used , allow remote attackers to obtain sensitive information via vectors related to inclusion of .pbl files from WML . NOTE : this vulnerability exists because of an incomplete fix for CVE-2015-5069 . 280 280 30.64714241027832 10001 602.9549837112427 ms
[Oct 01, 09:11:27] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wesnoth_wesnoth/retrieve.py/2023-10-01_09.11.03/ranking.tsv
#> Done.




2023-10-01 09:11:30,224 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:11:30,225 INFO rerun retrieving wireapp_wire-avs
2023-10-01 09:11:57,628 INFO 

[Oct 01, 09:11:32] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wireapp_wire-avs/retrieve.py/2023-10-01_09.11.31 




[Oct 01, 09:11:34] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wireapp_wire-avs/retrieve.py/2023-10-01_09.11.31/logs/ 


[Oct 01, 09:11:36] {'root': 'run/retrieve_output', 'experiment': 'wireapp_wire-avs', 'run': '2023-10-01_09.11.31', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/wireapp_wire-avs.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/wireapp_wire-avs', 'index_name': 'wireapp_wire-avs', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:11:47] #> Loading model checkpoint.
[Oct 01, 09:11:47] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:11:48] #> checkpoint['epoch'] = 0
[Oct 01, 09:11:48] #> checkpoint['batch'] = 346000
[Oct 01, 09:11:48] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:11:48] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/wireapp_wire-avs.tsv ...
[Oct 01, 09:11:48] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:11:50] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/wireapp_wire-avs/wireapp_wire-avs/ivfpq.70.faiss ..
[Oct 01, 09:11:50] #> Building the emb2pid mapping..
[Oct 01, 09:11:50] len(self.emb2pid) = 31567
[Oct 01, 09:11:51] tensor.size() =  torch.Size([32079, 128])
[Oct 01, 09:11:51] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/wireapp_wire-avs/wireapp_wire-avs/0.pt ...
[Oct 01, 09:11:51] #> Using strides [299, 414]..
[Oct 01, 09:11:53] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wireapp_wire-avs/retrieve.py/2023-10-01_09.11.31/ranking.tsv
0 wire-avs is the audio visual signaling ( AVS ) component of Wire , an open-source messenger . A remote format string vulnerability in versions prior to 7.1.12 allows an attacker to cause a denial of service or possibly execute arbitrary code . The issue has been fixed in wire-avs 7.1.12 . There are currently no known workarounds . 119 119 16.85755157470703 173 984.8146438598633 ms
[Oct 01, 09:11:54] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wireapp_wire-avs/retrieve.py/2023-10-01_09.11.31/ranking.tsv
#> Done.




2023-10-01 09:11:57,628 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:11:57,629 INFO rerun retrieving wolfSSL_wolfMQTT
2023-10-01 09:12:26,086 INFO 

[Oct 01, 09:11:59] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wolfSSL_wolfMQTT/retrieve.py/2023-10-01_09.11.59 




[Oct 01, 09:12:02] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wolfSSL_wolfMQTT/retrieve.py/2023-10-01_09.11.59/logs/ 


[Oct 01, 09:12:04] {'root': 'run/retrieve_output', 'experiment': 'wolfSSL_wolfMQTT', 'run': '2023-10-01_09.11.59', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/wolfSSL_wolfMQTT.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/wolfSSL_wolfMQTT', 'index_name': 'wolfSSL_wolfMQTT', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:12:14] #> Loading model checkpoint.
[Oct 01, 09:12:14] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:12:15] #> checkpoint['epoch'] = 0
[Oct 01, 09:12:15] #> checkpoint['batch'] = 346000
[Oct 01, 09:12:15] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:12:15] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/wolfSSL_wolfMQTT.tsv ...
[Oct 01, 09:12:15] #> Got 7 queries. All QIDs are unique.

[Oct 01, 09:12:17] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/wolfSSL_wolfMQTT/wolfSSL_wolfMQTT/ivfpq.70.faiss ..
[Oct 01, 09:12:17] #> Building the emb2pid mapping..
[Oct 01, 09:12:17] len(self.emb2pid) = 788550
[Oct 01, 09:12:18] tensor.size() =  torch.Size([789062, 128])
[Oct 01, 09:12:18] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/wolfSSL_wolfMQTT/wolfSSL_wolfMQTT/0.pt ...
[Oct 01, 09:12:19] #> Using strides [317, 415]..
[Oct 01, 09:12:21] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wolfSSL_wolfMQTT/retrieve.py/2023-10-01_09.11.59/ranking.tsv
0 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttDecode_Disconnect ( called from MqttClient_DecodePacket and MqttClient_WaitType ) . 21 21 28.505046844482422 4696 1034.0313911437988 ms
1 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow ( 8 bytes ) in MqttDecode_Publish ( called from MqttClient_DecodePacket and MqttClient_HandlePacket ) . 21 21 28.935890197753906 4696 552.0024299621582 ms
2 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttClient_DecodePacket ( called from MqttClient_HandlePacket and MqttClient_WaitType ) . 21 21 28.295429229736328 4696 390.22374153137207 ms
3 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttClient_DecodePacket ( called from MqttClient_WaitType and MqttClient_Connect ) . 21 21 28.295429229736328 4696 309.8565936088562 ms
4 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttClient_DecodePacket ( called from MqttClient_WaitType and MqttClient_Unsubscribe ) . 21 21 28.295429229736328 4696 261.80663108825684 ms
5 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow in MqttClient_DecodePacket ( called from MqttClient_WaitType and MqttClient_Subscribe ) . 21 21 28.295429229736328 4696 229.89817460378012 ms
6 wolfSSL wolfMQTT 1.9 has a heap-based buffer overflow ( 4 bytes ) in MqttDecode_Publish ( called from MqttClient_DecodePacket and MqttClient_HandlePacket ) . 21 21 28.93198013305664 4696 206.71650341578894 ms
[Oct 01, 09:12:23] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/wolfSSL_wolfMQTT/retrieve.py/2023-10-01_09.11.59/ranking.tsv
#> Done.




2023-10-01 09:12:26,086 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

2023-10-01 09:12:26,087 INFO rerun retrieving yast_yast-core
2023-10-01 09:12:53,598 INFO 

[Oct 01, 09:12:28] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/yast_yast-core/retrieve.py/2023-10-01_09.12.27 




[Oct 01, 09:12:30] #> Creating directory /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/yast_yast-core/retrieve.py/2023-10-01_09.12.27/logs/ 


[Oct 01, 09:12:32] {'root': 'run/retrieve_output', 'experiment': 'yast_yast-core', 'run': '2023-10-01_09.12.27', 'rank': -1, 'similarity': 'cosine', 'dim': 128, 'query_maxlen': 32, 'doc_maxlen': 512, 'mask_punctuation': True, 'checkpoint': '/mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn', 'bsize': 128, 'amp': True, 'queries': '/mnt/local/Baselines_Bugs/ColBERT/data/query_data/yast_yast-core.tsv', 'collection': None, 'qrels': None, 'index_root': '/mnt/local/Baselines_Bugs/ColBERT/run_index/yast_yast-core', 'index_name': 'yast_yast-core', 'partitions': 70, 'nprobe': 32, 'retrieve_only': False, 'faiss_name': None, 'faiss_depth': 1024, 'part_range': None, 'batch': False, 'depth': 100} 

[Oct 01, 09:12:42] #> Loading model checkpoint.
[Oct 01, 09:12:42] #> Loading checkpoint /mnt/local/Baselines_Bugs/ColBERT/commits_exp/commits_train/train.py/test.l2/checkpoints/colbert.dnn ..
[Oct 01, 09:12:43] #> checkpoint['epoch'] = 0
[Oct 01, 09:12:43] #> checkpoint['batch'] = 346000
[Oct 01, 09:12:43] [WARNING] 	 Got checkpoint['arguments']['similarity'] != args.similarity (i.e., l2 != cosine)
{
    "root": "commits_exp",
    "experiment": "commits_train_cont",
    "run": "test.l2",
    "rank": 0,
    "similarity": "l2",
    "dim": 128,
    "query_maxlen": 32,
    "doc_maxlen": 512,
    "mask_punctuation": true,
    "resume": true,
    "resume_optimizer": false,
    "checkpoint": "commits_exp\/commits_train_cont\/checkpoints\/colbert-300000.dnn",
    "lr": 3e-6,
    "maxsteps": 400000,
    "bsize": 64,
    "accumsteps": 1,
    "amp": true,
    "triples": "data\/train_data.tsv",
    "queries": null,
    "collection": null
}


[Oct 01, 09:12:43] #> Loading the queries from /mnt/local/Baselines_Bugs/ColBERT/data/query_data/yast_yast-core.tsv ...
[Oct 01, 09:12:43] #> Got 1 queries. All QIDs are unique.

[Oct 01, 09:12:45] #> Loading the FAISS index from /mnt/local/Baselines_Bugs/ColBERT/run_index/yast_yast-core/yast_yast-core/ivfpq.70.faiss ..
[Oct 01, 09:12:45] #> Building the emb2pid mapping..
[Oct 01, 09:12:45] len(self.emb2pid) = 562146
[Oct 01, 09:12:46] tensor.size() =  torch.Size([562658, 128])
[Oct 01, 09:12:46] |> Loading /mnt/local/Baselines_Bugs/ColBERT/run_index/yast_yast-core/yast_yast-core/0.pt ...
[Oct 01, 09:12:47] #> Using strides [303, 388]..
[Oct 01, 09:12:49] #> Logging ranked lists to /mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/yast_yast-core/retrieve.py/2023-10-01_09.12.27/ranking.tsv
0 The YaST2 network created files with world readable permissions which could have allowed local users to read sensitive material out of network configuration files , like passwords for wireless networks . 68 68 25.63689422607422 3048 1027.665376663208 ms
[Oct 01, 09:12:50] #> Logging query #0 (qid 0) now...



/mnt/local/Baselines_Bugs/ColBERT/run/retrieve_output/yast_yast-core/retrieve.py/2023-10-01_09.12.27/ranking.tsv
#> Done.




2023-10-01 09:12:53,598 INFO Some weights of the model checkpoint at bert-base-uncased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).
- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of ColBERT were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

